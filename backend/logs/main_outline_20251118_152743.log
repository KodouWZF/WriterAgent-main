=== main_outline æœåŠ¡å¯åŠ¨æ—¥å¿— ===
å¯åŠ¨æ—¶é—´: 2025-11-18 15:27:55
å·¥ä½œç›®å½•: D:\man\myvenv\WriterAgent-main\backend\main_outline
è„šæœ¬æ–‡ä»¶: main_api.py
ç«¯å£: 10050
==================================================

D:\man\myvenv\Lib\site-packages\google\cloud\aiplatform\models.py:52: FutureWarning: Support for google-cloud-storage < 3.0.0 will be removed in a future version of google-cloud-aiplatform. Please upgrade to google-cloud-storage >= 3.0.0.
  from google.cloud.aiplatform.utils import gcs_utils
2025-11-18 15:28:06,115 [INFO] å¯åŠ¨ Outline Agent æœåŠ¡
2025-11-18 15:28:06,115 [INFO] æµå¼æ¨¡å¼: True
2025-11-18 15:28:06,116 [INFO] åˆå§‹åŒ–Runner...
2025-11-18 15:28:06,117 [INFO] ä½¿ç”¨ SSE æµå¼è¾“å‡ºæ¨¡å¼
2025-11-18 15:28:06,117 [INFO] æœåŠ¡å¯åŠ¨ä¸­ï¼Œç›‘å¬åœ°å€: http://localhost:10050
åˆ›å»ºæ¨¡å‹,provider: local,æ¨¡å‹æ˜¯: qwen3
INFO:     Started server process [2596]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://localhost:10050 (Press CTRL+C to quit)
INFO:     127.0.0.1:49198 - "GET /.well-known/agent.json HTTP/1.1" 200 OK
INFO:     ::1:49199 - "POST / HTTP/1.1" 200 OK
2025-11-18 15:28:50,414 [DEBUG] æ”¶åˆ°è¯·æ±‚ä¿¡æ¯: parts=[Part(
  text='è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©åœ¨ç³–å°¿ç—…è¶³æºƒç–¡æ²»ç–—ä¸­çš„ä½œç”¨åŠæœºåˆ¶ç ”ç©¶è¿›å±•'
)] role='user'
2025-11-18 15:28:50,414 [INFO] æ”¶åˆ°è¯·æ±‚ä¿¡æ¯: parts=[Part(
  text='è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©åœ¨ç³–å°¿ç—…è¶³æºƒç–¡æ²»ç–—ä¸­çš„ä½œç”¨åŠæœºåˆ¶ç ”ç©¶è¿›å±•'
)] role='user'
[92m15:28:50 - LiteLLM:DEBUG[0m: utils.py:376 - 

2025-11-18 15:28:50,424 [DEBUG] 

[92m15:28:50 - LiteLLM:DEBUG[0m: utils.py:376 - [92mRequest to litellm:[0m
2025-11-18 15:28:50,424 [DEBUG] [92mRequest to litellm:[0m
[92m15:28:50 - LiteLLM:DEBUG[0m: utils.py:376 - [92mlitellm.acompletion(model='openai/qwen3', messages=[{'role': 'developer', 'content': '\n/no_think\n# è§’è‰²\nä½ æ˜¯ä¸€åä¸¥è°¨çš„ç»¼è¿°ä½œè€…ä¸å¤šå­¦ç§‘ä¿¡æ¯åˆ†æä¸“å®¶ã€‚å¿…é¡»å…ˆå®Œæˆç³»ç»Ÿæ£€ç´¢ä¸è¯æ®ç­›é€‰ï¼Œå†å¼€å§‹å†™å¤§çº²ã€‚\n\n# ç›®æ ‡\nä»…ç”Ÿæˆã€ä¸­æ–‡Markdownå¤§çº²ã€‘ï¼Œç»“æ„ä¸æ ‡é¢˜å¿…é¡»ä¸¥æ ¼æŒ‰â€œè¾“å‡ºç»“æ„â€ä¸€èŠ‚ï¼›ä¸å†™æ­£æ–‡ã€ä¸åŠ URLã€ä¸è¾“å‡ºå¤šä½™å†…å®¹ã€‚\n\n# ä»¥æ£€ç´¢ç»“æœé©±åŠ¨çš„åŠ¨æ€æ‰©å±•ï¼ˆæ ¸å¿ƒå¼ºåŒ–ï¼‰\n- ä»¥â€œä¸»é¢˜ç°‡â€ä¸ºæœ€å°å•å…ƒï¼šåŸºäºæ£€ç´¢ç»“æœå°†æ–‡çŒ®æˆ–æŠ¥å‘Šèšç±»ä¸ºä¸»é¢˜ç°‡ï¼ˆå¦‚æœºåˆ¶ã€æ–¹æ³•å­¦ã€äºšå‹ã€åº”ç”¨åœºæ™¯ã€å½±å“å› ç´ ã€ç»ˆç‚¹ã€å®‰å…¨æ€§ã€ç»æµå­¦ã€ç›‘ç®¡ç­‰ï¼‰ã€‚\n- æ‰©å±•è§„åˆ™ï¼ˆå†³å®šå°èŠ‚æ•°é‡ä¸å‘½åï¼‰ï¼š\n  1) å½“æŸä¸»é¢˜ç°‡æœ‰è¾ƒå¤šç ”ç©¶/æŒ‡å—/æŠ¥å‘Šæ”¯æŒæ—¶ï¼Œåˆ›å»ºç‹¬ç«‹ `###` å°èŠ‚ã€‚\n  2) è‹¥æŸä¸»é¢˜ç°‡æ¶‰åŠçš„ç ”ç©¶æ•°é‡è¾ƒå°‘ï¼Œåˆ™åˆå¹¶åˆ°é‚»è¿‘ `####` åˆ†èŠ‚ï¼›é¿å…ç”Ÿæˆç©ºæ´å°èŠ‚ã€‚\n  3) å¯¹â€œæ¯”è¾ƒ/ä¸€è‡´æ€§-å·®å¼‚/äº‰è®®ç‚¹â€â€œäºšç»„/ç‰¹å®šåº”ç”¨åœºæ™¯â€â€œçœŸå®ä¸–ç•Œè¯æ®/ç°åœºå®è·µâ€â€œæ–¹æ³•å­¦è´¨é‡ä¸åå€šâ€â€œæ ‡å‡†åŒ–ä¸ç›‘ç®¡/ä¼¦ç†/å…¬å¹³æ€§â€ä¼˜å…ˆå»ºèŠ‚ï¼ˆè‹¥è¯æ®å­˜åœ¨ï¼‰ã€‚\n  4) å°èŠ‚æ’åºæŒ‰â€œç ”ç©¶æ•°é‡Ã—å½±å“åŠ›Ã—æ–°è¿‘æ€§â€ç»¼åˆé™åºï¼›æ ‡é¢˜ç”¨å¯è¯»çš„ä¸»é¢˜åï¼Œä¸ä½¿ç”¨æ¨¡æ¿åŒ–è¯æ±‡ã€‚\n- åˆå¹¶ä¸æ‹†åˆ†é˜ˆå€¼ï¼š  \n  - å•ä¸€ `###` å°èŠ‚è‹¥æ¡ç›®>10ï¼ŒæŒ‰æœºåˆ¶/åœºæ™¯/äººç¾¤æ‹†ä¸ºå¤šä¸ª `####`ï¼›  \n  - å•ä¸€å°èŠ‚æ¡ç›®<3ï¼Œåˆå¹¶è‡³é‚»è¿‘æ›´ä¸Šä½å°èŠ‚ã€‚\n- è¦†ç›–åº¦çº¦æŸï¼š`###/####` å°èŠ‚åˆè®¡è‡³å°‘è¦†ç›–ä¸»è¦ä¸»é¢˜ç°‡çš„70%ã€‚\n\n# æ’°å†™è¦æ±‚\n- æ ‡é¢˜å¿…é¡»â€œæ¥æºäºæ£€ç´¢ä¸»é¢˜â€ï¼Œä¸å¯ç…§æ¬æ¨¡æ¿ï¼›å°èŠ‚æ•°é‡ä¸å‘½åä»¥å®é™…æ£€ç´¢ç»“æœä¸ºå‡†ã€‚\n- å¤§çº²æ¡ç›®ç²¾ç‚¼ï¼ˆâ‰¤30å­—ï¼‰ï¼Œå°½é‡é‡åŒ–å…³é”®æŒ‡æ ‡ï¼ˆå¦‚æ•ˆåº”é‡/é˜ˆå€¼/æ—¶é—´çª—/äººç¾¤ï¼‰ã€‚\n- æœ¯è¯­ä¸­æ–‡ç»Ÿä¸€ï¼Œåº¦é‡å•ä½/ç¼©å†™ä¸€è‡´ï¼›å¯åšç­‰ä»·æ˜ å°„ï¼ˆå¦‚â€œæ•°æ®é‡‡é›†/è´¨æ§â€â†’â€œæ•°æ®é¢„å¤„ç†/è´¨é‡ä¿éšœâ€ï¼‰ã€‚\n- ä¸¥ç¦ç”Ÿæˆä¸ä¸»é¢˜æ— å…³æˆ–æ— æ”¯æ’‘çš„å°èŠ‚/è¦ç‚¹ã€‚\n- ç¦æ­¢åœ¨å¤§çº²çš„æœ«å°¾æ·»åŠ å¼•ç”¨è¯´æ˜å’Œå‚è€ƒæ–‡çŒ®è¯´æ˜ç­‰ä»»ä½•è¯´æ˜ã€‚\n- ç¦æ­¢åœ¨å¤§çº²æ·»åŠ ä»»ä½•å¼•ç”¨è¯´æ˜ï¼Œä»…ç”Ÿæˆã€Markdownå¤§çº²ã€‘ã€‚\n\n\n# å¼ºåˆ¶æ£€ç´¢è¦æ±‚\n- åœ¨å¼€å§‹ç”Ÿæˆå¤§çº²ä¹‹å‰ï¼Œå¿…é¡»è°ƒç”¨ DocumentSearch å·¥å…·è¿›è¡Œç³»ç»Ÿæ€§æ–‡çŒ®æ£€ç´¢\n- æœç´¢å¿…é¡»åŒ…å«ä¸»é¢˜çš„æ ¸å¿ƒå…³é”®è¯åŠå…¶åŒä¹‰è¯ã€ç›¸å…³æœ¯è¯­\n- å¿…é¡»åŸºäºå®é™…æ£€ç´¢åˆ°çš„æ–‡çŒ®è¯æ®æ¥æ„å»ºå¤§çº²ç»“æ„å’Œå†…å®¹\n- ä¸¥ç¦åœ¨æœªæ‰§è¡Œæ£€ç´¢çš„æƒ…å†µä¸‹ç›´æ¥ç”Ÿæˆå¤§çº²\n\n# å·¥ä½œæµç¨‹ï¼ˆå…ˆæ£€ç´¢ï¼Œåå†™ä½œï¼‰\n1) æ£€ç´¢ä¸è¦†ç›–é¢  \n   - ç›®æ ‡ï¼šâ‰¥30ç¯‡å€™é€‰æ–‡çŒ®ï¼›è¿‘5å¹´ä¼˜å…ˆï¼Œä½†éœ€ä¿ç•™é‡Œç¨‹ç¢‘ç ”ç©¶ã€‚  \n   - è®°å½•æ¯æ¡å€™é€‰çš„ä¸»é¢˜ç°‡ã€æ ¸å¿ƒç»“è®ºä¸å¯æå–å®šé‡æŒ‡æ ‡ã€‚\n2) ä¸»é¢˜èšåˆ  \n   - å°†æ‰€æœ‰å€™é€‰æ–‡çŒ®èšåˆä¸ºè‹¥å¹²ä¸»é¢˜ç°‡ã€‚  \n   - ä¾æ®ä¸»é¢˜ç°‡çš„æ•°é‡å’Œé‡è¦æ€§å†³å®šå°èŠ‚ç»“æ„ï¼›ä¸è¶³è€…å¹¶å…¥ç›¸é‚»èŠ‚ã€‚  \n   - ä¸ºæ¯”è¾ƒã€å¼‚è´¨æ€§æ¥æºã€çœŸå®ä¸–ç•Œè¯æ®ã€æ–°å…´æ–¹å‘ä¸ç›‘ç®¡/ä¼¦ç†ç­‰è‡ªåŠ¨é¢„ç•™ä½ç½®ï¼ˆå­˜åœ¨è¯æ®æ—¶ï¼‰ã€‚\n\n# è¾“å‡ºè¦æ±‚\n- ä½¿ç”¨çš„è¯­è¨€æ˜¯: chinese\n- ä»…è¾“å‡ºã€Markdownå¤§çº²ã€‘ï¼Œå±‚çº§ä½¿ç”¨ #/##/###/####ã€‚  \n- æ¯æ¡è¦ç‚¹â‰¤30å­—ã€ä¿¡æ¯å¯†åº¦é«˜ã€å°½é‡é‡åŒ–ã€‚    \n- å¤§çº²æœ€å¥½ä¸å°‘äº10ä¸ªç« èŠ‚ï¼Œä¸å¤šäº15ç« èŠ‚ã€‚\n- ã€å¼ºåˆ¶ã€‘è¾“å‡ºå®Œæˆåç«‹å³ç»“æŸï¼›ç¦æ­¢åœ¨æ–‡æœ«æ·»åŠ â€œå¼•ç”¨è¯´æ˜/å‚è€ƒæ–‡çŒ®/è¯´æ˜/æ³¨é‡Š/Notes/Referencesâ€ç­‰ä»»ä½•è¯´æ˜æ€§æ–‡æœ¬æˆ–æ®µè½ã€‚\n\n# è¾“å‡ºç»“æ„ï¼ˆæ ‡é¢˜ä¸é¡ºåºå¿…é¡»ä¸€è‡´ï¼›åœ¨"..."å¤„æŒ‰è§„åˆ™åŠ¨æ€æ‰©å±•ï¼‰\n# è‡ªåŠ¨ç”Ÿæˆç²¾å‡†æ ‡é¢˜ï¼šä¸åŠ å‰¯æ ‡é¢˜\nä¸‹é¢æ˜¯ä¸€ä¸ªç¤ºä¾‹å¤§çº²ç»“æ„ï¼Œä»…ä¾›å‚è€ƒã€‚å®é™…è¾“å‡ºæ—¶å¿…é¡»æ ¹æ®æ£€ç´¢ç»“æœåŠ¨æ€è°ƒæ•´ç« èŠ‚ä¸å°èŠ‚æ ‡é¢˜ã€æ•°é‡ä¸é¡ºåºã€‚è¾“å‡ºçš„æ—¶å€™å¿…é¡»å¸¦æœ‰æ‰€æ’°å†™çš„å¤§çº²å¯¹åº”çš„æ ‡é¢˜ã€‚\n\n## æ‘˜è¦\n- èƒŒæ™¯ï¼šç ”ç©¶ç°çŠ¶/æœªæ»¡è¶³éœ€æ±‚\n- ç›®çš„ï¼šç»¼è¿°æ—¨åœ¨è§£å†³ä»€ä¹ˆé—®é¢˜\n- æ–¹æ³•ï¼ˆå¯é€‰ï¼‰ï¼šæ£€ç´¢èŒƒå›´/çº³æ’æ ‡å‡†/è¯æ®åˆ†çº§ç®€è¿°\n- ä¸»è¦å‘ç°ï¼šå›´ç»•â€œæŠ€æœ¯/æ–¹æ³•Ã—æœºåˆ¶/åº”ç”¨â€çš„å…³é”®è¿›å±•\n- ç»“è®ºä¸å±•æœ›ï¼šè½¬åŒ–è·¯å¾„/æ ‡å‡†åŒ–æŒ‘æˆ˜/æœªæ¥å‘å±•å‰æ™¯\n- å…³é”®è¯ï¼š3â€“8ä¸ªï¼›åˆ†å·åˆ†éš”\n\n## 1. å¼•è¨€\n### 1.1 xx\n### 1.2 xx\n### 1.3 xx\n...\n\n\nYou are an agent. Your internal name is "outline_agent".\n\n The description about you is "generate outline"'}, {'role': 'user', 'content': 'è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©åœ¨ç³–å°¿ç—…è¶³æºƒç–¡æ²»ç–—ä¸­çš„ä½œç”¨åŠæœºåˆ¶ç ”ç©¶è¿›å±•'}], tools=[{'type': 'function', 'function': {'name': 'DocumentSearch', 'description': '\n    æ ¹æ®å…³é”®è¯æœç´¢æ–‡æ¡£\n    :param keyword: str, æœç´¢çš„ç›¸å…³æ–‡æ¡£çš„å…³é”®è¯\n    :return: è¿”å›æ¯ç¯‡æ–‡æ¡£æ•°æ®\n    ', 'parameters': {'type': 'object', 'properties': {'keyword': {'type': 'string'}}}}}], response_format=None, api_key='sk-xxx', api_base='http://192.168.1.13:9997/v1', stream=True)[0m
2025-11-18 15:28:50,424 [DEBUG] [92mlitellm.acompletion(model='openai/qwen3', messages=[{'role': 'developer', 'content': '\n/no_think\n# è§’è‰²\nä½ æ˜¯ä¸€åä¸¥è°¨çš„ç»¼è¿°ä½œè€…ä¸å¤šå­¦ç§‘ä¿¡æ¯åˆ†æä¸“å®¶ã€‚å¿…é¡»å…ˆå®Œæˆç³»ç»Ÿæ£€ç´¢ä¸è¯æ®ç­›é€‰ï¼Œå†å¼€å§‹å†™å¤§çº²ã€‚\n\n# ç›®æ ‡\nä»…ç”Ÿæˆã€ä¸­æ–‡Markdownå¤§çº²ã€‘ï¼Œç»“æ„ä¸æ ‡é¢˜å¿…é¡»ä¸¥æ ¼æŒ‰â€œè¾“å‡ºç»“æ„â€ä¸€èŠ‚ï¼›ä¸å†™æ­£æ–‡ã€ä¸åŠ URLã€ä¸è¾“å‡ºå¤šä½™å†…å®¹ã€‚\n\n# ä»¥æ£€ç´¢ç»“æœé©±åŠ¨çš„åŠ¨æ€æ‰©å±•ï¼ˆæ ¸å¿ƒå¼ºåŒ–ï¼‰\n- ä»¥â€œä¸»é¢˜ç°‡â€ä¸ºæœ€å°å•å…ƒï¼šåŸºäºæ£€ç´¢ç»“æœå°†æ–‡çŒ®æˆ–æŠ¥å‘Šèšç±»ä¸ºä¸»é¢˜ç°‡ï¼ˆå¦‚æœºåˆ¶ã€æ–¹æ³•å­¦ã€äºšå‹ã€åº”ç”¨åœºæ™¯ã€å½±å“å› ç´ ã€ç»ˆç‚¹ã€å®‰å…¨æ€§ã€ç»æµå­¦ã€ç›‘ç®¡ç­‰ï¼‰ã€‚\n- æ‰©å±•è§„åˆ™ï¼ˆå†³å®šå°èŠ‚æ•°é‡ä¸å‘½åï¼‰ï¼š\n  1) å½“æŸä¸»é¢˜ç°‡æœ‰è¾ƒå¤šç ”ç©¶/æŒ‡å—/æŠ¥å‘Šæ”¯æŒæ—¶ï¼Œåˆ›å»ºç‹¬ç«‹ `###` å°èŠ‚ã€‚\n  2) è‹¥æŸä¸»é¢˜ç°‡æ¶‰åŠçš„ç ”ç©¶æ•°é‡è¾ƒå°‘ï¼Œåˆ™åˆå¹¶åˆ°é‚»è¿‘ `####` åˆ†èŠ‚ï¼›é¿å…ç”Ÿæˆç©ºæ´å°èŠ‚ã€‚\n  3) å¯¹â€œæ¯”è¾ƒ/ä¸€è‡´æ€§-å·®å¼‚/äº‰è®®ç‚¹â€â€œäºšç»„/ç‰¹å®šåº”ç”¨åœºæ™¯â€â€œçœŸå®ä¸–ç•Œè¯æ®/ç°åœºå®è·µâ€â€œæ–¹æ³•å­¦è´¨é‡ä¸åå€šâ€â€œæ ‡å‡†åŒ–ä¸ç›‘ç®¡/ä¼¦ç†/å…¬å¹³æ€§â€ä¼˜å…ˆå»ºèŠ‚ï¼ˆè‹¥è¯æ®å­˜åœ¨ï¼‰ã€‚\n  4) å°èŠ‚æ’åºæŒ‰â€œç ”ç©¶æ•°é‡Ã—å½±å“åŠ›Ã—æ–°è¿‘æ€§â€ç»¼åˆé™åºï¼›æ ‡é¢˜ç”¨å¯è¯»çš„ä¸»é¢˜åï¼Œä¸ä½¿ç”¨æ¨¡æ¿åŒ–è¯æ±‡ã€‚\n- åˆå¹¶ä¸æ‹†åˆ†é˜ˆå€¼ï¼š  \n  - å•ä¸€ `###` å°èŠ‚è‹¥æ¡ç›®>10ï¼ŒæŒ‰æœºåˆ¶/åœºæ™¯/äººç¾¤æ‹†ä¸ºå¤šä¸ª `####`ï¼›  \n  - å•ä¸€å°èŠ‚æ¡ç›®<3ï¼Œåˆå¹¶è‡³é‚»è¿‘æ›´ä¸Šä½å°èŠ‚ã€‚\n- è¦†ç›–åº¦çº¦æŸï¼š`###/####` å°èŠ‚åˆè®¡è‡³å°‘è¦†ç›–ä¸»è¦ä¸»é¢˜ç°‡çš„70%ã€‚\n\n# æ’°å†™è¦æ±‚\n- æ ‡é¢˜å¿…é¡»â€œæ¥æºäºæ£€ç´¢ä¸»é¢˜â€ï¼Œä¸å¯ç…§æ¬æ¨¡æ¿ï¼›å°èŠ‚æ•°é‡ä¸å‘½åä»¥å®é™…æ£€ç´¢ç»“æœä¸ºå‡†ã€‚\n- å¤§çº²æ¡ç›®ç²¾ç‚¼ï¼ˆâ‰¤30å­—ï¼‰ï¼Œå°½é‡é‡åŒ–å…³é”®æŒ‡æ ‡ï¼ˆå¦‚æ•ˆåº”é‡/é˜ˆå€¼/æ—¶é—´çª—/äººç¾¤ï¼‰ã€‚\n- æœ¯è¯­ä¸­æ–‡ç»Ÿä¸€ï¼Œåº¦é‡å•ä½/ç¼©å†™ä¸€è‡´ï¼›å¯åšç­‰ä»·æ˜ å°„ï¼ˆå¦‚â€œæ•°æ®é‡‡é›†/è´¨æ§â€â†’â€œæ•°æ®é¢„å¤„ç†/è´¨é‡ä¿éšœâ€ï¼‰ã€‚\n- ä¸¥ç¦ç”Ÿæˆä¸ä¸»é¢˜æ— å…³æˆ–æ— æ”¯æ’‘çš„å°èŠ‚/è¦ç‚¹ã€‚\n- ç¦æ­¢åœ¨å¤§çº²çš„æœ«å°¾æ·»åŠ å¼•ç”¨è¯´æ˜å’Œå‚è€ƒæ–‡çŒ®è¯´æ˜ç­‰ä»»ä½•è¯´æ˜ã€‚\n- ç¦æ­¢åœ¨å¤§çº²æ·»åŠ ä»»ä½•å¼•ç”¨è¯´æ˜ï¼Œä»…ç”Ÿæˆã€Markdownå¤§çº²ã€‘ã€‚\n\n\n# å¼ºåˆ¶æ£€ç´¢è¦æ±‚\n- åœ¨å¼€å§‹ç”Ÿæˆå¤§çº²ä¹‹å‰ï¼Œå¿…é¡»è°ƒç”¨ DocumentSearch å·¥å…·è¿›è¡Œç³»ç»Ÿæ€§æ–‡çŒ®æ£€ç´¢\n- æœç´¢å¿…é¡»åŒ…å«ä¸»é¢˜çš„æ ¸å¿ƒå…³é”®è¯åŠå…¶åŒä¹‰è¯ã€ç›¸å…³æœ¯è¯­\n- å¿…é¡»åŸºäºå®é™…æ£€ç´¢åˆ°çš„æ–‡çŒ®è¯æ®æ¥æ„å»ºå¤§çº²ç»“æ„å’Œå†…å®¹\n- ä¸¥ç¦åœ¨æœªæ‰§è¡Œæ£€ç´¢çš„æƒ…å†µä¸‹ç›´æ¥ç”Ÿæˆå¤§çº²\n\n# å·¥ä½œæµç¨‹ï¼ˆå…ˆæ£€ç´¢ï¼Œåå†™ä½œï¼‰\n1) æ£€ç´¢ä¸è¦†ç›–é¢  \n   - ç›®æ ‡ï¼šâ‰¥30ç¯‡å€™é€‰æ–‡çŒ®ï¼›è¿‘5å¹´ä¼˜å…ˆï¼Œä½†éœ€ä¿ç•™é‡Œç¨‹ç¢‘ç ”ç©¶ã€‚  \n   - è®°å½•æ¯æ¡å€™é€‰çš„ä¸»é¢˜ç°‡ã€æ ¸å¿ƒç»“è®ºä¸å¯æå–å®šé‡æŒ‡æ ‡ã€‚\n2) ä¸»é¢˜èšåˆ  \n   - å°†æ‰€æœ‰å€™é€‰æ–‡çŒ®èšåˆä¸ºè‹¥å¹²ä¸»é¢˜ç°‡ã€‚  \n   - ä¾æ®ä¸»é¢˜ç°‡çš„æ•°é‡å’Œé‡è¦æ€§å†³å®šå°èŠ‚ç»“æ„ï¼›ä¸è¶³è€…å¹¶å…¥ç›¸é‚»èŠ‚ã€‚  \n   - ä¸ºæ¯”è¾ƒã€å¼‚è´¨æ€§æ¥æºã€çœŸå®ä¸–ç•Œè¯æ®ã€æ–°å…´æ–¹å‘ä¸ç›‘ç®¡/ä¼¦ç†ç­‰è‡ªåŠ¨é¢„ç•™ä½ç½®ï¼ˆå­˜åœ¨è¯æ®æ—¶ï¼‰ã€‚\n\n# è¾“å‡ºè¦æ±‚\n- ä½¿ç”¨çš„è¯­è¨€æ˜¯: chinese\n- ä»…è¾“å‡ºã€Markdownå¤§çº²ã€‘ï¼Œå±‚çº§ä½¿ç”¨ #/##/###/####ã€‚  \n- æ¯æ¡è¦ç‚¹â‰¤30å­—ã€ä¿¡æ¯å¯†åº¦é«˜ã€å°½é‡é‡åŒ–ã€‚    \n- å¤§çº²æœ€å¥½ä¸å°‘äº10ä¸ªç« èŠ‚ï¼Œä¸å¤šäº15ç« èŠ‚ã€‚\n- ã€å¼ºåˆ¶ã€‘è¾“å‡ºå®Œæˆåç«‹å³ç»“æŸï¼›ç¦æ­¢åœ¨æ–‡æœ«æ·»åŠ â€œå¼•ç”¨è¯´æ˜/å‚è€ƒæ–‡çŒ®/è¯´æ˜/æ³¨é‡Š/Notes/Referencesâ€ç­‰ä»»ä½•è¯´æ˜æ€§æ–‡æœ¬æˆ–æ®µè½ã€‚\n\n# è¾“å‡ºç»“æ„ï¼ˆæ ‡é¢˜ä¸é¡ºåºå¿…é¡»ä¸€è‡´ï¼›åœ¨"..."å¤„æŒ‰è§„åˆ™åŠ¨æ€æ‰©å±•ï¼‰\n# è‡ªåŠ¨ç”Ÿæˆç²¾å‡†æ ‡é¢˜ï¼šä¸åŠ å‰¯æ ‡é¢˜\nä¸‹é¢æ˜¯ä¸€ä¸ªç¤ºä¾‹å¤§çº²ç»“æ„ï¼Œä»…ä¾›å‚è€ƒã€‚å®é™…è¾“å‡ºæ—¶å¿…é¡»æ ¹æ®æ£€ç´¢ç»“æœåŠ¨æ€è°ƒæ•´ç« èŠ‚ä¸å°èŠ‚æ ‡é¢˜ã€æ•°é‡ä¸é¡ºåºã€‚è¾“å‡ºçš„æ—¶å€™å¿…é¡»å¸¦æœ‰æ‰€æ’°å†™çš„å¤§çº²å¯¹åº”çš„æ ‡é¢˜ã€‚\n\n## æ‘˜è¦\n- èƒŒæ™¯ï¼šç ”ç©¶ç°çŠ¶/æœªæ»¡è¶³éœ€æ±‚\n- ç›®çš„ï¼šç»¼è¿°æ—¨åœ¨è§£å†³ä»€ä¹ˆé—®é¢˜\n- æ–¹æ³•ï¼ˆå¯é€‰ï¼‰ï¼šæ£€ç´¢èŒƒå›´/çº³æ’æ ‡å‡†/è¯æ®åˆ†çº§ç®€è¿°\n- ä¸»è¦å‘ç°ï¼šå›´ç»•â€œæŠ€æœ¯/æ–¹æ³•Ã—æœºåˆ¶/åº”ç”¨â€çš„å…³é”®è¿›å±•\n- ç»“è®ºä¸å±•æœ›ï¼šè½¬åŒ–è·¯å¾„/æ ‡å‡†åŒ–æŒ‘æˆ˜/æœªæ¥å‘å±•å‰æ™¯\n- å…³é”®è¯ï¼š3â€“8ä¸ªï¼›åˆ†å·åˆ†éš”\n\n## 1. å¼•è¨€\n### 1.1 xx\n### 1.2 xx\n### 1.3 xx\n...\n\n\nYou are an agent. Your internal name is "outline_agent".\n\n The description about you is "generate outline"'}, {'role': 'user', 'content': 'è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©åœ¨ç³–å°¿ç—…è¶³æºƒç–¡æ²»ç–—ä¸­çš„ä½œç”¨åŠæœºåˆ¶ç ”ç©¶è¿›å±•'}], tools=[{'type': 'function', 'function': {'name': 'DocumentSearch', 'description': '\n    æ ¹æ®å…³é”®è¯æœç´¢æ–‡æ¡£\n    :param keyword: str, æœç´¢çš„ç›¸å…³æ–‡æ¡£çš„å…³é”®è¯\n    :return: è¿”å›æ¯ç¯‡æ–‡æ¡£æ•°æ®\n    ', 'parameters': {'type': 'object', 'properties': {'keyword': {'type': 'string'}}}}}], response_format=None, api_key='sk-xxx', api_base='http://192.168.1.13:9997/v1', stream=True)[0m
[92m15:28:50 - LiteLLM:DEBUG[0m: utils.py:376 - 

2025-11-18 15:28:50,425 [DEBUG] 

[92m15:28:50 - LiteLLM:DEBUG[0m: litellm_logging.py:490 - self.optional_params: {}
2025-11-18 15:28:50,425 [DEBUG] self.optional_params: {}
[92m15:28:50 - LiteLLM:DEBUG[0m: utils.py:376 - ASYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache'): None
2025-11-18 15:28:50,426 [DEBUG] ASYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache'): None
[92m15:28:50 - LiteLLM:DEBUG[0m: main.py:504 - ğŸ”„ NO SHARED SESSION: acompletion called without shared_session
2025-11-18 15:28:50,427 [DEBUG] ğŸ”„ NO SHARED SESSION: acompletion called without shared_session
2025-11-18 15:28:50,428 [INFO] Task not found or task_id not set. Creating new task for event (task_id: 84b7854c-524c-43a2-81d1-5eb0122d143b, context_id: c06fbca28b504686a3837503367483b1).
[92m15:28:50 - LiteLLM:DEBUG[0m: base_utils.py:219 - Translating developer role to system role for non-OpenAI providers.
2025-11-18 15:28:50,440 [DEBUG] Translating developer role to system role for non-OpenAI providers.
[92m15:28:50 - LiteLLM:INFO[0m: utils.py:3422 - 
LiteLLM completion() model= qwen3; provider = openai
2025-11-18 15:28:50,443 [INFO] 
LiteLLM completion() model= qwen3; provider = openai
[92m15:28:50 - LiteLLM:DEBUG[0m: utils.py:3425 - 
LiteLLM: Params passed to completion() {'model': 'qwen3', 'functions': None, 'function_call': None, 'temperature': None, 'top_p': None, 'n': None, 'stream': True, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': [{'type': 'function', 'function': {'name': 'DocumentSearch', 'description': '\n    æ ¹æ®å…³é”®è¯æœç´¢æ–‡æ¡£\n    :param keyword: str, æœç´¢çš„ç›¸å…³æ–‡æ¡£çš„å…³é”®è¯\n    :return: è¿”å›æ¯ç¯‡æ–‡æ¡£æ•°æ®\n    ', 'parameters': {'type': 'object', 'properties': {'keyword': {'type': 'string'}}}}}], 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\n/no_think\n# è§’è‰²\nä½ æ˜¯ä¸€åä¸¥è°¨çš„ç»¼è¿°ä½œè€…ä¸å¤šå­¦ç§‘ä¿¡æ¯åˆ†æä¸“å®¶ã€‚å¿…é¡»å…ˆå®Œæˆç³»ç»Ÿæ£€ç´¢ä¸è¯æ®ç­›é€‰ï¼Œå†å¼€å§‹å†™å¤§çº²ã€‚\n\n# ç›®æ ‡\nä»…ç”Ÿæˆã€ä¸­æ–‡Markdownå¤§çº²ã€‘ï¼Œç»“æ„ä¸æ ‡é¢˜å¿…é¡»ä¸¥æ ¼æŒ‰â€œè¾“å‡ºç»“æ„â€ä¸€èŠ‚ï¼›ä¸å†™æ­£æ–‡ã€ä¸åŠ URLã€ä¸è¾“å‡ºå¤šä½™å†…å®¹ã€‚\n\n# ä»¥æ£€ç´¢ç»“æœé©±åŠ¨çš„åŠ¨æ€æ‰©å±•ï¼ˆæ ¸å¿ƒå¼ºåŒ–ï¼‰\n- ä»¥â€œä¸»é¢˜ç°‡â€ä¸ºæœ€å°å•å…ƒï¼šåŸºäºæ£€ç´¢ç»“æœå°†æ–‡çŒ®æˆ–æŠ¥å‘Šèšç±»ä¸ºä¸»é¢˜ç°‡ï¼ˆå¦‚æœºåˆ¶ã€æ–¹æ³•å­¦ã€äºšå‹ã€åº”ç”¨åœºæ™¯ã€å½±å“å› ç´ ã€ç»ˆç‚¹ã€å®‰å…¨æ€§ã€ç»æµå­¦ã€ç›‘ç®¡ç­‰ï¼‰ã€‚\n- æ‰©å±•è§„åˆ™ï¼ˆå†³å®šå°èŠ‚æ•°é‡ä¸å‘½åï¼‰ï¼š\n  1) å½“æŸä¸»é¢˜ç°‡æœ‰è¾ƒå¤šç ”ç©¶/æŒ‡å—/æŠ¥å‘Šæ”¯æŒæ—¶ï¼Œåˆ›å»ºç‹¬ç«‹ `###` å°èŠ‚ã€‚\n  2) è‹¥æŸä¸»é¢˜ç°‡æ¶‰åŠçš„ç ”ç©¶æ•°é‡è¾ƒå°‘ï¼Œåˆ™åˆå¹¶åˆ°é‚»è¿‘ `####` åˆ†èŠ‚ï¼›é¿å…ç”Ÿæˆç©ºæ´å°èŠ‚ã€‚\n  3) å¯¹â€œæ¯”è¾ƒ/ä¸€è‡´æ€§-å·®å¼‚/äº‰è®®ç‚¹â€â€œäºšç»„/ç‰¹å®šåº”ç”¨åœºæ™¯â€â€œçœŸå®ä¸–ç•Œè¯æ®/ç°åœºå®è·µâ€â€œæ–¹æ³•å­¦è´¨é‡ä¸åå€šâ€â€œæ ‡å‡†åŒ–ä¸ç›‘ç®¡/ä¼¦ç†/å…¬å¹³æ€§â€ä¼˜å…ˆå»ºèŠ‚ï¼ˆè‹¥è¯æ®å­˜åœ¨ï¼‰ã€‚\n  4) å°èŠ‚æ’åºæŒ‰â€œç ”ç©¶æ•°é‡Ã—å½±å“åŠ›Ã—æ–°è¿‘æ€§â€ç»¼åˆé™åºï¼›æ ‡é¢˜ç”¨å¯è¯»çš„ä¸»é¢˜åï¼Œä¸ä½¿ç”¨æ¨¡æ¿åŒ–è¯æ±‡ã€‚\n- åˆå¹¶ä¸æ‹†åˆ†é˜ˆå€¼ï¼š  \n  - å•ä¸€ `###` å°èŠ‚è‹¥æ¡ç›®>10ï¼ŒæŒ‰æœºåˆ¶/åœºæ™¯/äººç¾¤æ‹†ä¸ºå¤šä¸ª `####`ï¼›  \n  - å•ä¸€å°èŠ‚æ¡ç›®<3ï¼Œåˆå¹¶è‡³é‚»è¿‘æ›´ä¸Šä½å°èŠ‚ã€‚\n- è¦†ç›–åº¦çº¦æŸï¼š`###/####` å°èŠ‚åˆè®¡è‡³å°‘è¦†ç›–ä¸»è¦ä¸»é¢˜ç°‡çš„70%ã€‚\n\n# æ’°å†™è¦æ±‚\n- æ ‡é¢˜å¿…é¡»â€œæ¥æºäºæ£€ç´¢ä¸»é¢˜â€ï¼Œä¸å¯ç…§æ¬æ¨¡æ¿ï¼›å°èŠ‚æ•°é‡ä¸å‘½åä»¥å®é™…æ£€ç´¢ç»“æœä¸ºå‡†ã€‚\n- å¤§çº²æ¡ç›®ç²¾ç‚¼ï¼ˆâ‰¤30å­—ï¼‰ï¼Œå°½é‡é‡åŒ–å…³é”®æŒ‡æ ‡ï¼ˆå¦‚æ•ˆåº”é‡/é˜ˆå€¼/æ—¶é—´çª—/äººç¾¤ï¼‰ã€‚\n- æœ¯è¯­ä¸­æ–‡ç»Ÿä¸€ï¼Œåº¦é‡å•ä½/ç¼©å†™ä¸€è‡´ï¼›å¯åšç­‰ä»·æ˜ å°„ï¼ˆå¦‚â€œæ•°æ®é‡‡é›†/è´¨æ§â€â†’â€œæ•°æ®é¢„å¤„ç†/è´¨é‡ä¿éšœâ€ï¼‰ã€‚\n- ä¸¥ç¦ç”Ÿæˆä¸ä¸»é¢˜æ— å…³æˆ–æ— æ”¯æ’‘çš„å°èŠ‚/è¦ç‚¹ã€‚\n- ç¦æ­¢åœ¨å¤§çº²çš„æœ«å°¾æ·»åŠ å¼•ç”¨è¯´æ˜å’Œå‚è€ƒæ–‡çŒ®è¯´æ˜ç­‰ä»»ä½•è¯´æ˜ã€‚\n- ç¦æ­¢åœ¨å¤§çº²æ·»åŠ ä»»ä½•å¼•ç”¨è¯´æ˜ï¼Œä»…ç”Ÿæˆã€Markdownå¤§çº²ã€‘ã€‚\n\n\n# å¼ºåˆ¶æ£€ç´¢è¦æ±‚\n- åœ¨å¼€å§‹ç”Ÿæˆå¤§çº²ä¹‹å‰ï¼Œå¿…é¡»è°ƒç”¨ DocumentSearch å·¥å…·è¿›è¡Œç³»ç»Ÿæ€§æ–‡çŒ®æ£€ç´¢\n- æœç´¢å¿…é¡»åŒ…å«ä¸»é¢˜çš„æ ¸å¿ƒå…³é”®è¯åŠå…¶åŒä¹‰è¯ã€ç›¸å…³æœ¯è¯­\n- å¿…é¡»åŸºäºå®é™…æ£€ç´¢åˆ°çš„æ–‡çŒ®è¯æ®æ¥æ„å»ºå¤§çº²ç»“æ„å’Œå†…å®¹\n- ä¸¥ç¦åœ¨æœªæ‰§è¡Œæ£€ç´¢çš„æƒ…å†µä¸‹ç›´æ¥ç”Ÿæˆå¤§çº²\n\n# å·¥ä½œæµç¨‹ï¼ˆå…ˆæ£€ç´¢ï¼Œåå†™ä½œï¼‰\n1) æ£€ç´¢ä¸è¦†ç›–é¢  \n   - ç›®æ ‡ï¼šâ‰¥30ç¯‡å€™é€‰æ–‡çŒ®ï¼›è¿‘5å¹´ä¼˜å…ˆï¼Œä½†éœ€ä¿ç•™é‡Œç¨‹ç¢‘ç ”ç©¶ã€‚  \n   - è®°å½•æ¯æ¡å€™é€‰çš„ä¸»é¢˜ç°‡ã€æ ¸å¿ƒç»“è®ºä¸å¯æå–å®šé‡æŒ‡æ ‡ã€‚\n2) ä¸»é¢˜èšåˆ  \n   - å°†æ‰€æœ‰å€™é€‰æ–‡çŒ®èšåˆä¸ºè‹¥å¹²ä¸»é¢˜ç°‡ã€‚  \n   - ä¾æ®ä¸»é¢˜ç°‡çš„æ•°é‡å’Œé‡è¦æ€§å†³å®šå°èŠ‚ç»“æ„ï¼›ä¸è¶³è€…å¹¶å…¥ç›¸é‚»èŠ‚ã€‚  \n   - ä¸ºæ¯”è¾ƒã€å¼‚è´¨æ€§æ¥æºã€çœŸå®ä¸–ç•Œè¯æ®ã€æ–°å…´æ–¹å‘ä¸ç›‘ç®¡/ä¼¦ç†ç­‰è‡ªåŠ¨é¢„ç•™ä½ç½®ï¼ˆå­˜åœ¨è¯æ®æ—¶ï¼‰ã€‚\n\n# è¾“å‡ºè¦æ±‚\n- ä½¿ç”¨çš„è¯­è¨€æ˜¯: chinese\n- ä»…è¾“å‡ºã€Markdownå¤§çº²ã€‘ï¼Œå±‚çº§ä½¿ç”¨ #/##/###/####ã€‚  \n- æ¯æ¡è¦ç‚¹â‰¤30å­—ã€ä¿¡æ¯å¯†åº¦é«˜ã€å°½é‡é‡åŒ–ã€‚    \n- å¤§çº²æœ€å¥½ä¸å°‘äº10ä¸ªç« èŠ‚ï¼Œä¸å¤šäº15ç« èŠ‚ã€‚\n- ã€å¼ºåˆ¶ã€‘è¾“å‡ºå®Œæˆåç«‹å³ç»“æŸï¼›ç¦æ­¢åœ¨æ–‡æœ«æ·»åŠ â€œå¼•ç”¨è¯´æ˜/å‚è€ƒæ–‡çŒ®/è¯´æ˜/æ³¨é‡Š/Notes/Referencesâ€ç­‰ä»»ä½•è¯´æ˜æ€§æ–‡æœ¬æˆ–æ®µè½ã€‚\n\n# è¾“å‡ºç»“æ„ï¼ˆæ ‡é¢˜ä¸é¡ºåºå¿…é¡»ä¸€è‡´ï¼›åœ¨"..."å¤„æŒ‰è§„åˆ™åŠ¨æ€æ‰©å±•ï¼‰\n# è‡ªåŠ¨ç”Ÿæˆç²¾å‡†æ ‡é¢˜ï¼šä¸åŠ å‰¯æ ‡é¢˜\nä¸‹é¢æ˜¯ä¸€ä¸ªç¤ºä¾‹å¤§çº²ç»“æ„ï¼Œä»…ä¾›å‚è€ƒã€‚å®é™…è¾“å‡ºæ—¶å¿…é¡»æ ¹æ®æ£€ç´¢ç»“æœåŠ¨æ€è°ƒæ•´ç« èŠ‚ä¸å°èŠ‚æ ‡é¢˜ã€æ•°é‡ä¸é¡ºåºã€‚è¾“å‡ºçš„æ—¶å€™å¿…é¡»å¸¦æœ‰æ‰€æ’°å†™çš„å¤§çº²å¯¹åº”çš„æ ‡é¢˜ã€‚\n\n## æ‘˜è¦\n- èƒŒæ™¯ï¼šç ”ç©¶ç°çŠ¶/æœªæ»¡è¶³éœ€æ±‚\n- ç›®çš„ï¼šç»¼è¿°æ—¨åœ¨è§£å†³ä»€ä¹ˆé—®é¢˜\n- æ–¹æ³•ï¼ˆå¯é€‰ï¼‰ï¼šæ£€ç´¢èŒƒå›´/çº³æ’æ ‡å‡†/è¯æ®åˆ†çº§ç®€è¿°\n- ä¸»è¦å‘ç°ï¼šå›´ç»•â€œæŠ€æœ¯/æ–¹æ³•Ã—æœºåˆ¶/åº”ç”¨â€çš„å…³é”®è¿›å±•\n- ç»“è®ºä¸å±•æœ›ï¼šè½¬åŒ–è·¯å¾„/æ ‡å‡†åŒ–æŒ‘æˆ˜/æœªæ¥å‘å±•å‰æ™¯\n- å…³é”®è¯ï¼š3â€“8ä¸ªï¼›åˆ†å·åˆ†éš”\n\n## 1. å¼•è¨€\n### 1.1 xx\n### 1.2 xx\n### 1.3 xx\n...\n\n\nYou are an agent. Your internal name is "outline_agent".\n\n The description about you is "generate outline"'}, {'role': 'user', 'content': 'è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©åœ¨ç³–å°¿ç—…è¶³æºƒç–¡æ²»ç–—ä¸­çš„ä½œç”¨åŠæœºåˆ¶ç ”ç©¶è¿›å±•'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
2025-11-18 15:28:50,443 [DEBUG] 
LiteLLM: Params passed to completion() {'model': 'qwen3', 'functions': None, 'function_call': None, 'temperature': None, 'top_p': None, 'n': None, 'stream': True, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': [{'type': 'function', 'function': {'name': 'DocumentSearch', 'description': '\n    æ ¹æ®å…³é”®è¯æœç´¢æ–‡æ¡£\n    :param keyword: str, æœç´¢çš„ç›¸å…³æ–‡æ¡£çš„å…³é”®è¯\n    :return: è¿”å›æ¯ç¯‡æ–‡æ¡£æ•°æ®\n    ', 'parameters': {'type': 'object', 'properties': {'keyword': {'type': 'string'}}}}}], 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\n/no_think\n# è§’è‰²\nä½ æ˜¯ä¸€åä¸¥è°¨çš„ç»¼è¿°ä½œè€…ä¸å¤šå­¦ç§‘ä¿¡æ¯åˆ†æä¸“å®¶ã€‚å¿…é¡»å…ˆå®Œæˆç³»ç»Ÿæ£€ç´¢ä¸è¯æ®ç­›é€‰ï¼Œå†å¼€å§‹å†™å¤§çº²ã€‚\n\n# ç›®æ ‡\nä»…ç”Ÿæˆã€ä¸­æ–‡Markdownå¤§çº²ã€‘ï¼Œç»“æ„ä¸æ ‡é¢˜å¿…é¡»ä¸¥æ ¼æŒ‰â€œè¾“å‡ºç»“æ„â€ä¸€èŠ‚ï¼›ä¸å†™æ­£æ–‡ã€ä¸åŠ URLã€ä¸è¾“å‡ºå¤šä½™å†…å®¹ã€‚\n\n# ä»¥æ£€ç´¢ç»“æœé©±åŠ¨çš„åŠ¨æ€æ‰©å±•ï¼ˆæ ¸å¿ƒå¼ºåŒ–ï¼‰\n- ä»¥â€œä¸»é¢˜ç°‡â€ä¸ºæœ€å°å•å…ƒï¼šåŸºäºæ£€ç´¢ç»“æœå°†æ–‡çŒ®æˆ–æŠ¥å‘Šèšç±»ä¸ºä¸»é¢˜ç°‡ï¼ˆå¦‚æœºåˆ¶ã€æ–¹æ³•å­¦ã€äºšå‹ã€åº”ç”¨åœºæ™¯ã€å½±å“å› ç´ ã€ç»ˆç‚¹ã€å®‰å…¨æ€§ã€ç»æµå­¦ã€ç›‘ç®¡ç­‰ï¼‰ã€‚\n- æ‰©å±•è§„åˆ™ï¼ˆå†³å®šå°èŠ‚æ•°é‡ä¸å‘½åï¼‰ï¼š\n  1) å½“æŸä¸»é¢˜ç°‡æœ‰è¾ƒå¤šç ”ç©¶/æŒ‡å—/æŠ¥å‘Šæ”¯æŒæ—¶ï¼Œåˆ›å»ºç‹¬ç«‹ `###` å°èŠ‚ã€‚\n  2) è‹¥æŸä¸»é¢˜ç°‡æ¶‰åŠçš„ç ”ç©¶æ•°é‡è¾ƒå°‘ï¼Œåˆ™åˆå¹¶åˆ°é‚»è¿‘ `####` åˆ†èŠ‚ï¼›é¿å…ç”Ÿæˆç©ºæ´å°èŠ‚ã€‚\n  3) å¯¹â€œæ¯”è¾ƒ/ä¸€è‡´æ€§-å·®å¼‚/äº‰è®®ç‚¹â€â€œäºšç»„/ç‰¹å®šåº”ç”¨åœºæ™¯â€â€œçœŸå®ä¸–ç•Œè¯æ®/ç°åœºå®è·µâ€â€œæ–¹æ³•å­¦è´¨é‡ä¸åå€šâ€â€œæ ‡å‡†åŒ–ä¸ç›‘ç®¡/ä¼¦ç†/å…¬å¹³æ€§â€ä¼˜å…ˆå»ºèŠ‚ï¼ˆè‹¥è¯æ®å­˜åœ¨ï¼‰ã€‚\n  4) å°èŠ‚æ’åºæŒ‰â€œç ”ç©¶æ•°é‡Ã—å½±å“åŠ›Ã—æ–°è¿‘æ€§â€ç»¼åˆé™åºï¼›æ ‡é¢˜ç”¨å¯è¯»çš„ä¸»é¢˜åï¼Œä¸ä½¿ç”¨æ¨¡æ¿åŒ–è¯æ±‡ã€‚\n- åˆå¹¶ä¸æ‹†åˆ†é˜ˆå€¼ï¼š  \n  - å•ä¸€ `###` å°èŠ‚è‹¥æ¡ç›®>10ï¼ŒæŒ‰æœºåˆ¶/åœºæ™¯/äººç¾¤æ‹†ä¸ºå¤šä¸ª `####`ï¼›  \n  - å•ä¸€å°èŠ‚æ¡ç›®<3ï¼Œåˆå¹¶è‡³é‚»è¿‘æ›´ä¸Šä½å°èŠ‚ã€‚\n- è¦†ç›–åº¦çº¦æŸï¼š`###/####` å°èŠ‚åˆè®¡è‡³å°‘è¦†ç›–ä¸»è¦ä¸»é¢˜ç°‡çš„70%ã€‚\n\n# æ’°å†™è¦æ±‚\n- æ ‡é¢˜å¿…é¡»â€œæ¥æºäºæ£€ç´¢ä¸»é¢˜â€ï¼Œä¸å¯ç…§æ¬æ¨¡æ¿ï¼›å°èŠ‚æ•°é‡ä¸å‘½åä»¥å®é™…æ£€ç´¢ç»“æœä¸ºå‡†ã€‚\n- å¤§çº²æ¡ç›®ç²¾ç‚¼ï¼ˆâ‰¤30å­—ï¼‰ï¼Œå°½é‡é‡åŒ–å…³é”®æŒ‡æ ‡ï¼ˆå¦‚æ•ˆåº”é‡/é˜ˆå€¼/æ—¶é—´çª—/äººç¾¤ï¼‰ã€‚\n- æœ¯è¯­ä¸­æ–‡ç»Ÿä¸€ï¼Œåº¦é‡å•ä½/ç¼©å†™ä¸€è‡´ï¼›å¯åšç­‰ä»·æ˜ å°„ï¼ˆå¦‚â€œæ•°æ®é‡‡é›†/è´¨æ§â€â†’â€œæ•°æ®é¢„å¤„ç†/è´¨é‡ä¿éšœâ€ï¼‰ã€‚\n- ä¸¥ç¦ç”Ÿæˆä¸ä¸»é¢˜æ— å…³æˆ–æ— æ”¯æ’‘çš„å°èŠ‚/è¦ç‚¹ã€‚\n- ç¦æ­¢åœ¨å¤§çº²çš„æœ«å°¾æ·»åŠ å¼•ç”¨è¯´æ˜å’Œå‚è€ƒæ–‡çŒ®è¯´æ˜ç­‰ä»»ä½•è¯´æ˜ã€‚\n- ç¦æ­¢åœ¨å¤§çº²æ·»åŠ ä»»ä½•å¼•ç”¨è¯´æ˜ï¼Œä»…ç”Ÿæˆã€Markdownå¤§çº²ã€‘ã€‚\n\n\n# å¼ºåˆ¶æ£€ç´¢è¦æ±‚\n- åœ¨å¼€å§‹ç”Ÿæˆå¤§çº²ä¹‹å‰ï¼Œå¿…é¡»è°ƒç”¨ DocumentSearch å·¥å…·è¿›è¡Œç³»ç»Ÿæ€§æ–‡çŒ®æ£€ç´¢\n- æœç´¢å¿…é¡»åŒ…å«ä¸»é¢˜çš„æ ¸å¿ƒå…³é”®è¯åŠå…¶åŒä¹‰è¯ã€ç›¸å…³æœ¯è¯­\n- å¿…é¡»åŸºäºå®é™…æ£€ç´¢åˆ°çš„æ–‡çŒ®è¯æ®æ¥æ„å»ºå¤§çº²ç»“æ„å’Œå†…å®¹\n- ä¸¥ç¦åœ¨æœªæ‰§è¡Œæ£€ç´¢çš„æƒ…å†µä¸‹ç›´æ¥ç”Ÿæˆå¤§çº²\n\n# å·¥ä½œæµç¨‹ï¼ˆå…ˆæ£€ç´¢ï¼Œåå†™ä½œï¼‰\n1) æ£€ç´¢ä¸è¦†ç›–é¢  \n   - ç›®æ ‡ï¼šâ‰¥30ç¯‡å€™é€‰æ–‡çŒ®ï¼›è¿‘5å¹´ä¼˜å…ˆï¼Œä½†éœ€ä¿ç•™é‡Œç¨‹ç¢‘ç ”ç©¶ã€‚  \n   - è®°å½•æ¯æ¡å€™é€‰çš„ä¸»é¢˜ç°‡ã€æ ¸å¿ƒç»“è®ºä¸å¯æå–å®šé‡æŒ‡æ ‡ã€‚\n2) ä¸»é¢˜èšåˆ  \n   - å°†æ‰€æœ‰å€™é€‰æ–‡çŒ®èšåˆä¸ºè‹¥å¹²ä¸»é¢˜ç°‡ã€‚  \n   - ä¾æ®ä¸»é¢˜ç°‡çš„æ•°é‡å’Œé‡è¦æ€§å†³å®šå°èŠ‚ç»“æ„ï¼›ä¸è¶³è€…å¹¶å…¥ç›¸é‚»èŠ‚ã€‚  \n   - ä¸ºæ¯”è¾ƒã€å¼‚è´¨æ€§æ¥æºã€çœŸå®ä¸–ç•Œè¯æ®ã€æ–°å…´æ–¹å‘ä¸ç›‘ç®¡/ä¼¦ç†ç­‰è‡ªåŠ¨é¢„ç•™ä½ç½®ï¼ˆå­˜åœ¨è¯æ®æ—¶ï¼‰ã€‚\n\n# è¾“å‡ºè¦æ±‚\n- ä½¿ç”¨çš„è¯­è¨€æ˜¯: chinese\n- ä»…è¾“å‡ºã€Markdownå¤§çº²ã€‘ï¼Œå±‚çº§ä½¿ç”¨ #/##/###/####ã€‚  \n- æ¯æ¡è¦ç‚¹â‰¤30å­—ã€ä¿¡æ¯å¯†åº¦é«˜ã€å°½é‡é‡åŒ–ã€‚    \n- å¤§çº²æœ€å¥½ä¸å°‘äº10ä¸ªç« èŠ‚ï¼Œä¸å¤šäº15ç« èŠ‚ã€‚\n- ã€å¼ºåˆ¶ã€‘è¾“å‡ºå®Œæˆåç«‹å³ç»“æŸï¼›ç¦æ­¢åœ¨æ–‡æœ«æ·»åŠ â€œå¼•ç”¨è¯´æ˜/å‚è€ƒæ–‡çŒ®/è¯´æ˜/æ³¨é‡Š/Notes/Referencesâ€ç­‰ä»»ä½•è¯´æ˜æ€§æ–‡æœ¬æˆ–æ®µè½ã€‚\n\n# è¾“å‡ºç»“æ„ï¼ˆæ ‡é¢˜ä¸é¡ºåºå¿…é¡»ä¸€è‡´ï¼›åœ¨"..."å¤„æŒ‰è§„åˆ™åŠ¨æ€æ‰©å±•ï¼‰\n# è‡ªåŠ¨ç”Ÿæˆç²¾å‡†æ ‡é¢˜ï¼šä¸åŠ å‰¯æ ‡é¢˜\nä¸‹é¢æ˜¯ä¸€ä¸ªç¤ºä¾‹å¤§çº²ç»“æ„ï¼Œä»…ä¾›å‚è€ƒã€‚å®é™…è¾“å‡ºæ—¶å¿…é¡»æ ¹æ®æ£€ç´¢ç»“æœåŠ¨æ€è°ƒæ•´ç« èŠ‚ä¸å°èŠ‚æ ‡é¢˜ã€æ•°é‡ä¸é¡ºåºã€‚è¾“å‡ºçš„æ—¶å€™å¿…é¡»å¸¦æœ‰æ‰€æ’°å†™çš„å¤§çº²å¯¹åº”çš„æ ‡é¢˜ã€‚\n\n## æ‘˜è¦\n- èƒŒæ™¯ï¼šç ”ç©¶ç°çŠ¶/æœªæ»¡è¶³éœ€æ±‚\n- ç›®çš„ï¼šç»¼è¿°æ—¨åœ¨è§£å†³ä»€ä¹ˆé—®é¢˜\n- æ–¹æ³•ï¼ˆå¯é€‰ï¼‰ï¼šæ£€ç´¢èŒƒå›´/çº³æ’æ ‡å‡†/è¯æ®åˆ†çº§ç®€è¿°\n- ä¸»è¦å‘ç°ï¼šå›´ç»•â€œæŠ€æœ¯/æ–¹æ³•Ã—æœºåˆ¶/åº”ç”¨â€çš„å…³é”®è¿›å±•\n- ç»“è®ºä¸å±•æœ›ï¼šè½¬åŒ–è·¯å¾„/æ ‡å‡†åŒ–æŒ‘æˆ˜/æœªæ¥å‘å±•å‰æ™¯\n- å…³é”®è¯ï¼š3â€“8ä¸ªï¼›åˆ†å·åˆ†éš”\n\n## 1. å¼•è¨€\n### 1.1 xx\n### 1.2 xx\n### 1.3 xx\n...\n\n\nYou are an agent. Your internal name is "outline_agent".\n\n The description about you is "generate outline"'}, {'role': 'user', 'content': 'è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©åœ¨ç³–å°¿ç—…è¶³æºƒç–¡æ²»ç–—ä¸­çš„ä½œç”¨åŠæœºåˆ¶ç ”ç©¶è¿›å±•'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
[92m15:28:50 - LiteLLM:DEBUG[0m: utils.py:3428 - 
LiteLLM: Non-Default params passed to completion() {'stream': True, 'tools': [{'type': 'function', 'function': {'name': 'DocumentSearch', 'description': '\n    æ ¹æ®å…³é”®è¯æœç´¢æ–‡æ¡£\n    :param keyword: str, æœç´¢çš„ç›¸å…³æ–‡æ¡£çš„å…³é”®è¯\n    :return: è¿”å›æ¯ç¯‡æ–‡æ¡£æ•°æ®\n    ', 'parameters': {'type': 'object', 'properties': {'keyword': {'type': 'string'}}}}}]}
2025-11-18 15:28:50,444 [DEBUG] 
LiteLLM: Non-Default params passed to completion() {'stream': True, 'tools': [{'type': 'function', 'function': {'name': 'DocumentSearch', 'description': '\n    æ ¹æ®å…³é”®è¯æœç´¢æ–‡æ¡£\n    :param keyword: str, æœç´¢çš„ç›¸å…³æ–‡æ¡£çš„å…³é”®è¯\n    :return: è¿”å›æ¯ç¯‡æ–‡æ¡£æ•°æ®\n    ', 'parameters': {'type': 'object', 'properties': {'keyword': {'type': 'string'}}}}}]}
[92m15:28:50 - LiteLLM:DEBUG[0m: utils.py:376 - Final returned optional params: {'stream': True, 'tools': [{'type': 'function', 'function': {'name': 'DocumentSearch', 'description': '\n    æ ¹æ®å…³é”®è¯æœç´¢æ–‡æ¡£\n    :param keyword: str, æœç´¢çš„ç›¸å…³æ–‡æ¡£çš„å…³é”®è¯\n    :return: è¿”å›æ¯ç¯‡æ–‡æ¡£æ•°æ®\n    ', 'parameters': {'type': 'object', 'properties': {'keyword': {'type': 'string'}}}}}], 'extra_body': {}}
2025-11-18 15:28:50,444 [DEBUG] Final returned optional params: {'stream': True, 'tools': [{'type': 'function', 'function': {'name': 'DocumentSearch', 'description': '\n    æ ¹æ®å…³é”®è¯æœç´¢æ–‡æ¡£\n    :param keyword: str, æœç´¢çš„ç›¸å…³æ–‡æ¡£çš„å…³é”®è¯\n    :return: è¿”å›æ¯ç¯‡æ–‡æ¡£æ•°æ®\n    ', 'parameters': {'type': 'object', 'properties': {'keyword': {'type': 'string'}}}}}], 'extra_body': {}}
[92m15:28:50 - LiteLLM:DEBUG[0m: litellm_logging.py:490 - self.optional_params: {'stream': True, 'tools': [{'type': 'function', 'function': {'name': 'DocumentSearch', 'description': '\n    æ ¹æ®å…³é”®è¯æœç´¢æ–‡æ¡£\n    :param keyword: str, æœç´¢çš„ç›¸å…³æ–‡æ¡£çš„å…³é”®è¯\n    :return: è¿”å›æ¯ç¯‡æ–‡æ¡£æ•°æ®\n    ', 'parameters': {'type': 'object', 'properties': {'keyword': {'type': 'string'}}}}}], 'extra_body': {}}
2025-11-18 15:28:50,444 [DEBUG] self.optional_params: {'stream': True, 'tools': [{'type': 'function', 'function': {'name': 'DocumentSearch', 'description': '\n    æ ¹æ®å…³é”®è¯æœç´¢æ–‡æ¡£\n    :param keyword: str, æœç´¢çš„ç›¸å…³æ–‡æ¡£çš„å…³é”®è¯\n    :return: è¿”å›æ¯ç¯‡æ–‡æ¡£æ•°æ®\n    ', 'parameters': {'type': 'object', 'properties': {'keyword': {'type': 'string'}}}}}], 'extra_body': {}}
[92m15:28:50 - LiteLLM:DEBUG[0m: utils.py:4823 - checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
2025-11-18 15:28:50,444 [DEBUG] checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
[92m15:28:50 - LiteLLM:DEBUG[0m: utils.py:5073 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-11-18 15:28:50,444 [DEBUG] Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
[92m15:28:50 - LiteLLM:DEBUG[0m: main.py:927 - Error getting model info: This model isn't mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
2025-11-18 15:28:50,444 [DEBUG] Error getting model info: This model isn't mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
[92m15:28:50 - LiteLLM:DEBUG[0m: litellm_logging.py:1036 - RAW RESPONSE:
<coroutine object OpenAIChatCompletion.async_streaming at 0x000001B8E3C34CF0>


2025-11-18 15:28:50,445 [DEBUG] RAW RESPONSE:
<coroutine object OpenAIChatCompletion.async_streaming at 0x000001B8E3C34CF0>


[92m15:28:50 - LiteLLM:DEBUG[0m: http_handler.py:678 - Using AiohttpTransport...
2025-11-18 15:28:50,868 [DEBUG] Using AiohttpTransport...
[92m15:28:50 - LiteLLM:DEBUG[0m: http_handler.py:736 - Creating AiohttpTransport...
2025-11-18 15:28:50,868 [DEBUG] Creating AiohttpTransport...
[92m15:28:50 - LiteLLM:DEBUG[0m: http_handler.py:746 - NEW SESSION: Creating new ClientSession (no shared session provided)
2025-11-18 15:28:50,868 [DEBUG] NEW SESSION: Creating new ClientSession (no shared session provided)
[92m15:28:50 - LiteLLM:DEBUG[0m: litellm_logging.py:963 - [92m

POST Request Sent from LiteLLM:
curl -X POST \
http://192.168.1.13:9997/v1 \
-d '{'model': 'qwen3', 'messages': [{'role': 'system', 'content': '\n/no_think\n# è§’è‰²\nä½ æ˜¯ä¸€åä¸¥è°¨çš„ç»¼è¿°ä½œè€…ä¸å¤šå­¦ç§‘ä¿¡æ¯åˆ†æä¸“å®¶ã€‚å¿…é¡»å…ˆå®Œæˆç³»ç»Ÿæ£€ç´¢ä¸è¯æ®ç­›é€‰ï¼Œå†å¼€å§‹å†™å¤§çº²ã€‚\n\n# ç›®æ ‡\nä»…ç”Ÿæˆã€ä¸­æ–‡Markdownå¤§çº²ã€‘ï¼Œç»“æ„ä¸æ ‡é¢˜å¿…é¡»ä¸¥æ ¼æŒ‰â€œè¾“å‡ºç»“æ„â€ä¸€èŠ‚ï¼›ä¸å†™æ­£æ–‡ã€ä¸åŠ URLã€ä¸è¾“å‡ºå¤šä½™å†…å®¹ã€‚\n\n# ä»¥æ£€ç´¢ç»“æœé©±åŠ¨çš„åŠ¨æ€æ‰©å±•ï¼ˆæ ¸å¿ƒå¼ºåŒ–ï¼‰\n- ä»¥â€œä¸»é¢˜ç°‡â€ä¸ºæœ€å°å•å…ƒï¼šåŸºäºæ£€ç´¢ç»“æœå°†æ–‡çŒ®æˆ–æŠ¥å‘Šèšç±»ä¸ºä¸»é¢˜ç°‡ï¼ˆå¦‚æœºåˆ¶ã€æ–¹æ³•å­¦ã€äºšå‹ã€åº”ç”¨åœºæ™¯ã€å½±å“å› ç´ ã€ç»ˆç‚¹ã€å®‰å…¨æ€§ã€ç»æµå­¦ã€ç›‘ç®¡ç­‰ï¼‰ã€‚\n- æ‰©å±•è§„åˆ™ï¼ˆå†³å®šå°èŠ‚æ•°é‡ä¸å‘½åï¼‰ï¼š\n  1) å½“æŸä¸»é¢˜ç°‡æœ‰è¾ƒå¤šç ”ç©¶/æŒ‡å—/æŠ¥å‘Šæ”¯æŒæ—¶ï¼Œåˆ›å»ºç‹¬ç«‹ `###` å°èŠ‚ã€‚\n  2) è‹¥æŸä¸»é¢˜ç°‡æ¶‰åŠçš„ç ”ç©¶æ•°é‡è¾ƒå°‘ï¼Œåˆ™åˆå¹¶åˆ°é‚»è¿‘ `####` åˆ†èŠ‚ï¼›é¿å…ç”Ÿæˆç©ºæ´å°èŠ‚ã€‚\n  3) å¯¹â€œæ¯”è¾ƒ/ä¸€è‡´æ€§-å·®å¼‚/äº‰è®®ç‚¹â€â€œäºšç»„/ç‰¹å®šåº”ç”¨åœºæ™¯â€â€œçœŸå®ä¸–ç•Œè¯æ®/ç°åœºå®è·µâ€â€œæ–¹æ³•å­¦è´¨é‡ä¸åå€šâ€â€œæ ‡å‡†åŒ–ä¸ç›‘ç®¡/ä¼¦ç†/å…¬å¹³æ€§â€ä¼˜å…ˆå»ºèŠ‚ï¼ˆè‹¥è¯æ®å­˜åœ¨ï¼‰ã€‚\n  4) å°èŠ‚æ’åºæŒ‰â€œç ”ç©¶æ•°é‡Ã—å½±å“åŠ›Ã—æ–°è¿‘æ€§â€ç»¼åˆé™åºï¼›æ ‡é¢˜ç”¨å¯è¯»çš„ä¸»é¢˜åï¼Œä¸ä½¿ç”¨æ¨¡æ¿åŒ–è¯æ±‡ã€‚\n- åˆå¹¶ä¸æ‹†åˆ†é˜ˆå€¼ï¼š  \n  - å•ä¸€ `###` å°èŠ‚è‹¥æ¡ç›®>10ï¼ŒæŒ‰æœºåˆ¶/åœºæ™¯/äººç¾¤æ‹†ä¸ºå¤šä¸ª `####`ï¼›  \n  - å•ä¸€å°èŠ‚æ¡ç›®<3ï¼Œåˆå¹¶è‡³é‚»è¿‘æ›´ä¸Šä½å°èŠ‚ã€‚\n- è¦†ç›–åº¦çº¦æŸï¼š`###/####` å°èŠ‚åˆè®¡è‡³å°‘è¦†ç›–ä¸»è¦ä¸»é¢˜ç°‡çš„70%ã€‚\n\n# æ’°å†™è¦æ±‚\n- æ ‡é¢˜å¿…é¡»â€œæ¥æºäºæ£€ç´¢ä¸»é¢˜â€ï¼Œä¸å¯ç…§æ¬æ¨¡æ¿ï¼›å°èŠ‚æ•°é‡ä¸å‘½åä»¥å®é™…æ£€ç´¢ç»“æœä¸ºå‡†ã€‚\n- å¤§çº²æ¡ç›®ç²¾ç‚¼ï¼ˆâ‰¤30å­—ï¼‰ï¼Œå°½é‡é‡åŒ–å…³é”®æŒ‡æ ‡ï¼ˆå¦‚æ•ˆåº”é‡/é˜ˆå€¼/æ—¶é—´çª—/äººç¾¤ï¼‰ã€‚\n- æœ¯è¯­ä¸­æ–‡ç»Ÿä¸€ï¼Œåº¦é‡å•ä½/ç¼©å†™ä¸€è‡´ï¼›å¯åšç­‰ä»·æ˜ å°„ï¼ˆå¦‚â€œæ•°æ®é‡‡é›†/è´¨æ§â€â†’â€œæ•°æ®é¢„å¤„ç†/è´¨é‡ä¿éšœâ€ï¼‰ã€‚\n- ä¸¥ç¦ç”Ÿæˆä¸ä¸»é¢˜æ— å…³æˆ–æ— æ”¯æ’‘çš„å°èŠ‚/è¦ç‚¹ã€‚\n- ç¦æ­¢åœ¨å¤§çº²çš„æœ«å°¾æ·»åŠ å¼•ç”¨è¯´æ˜å’Œå‚è€ƒæ–‡çŒ®è¯´æ˜ç­‰ä»»ä½•è¯´æ˜ã€‚\n- ç¦æ­¢åœ¨å¤§çº²æ·»åŠ ä»»ä½•å¼•ç”¨è¯´æ˜ï¼Œä»…ç”Ÿæˆã€Markdownå¤§çº²ã€‘ã€‚\n\n\n# å¼ºåˆ¶æ£€ç´¢è¦æ±‚\n- åœ¨å¼€å§‹ç”Ÿæˆå¤§çº²ä¹‹å‰ï¼Œå¿…é¡»è°ƒç”¨ DocumentSearch å·¥å…·è¿›è¡Œç³»ç»Ÿæ€§æ–‡çŒ®æ£€ç´¢\n- æœç´¢å¿…é¡»åŒ…å«ä¸»é¢˜çš„æ ¸å¿ƒå…³é”®è¯åŠå…¶åŒä¹‰è¯ã€ç›¸å…³æœ¯è¯­\n- å¿…é¡»åŸºäºå®é™…æ£€ç´¢åˆ°çš„æ–‡çŒ®è¯æ®æ¥æ„å»ºå¤§çº²ç»“æ„å’Œå†…å®¹\n- ä¸¥ç¦åœ¨æœªæ‰§è¡Œæ£€ç´¢çš„æƒ…å†µä¸‹ç›´æ¥ç”Ÿæˆå¤§çº²\n\n# å·¥ä½œæµç¨‹ï¼ˆå…ˆæ£€ç´¢ï¼Œåå†™ä½œï¼‰\n1) æ£€ç´¢ä¸è¦†ç›–é¢  \n   - ç›®æ ‡ï¼šâ‰¥30ç¯‡å€™é€‰æ–‡çŒ®ï¼›è¿‘5å¹´ä¼˜å…ˆï¼Œä½†éœ€ä¿ç•™é‡Œç¨‹ç¢‘ç ”ç©¶ã€‚  \n   - è®°å½•æ¯æ¡å€™é€‰çš„ä¸»é¢˜ç°‡ã€æ ¸å¿ƒç»“è®ºä¸å¯æå–å®šé‡æŒ‡æ ‡ã€‚\n2) ä¸»é¢˜èšåˆ  \n   - å°†æ‰€æœ‰å€™é€‰æ–‡çŒ®èšåˆä¸ºè‹¥å¹²ä¸»é¢˜ç°‡ã€‚  \n   - ä¾æ®ä¸»é¢˜ç°‡çš„æ•°é‡å’Œé‡è¦æ€§å†³å®šå°èŠ‚ç»“æ„ï¼›ä¸è¶³è€…å¹¶å…¥ç›¸é‚»èŠ‚ã€‚  \n   - ä¸ºæ¯”è¾ƒã€å¼‚è´¨æ€§æ¥æºã€çœŸå®ä¸–ç•Œè¯æ®ã€æ–°å…´æ–¹å‘ä¸ç›‘ç®¡/ä¼¦ç†ç­‰è‡ªåŠ¨é¢„ç•™ä½ç½®ï¼ˆå­˜åœ¨è¯æ®æ—¶ï¼‰ã€‚\n\n# è¾“å‡ºè¦æ±‚\n- ä½¿ç”¨çš„è¯­è¨€æ˜¯: chinese\n- ä»…è¾“å‡ºã€Markdownå¤§çº²ã€‘ï¼Œå±‚çº§ä½¿ç”¨ #/##/###/####ã€‚  \n- æ¯æ¡è¦ç‚¹â‰¤30å­—ã€ä¿¡æ¯å¯†åº¦é«˜ã€å°½é‡é‡åŒ–ã€‚    \n- å¤§çº²æœ€å¥½ä¸å°‘äº10ä¸ªç« èŠ‚ï¼Œä¸å¤šäº15ç« èŠ‚ã€‚\n- ã€å¼ºåˆ¶ã€‘è¾“å‡ºå®Œæˆåç«‹å³ç»“æŸï¼›ç¦æ­¢åœ¨æ–‡æœ«æ·»åŠ â€œå¼•ç”¨è¯´æ˜/å‚è€ƒæ–‡çŒ®/è¯´æ˜/æ³¨é‡Š/Notes/Referencesâ€ç­‰ä»»ä½•è¯´æ˜æ€§æ–‡æœ¬æˆ–æ®µè½ã€‚\n\n# è¾“å‡ºç»“æ„ï¼ˆæ ‡é¢˜ä¸é¡ºåºå¿…é¡»ä¸€è‡´ï¼›åœ¨"..."å¤„æŒ‰è§„åˆ™åŠ¨æ€æ‰©å±•ï¼‰\n# è‡ªåŠ¨ç”Ÿæˆç²¾å‡†æ ‡é¢˜ï¼šä¸åŠ å‰¯æ ‡é¢˜\nä¸‹é¢æ˜¯ä¸€ä¸ªç¤ºä¾‹å¤§çº²ç»“æ„ï¼Œä»…ä¾›å‚è€ƒã€‚å®é™…è¾“å‡ºæ—¶å¿…é¡»æ ¹æ®æ£€ç´¢ç»“æœåŠ¨æ€è°ƒæ•´ç« èŠ‚ä¸å°èŠ‚æ ‡é¢˜ã€æ•°é‡ä¸é¡ºåºã€‚è¾“å‡ºçš„æ—¶å€™å¿…é¡»å¸¦æœ‰æ‰€æ’°å†™çš„å¤§çº²å¯¹åº”çš„æ ‡é¢˜ã€‚\n\n## æ‘˜è¦\n- èƒŒæ™¯ï¼šç ”ç©¶ç°çŠ¶/æœªæ»¡è¶³éœ€æ±‚\n- ç›®çš„ï¼šç»¼è¿°æ—¨åœ¨è§£å†³ä»€ä¹ˆé—®é¢˜\n- æ–¹æ³•ï¼ˆå¯é€‰ï¼‰ï¼šæ£€ç´¢èŒƒå›´/çº³æ’æ ‡å‡†/è¯æ®åˆ†çº§ç®€è¿°\n- ä¸»è¦å‘ç°ï¼šå›´ç»•â€œæŠ€æœ¯/æ–¹æ³•Ã—æœºåˆ¶/åº”ç”¨â€çš„å…³é”®è¿›å±•\n- ç»“è®ºä¸å±•æœ›ï¼šè½¬åŒ–è·¯å¾„/æ ‡å‡†åŒ–æŒ‘æˆ˜/æœªæ¥å‘å±•å‰æ™¯\n- å…³é”®è¯ï¼š3â€“8ä¸ªï¼›åˆ†å·åˆ†éš”\n\n## 1. å¼•è¨€\n### 1.1 xx\n### 1.2 xx\n### 1.3 xx\n...\n\n\nYou are an agent. Your internal name is "outline_agent".\n\n The description about you is "generate outline"'}, {'role': 'user', 'content': 'è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©åœ¨ç³–å°¿ç—…è¶³æºƒç–¡æ²»ç–—ä¸­çš„ä½œç”¨åŠæœºåˆ¶ç ”ç©¶è¿›å±•'}], 'tools': [{'type': 'function', 'function': {'name': 'DocumentSearch', 'description': '\n    æ ¹æ®å…³é”®è¯æœç´¢æ–‡æ¡£\n    :param keyword: str, æœç´¢çš„ç›¸å…³æ–‡æ¡£çš„å…³é”®è¯\n    :return: è¿”å›æ¯ç¯‡æ–‡æ¡£æ•°æ®\n    ', 'parameters': {'type': 'object', 'properties': {'keyword': {'type': 'string'}}}}}], 'extra_body': {}, 'stream': True}'
[0m

2025-11-18 15:28:50,869 [DEBUG] [92m

POST Request Sent from LiteLLM:
curl -X POST \
http://192.168.1.13:9997/v1 \
-d '{'model': 'qwen3', 'messages': [{'role': 'system', 'content': '\n/no_think\n# è§’è‰²\nä½ æ˜¯ä¸€åä¸¥è°¨çš„ç»¼è¿°ä½œè€…ä¸å¤šå­¦ç§‘ä¿¡æ¯åˆ†æä¸“å®¶ã€‚å¿…é¡»å…ˆå®Œæˆç³»ç»Ÿæ£€ç´¢ä¸è¯æ®ç­›é€‰ï¼Œå†å¼€å§‹å†™å¤§çº²ã€‚\n\n# ç›®æ ‡\nä»…ç”Ÿæˆã€ä¸­æ–‡Markdownå¤§çº²ã€‘ï¼Œç»“æ„ä¸æ ‡é¢˜å¿…é¡»ä¸¥æ ¼æŒ‰â€œè¾“å‡ºç»“æ„â€ä¸€èŠ‚ï¼›ä¸å†™æ­£æ–‡ã€ä¸åŠ URLã€ä¸è¾“å‡ºå¤šä½™å†…å®¹ã€‚\n\n# ä»¥æ£€ç´¢ç»“æœé©±åŠ¨çš„åŠ¨æ€æ‰©å±•ï¼ˆæ ¸å¿ƒå¼ºåŒ–ï¼‰\n- ä»¥â€œä¸»é¢˜ç°‡â€ä¸ºæœ€å°å•å…ƒï¼šåŸºäºæ£€ç´¢ç»“æœå°†æ–‡çŒ®æˆ–æŠ¥å‘Šèšç±»ä¸ºä¸»é¢˜ç°‡ï¼ˆå¦‚æœºåˆ¶ã€æ–¹æ³•å­¦ã€äºšå‹ã€åº”ç”¨åœºæ™¯ã€å½±å“å› ç´ ã€ç»ˆç‚¹ã€å®‰å…¨æ€§ã€ç»æµå­¦ã€ç›‘ç®¡ç­‰ï¼‰ã€‚\n- æ‰©å±•è§„åˆ™ï¼ˆå†³å®šå°èŠ‚æ•°é‡ä¸å‘½åï¼‰ï¼š\n  1) å½“æŸä¸»é¢˜ç°‡æœ‰è¾ƒå¤šç ”ç©¶/æŒ‡å—/æŠ¥å‘Šæ”¯æŒæ—¶ï¼Œåˆ›å»ºç‹¬ç«‹ `###` å°èŠ‚ã€‚\n  2) è‹¥æŸä¸»é¢˜ç°‡æ¶‰åŠçš„ç ”ç©¶æ•°é‡è¾ƒå°‘ï¼Œåˆ™åˆå¹¶åˆ°é‚»è¿‘ `####` åˆ†èŠ‚ï¼›é¿å…ç”Ÿæˆç©ºæ´å°èŠ‚ã€‚\n  3) å¯¹â€œæ¯”è¾ƒ/ä¸€è‡´æ€§-å·®å¼‚/äº‰è®®ç‚¹â€â€œäºšç»„/ç‰¹å®šåº”ç”¨åœºæ™¯â€â€œçœŸå®ä¸–ç•Œè¯æ®/ç°åœºå®è·µâ€â€œæ–¹æ³•å­¦è´¨é‡ä¸åå€šâ€â€œæ ‡å‡†åŒ–ä¸ç›‘ç®¡/ä¼¦ç†/å…¬å¹³æ€§â€ä¼˜å…ˆå»ºèŠ‚ï¼ˆè‹¥è¯æ®å­˜åœ¨ï¼‰ã€‚\n  4) å°èŠ‚æ’åºæŒ‰â€œç ”ç©¶æ•°é‡Ã—å½±å“åŠ›Ã—æ–°è¿‘æ€§â€ç»¼åˆé™åºï¼›æ ‡é¢˜ç”¨å¯è¯»çš„ä¸»é¢˜åï¼Œä¸ä½¿ç”¨æ¨¡æ¿åŒ–è¯æ±‡ã€‚\n- åˆå¹¶ä¸æ‹†åˆ†é˜ˆå€¼ï¼š  \n  - å•ä¸€ `###` å°èŠ‚è‹¥æ¡ç›®>10ï¼ŒæŒ‰æœºåˆ¶/åœºæ™¯/äººç¾¤æ‹†ä¸ºå¤šä¸ª `####`ï¼›  \n  - å•ä¸€å°èŠ‚æ¡ç›®<3ï¼Œåˆå¹¶è‡³é‚»è¿‘æ›´ä¸Šä½å°èŠ‚ã€‚\n- è¦†ç›–åº¦çº¦æŸï¼š`###/####` å°èŠ‚åˆè®¡è‡³å°‘è¦†ç›–ä¸»è¦ä¸»é¢˜ç°‡çš„70%ã€‚\n\n# æ’°å†™è¦æ±‚\n- æ ‡é¢˜å¿…é¡»â€œæ¥æºäºæ£€ç´¢ä¸»é¢˜â€ï¼Œä¸å¯ç…§æ¬æ¨¡æ¿ï¼›å°èŠ‚æ•°é‡ä¸å‘½åä»¥å®é™…æ£€ç´¢ç»“æœä¸ºå‡†ã€‚\n- å¤§çº²æ¡ç›®ç²¾ç‚¼ï¼ˆâ‰¤30å­—ï¼‰ï¼Œå°½é‡é‡åŒ–å…³é”®æŒ‡æ ‡ï¼ˆå¦‚æ•ˆåº”é‡/é˜ˆå€¼/æ—¶é—´çª—/äººç¾¤ï¼‰ã€‚\n- æœ¯è¯­ä¸­æ–‡ç»Ÿä¸€ï¼Œåº¦é‡å•ä½/ç¼©å†™ä¸€è‡´ï¼›å¯åšç­‰ä»·æ˜ å°„ï¼ˆå¦‚â€œæ•°æ®é‡‡é›†/è´¨æ§â€â†’â€œæ•°æ®é¢„å¤„ç†/è´¨é‡ä¿éšœâ€ï¼‰ã€‚\n- ä¸¥ç¦ç”Ÿæˆä¸ä¸»é¢˜æ— å…³æˆ–æ— æ”¯æ’‘çš„å°èŠ‚/è¦ç‚¹ã€‚\n- ç¦æ­¢åœ¨å¤§çº²çš„æœ«å°¾æ·»åŠ å¼•ç”¨è¯´æ˜å’Œå‚è€ƒæ–‡çŒ®è¯´æ˜ç­‰ä»»ä½•è¯´æ˜ã€‚\n- ç¦æ­¢åœ¨å¤§çº²æ·»åŠ ä»»ä½•å¼•ç”¨è¯´æ˜ï¼Œä»…ç”Ÿæˆã€Markdownå¤§çº²ã€‘ã€‚\n\n\n# å¼ºåˆ¶æ£€ç´¢è¦æ±‚\n- åœ¨å¼€å§‹ç”Ÿæˆå¤§çº²ä¹‹å‰ï¼Œå¿…é¡»è°ƒç”¨ DocumentSearch å·¥å…·è¿›è¡Œç³»ç»Ÿæ€§æ–‡çŒ®æ£€ç´¢\n- æœç´¢å¿…é¡»åŒ…å«ä¸»é¢˜çš„æ ¸å¿ƒå…³é”®è¯åŠå…¶åŒä¹‰è¯ã€ç›¸å…³æœ¯è¯­\n- å¿…é¡»åŸºäºå®é™…æ£€ç´¢åˆ°çš„æ–‡çŒ®è¯æ®æ¥æ„å»ºå¤§çº²ç»“æ„å’Œå†…å®¹\n- ä¸¥ç¦åœ¨æœªæ‰§è¡Œæ£€ç´¢çš„æƒ…å†µä¸‹ç›´æ¥ç”Ÿæˆå¤§çº²\n\n# å·¥ä½œæµç¨‹ï¼ˆå…ˆæ£€ç´¢ï¼Œåå†™ä½œï¼‰\n1) æ£€ç´¢ä¸è¦†ç›–é¢  \n   - ç›®æ ‡ï¼šâ‰¥30ç¯‡å€™é€‰æ–‡çŒ®ï¼›è¿‘5å¹´ä¼˜å…ˆï¼Œä½†éœ€ä¿ç•™é‡Œç¨‹ç¢‘ç ”ç©¶ã€‚  \n   - è®°å½•æ¯æ¡å€™é€‰çš„ä¸»é¢˜ç°‡ã€æ ¸å¿ƒç»“è®ºä¸å¯æå–å®šé‡æŒ‡æ ‡ã€‚\n2) ä¸»é¢˜èšåˆ  \n   - å°†æ‰€æœ‰å€™é€‰æ–‡çŒ®èšåˆä¸ºè‹¥å¹²ä¸»é¢˜ç°‡ã€‚  \n   - ä¾æ®ä¸»é¢˜ç°‡çš„æ•°é‡å’Œé‡è¦æ€§å†³å®šå°èŠ‚ç»“æ„ï¼›ä¸è¶³è€…å¹¶å…¥ç›¸é‚»èŠ‚ã€‚  \n   - ä¸ºæ¯”è¾ƒã€å¼‚è´¨æ€§æ¥æºã€çœŸå®ä¸–ç•Œè¯æ®ã€æ–°å…´æ–¹å‘ä¸ç›‘ç®¡/ä¼¦ç†ç­‰è‡ªåŠ¨é¢„ç•™ä½ç½®ï¼ˆå­˜åœ¨è¯æ®æ—¶ï¼‰ã€‚\n\n# è¾“å‡ºè¦æ±‚\n- ä½¿ç”¨çš„è¯­è¨€æ˜¯: chinese\n- ä»…è¾“å‡ºã€Markdownå¤§çº²ã€‘ï¼Œå±‚çº§ä½¿ç”¨ #/##/###/####ã€‚  \n- æ¯æ¡è¦ç‚¹â‰¤30å­—ã€ä¿¡æ¯å¯†åº¦é«˜ã€å°½é‡é‡åŒ–ã€‚    \n- å¤§çº²æœ€å¥½ä¸å°‘äº10ä¸ªç« èŠ‚ï¼Œä¸å¤šäº15ç« èŠ‚ã€‚\n- ã€å¼ºåˆ¶ã€‘è¾“å‡ºå®Œæˆåç«‹å³ç»“æŸï¼›ç¦æ­¢åœ¨æ–‡æœ«æ·»åŠ â€œå¼•ç”¨è¯´æ˜/å‚è€ƒæ–‡çŒ®/è¯´æ˜/æ³¨é‡Š/Notes/Referencesâ€ç­‰ä»»ä½•è¯´æ˜æ€§æ–‡æœ¬æˆ–æ®µè½ã€‚\n\n# è¾“å‡ºç»“æ„ï¼ˆæ ‡é¢˜ä¸é¡ºåºå¿…é¡»ä¸€è‡´ï¼›åœ¨"..."å¤„æŒ‰è§„åˆ™åŠ¨æ€æ‰©å±•ï¼‰\n# è‡ªåŠ¨ç”Ÿæˆç²¾å‡†æ ‡é¢˜ï¼šä¸åŠ å‰¯æ ‡é¢˜\nä¸‹é¢æ˜¯ä¸€ä¸ªç¤ºä¾‹å¤§çº²ç»“æ„ï¼Œä»…ä¾›å‚è€ƒã€‚å®é™…è¾“å‡ºæ—¶å¿…é¡»æ ¹æ®æ£€ç´¢ç»“æœåŠ¨æ€è°ƒæ•´ç« èŠ‚ä¸å°èŠ‚æ ‡é¢˜ã€æ•°é‡ä¸é¡ºåºã€‚è¾“å‡ºçš„æ—¶å€™å¿…é¡»å¸¦æœ‰æ‰€æ’°å†™çš„å¤§çº²å¯¹åº”çš„æ ‡é¢˜ã€‚\n\n## æ‘˜è¦\n- èƒŒæ™¯ï¼šç ”ç©¶ç°çŠ¶/æœªæ»¡è¶³éœ€æ±‚\n- ç›®çš„ï¼šç»¼è¿°æ—¨åœ¨è§£å†³ä»€ä¹ˆé—®é¢˜\n- æ–¹æ³•ï¼ˆå¯é€‰ï¼‰ï¼šæ£€ç´¢èŒƒå›´/çº³æ’æ ‡å‡†/è¯æ®åˆ†çº§ç®€è¿°\n- ä¸»è¦å‘ç°ï¼šå›´ç»•â€œæŠ€æœ¯/æ–¹æ³•Ã—æœºåˆ¶/åº”ç”¨â€çš„å…³é”®è¿›å±•\n- ç»“è®ºä¸å±•æœ›ï¼šè½¬åŒ–è·¯å¾„/æ ‡å‡†åŒ–æŒ‘æˆ˜/æœªæ¥å‘å±•å‰æ™¯\n- å…³é”®è¯ï¼š3â€“8ä¸ªï¼›åˆ†å·åˆ†éš”\n\n## 1. å¼•è¨€\n### 1.1 xx\n### 1.2 xx\n### 1.3 xx\n...\n\n\nYou are an agent. Your internal name is "outline_agent".\n\n The description about you is "generate outline"'}, {'role': 'user', 'content': 'è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©åœ¨ç³–å°¿ç—…è¶³æºƒç–¡æ²»ç–—ä¸­çš„ä½œç”¨åŠæœºåˆ¶ç ”ç©¶è¿›å±•'}], 'tools': [{'type': 'function', 'function': {'name': 'DocumentSearch', 'description': '\n    æ ¹æ®å…³é”®è¯æœç´¢æ–‡æ¡£\n    :param keyword: str, æœç´¢çš„ç›¸å…³æ–‡æ¡£çš„å…³é”®è¯\n    :return: è¿”å›æ¯ç¯‡æ–‡æ¡£æ•°æ®\n    ', 'parameters': {'type': 'object', 'properties': {'keyword': {'type': 'string'}}}}}], 'extra_body': {}, 'stream': True}'
[0m

[92m15:28:51 - LiteLLM:DEBUG[0m: cost_calculator.py:833 - selected model name for cost calculation: openai/qwen3
2025-11-18 15:28:51,361 [DEBUG] selected model name for cost calculation: openai/qwen3
[92m15:28:51 - LiteLLM:DEBUG[0m: token_counter.py:374 - messages in token_counter: None, text in token_counter: 
2025-11-18 15:28:51,361 [DEBUG] messages in token_counter: None, text in token_counter: 
[92m15:28:51 - LiteLLM:DEBUG[0m: utils.py:4823 - checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
2025-11-18 15:28:51,362 [DEBUG] checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
[92m15:28:51 - LiteLLM:DEBUG[0m: utils.py:5073 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-11-18 15:28:51,362 [DEBUG] Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
[92m15:28:51 - LiteLLM:DEBUG[0m: cost_calculator.py:1149 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=openai/qwen3 - This model isn't mapped yet. model=openai/qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
2025-11-18 15:28:51,362 [DEBUG] litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=openai/qwen3 - This model isn't mapped yet. model=openai/qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
[92m15:28:51 - LiteLLM:DEBUG[0m: cost_calculator.py:833 - selected model name for cost calculation: openai/qwen3
2025-11-18 15:28:51,362 [DEBUG] selected model name for cost calculation: openai/qwen3
[92m15:28:51 - LiteLLM:DEBUG[0m: token_counter.py:374 - messages in token_counter: None, text in token_counter: 
2025-11-18 15:28:51,362 [DEBUG] messages in token_counter: None, text in token_counter: 
[92m15:28:51 - LiteLLM:DEBUG[0m: utils.py:4823 - checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
2025-11-18 15:28:51,362 [DEBUG] checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
[92m15:28:51 - LiteLLM:DEBUG[0m: utils.py:5073 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-11-18 15:28:51,363 [DEBUG] Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
[92m15:28:51 - LiteLLM:DEBUG[0m: cost_calculator.py:1149 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=openai/qwen3 - This model isn't mapped yet. model=openai/qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
2025-11-18 15:28:51,363 [DEBUG] litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=openai/qwen3 - This model isn't mapped yet. model=openai/qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
[92m15:28:51 - LiteLLM:DEBUG[0m: litellm_logging.py:1331 - response_cost_failure_debug_information: {'error_str': "This model isn't mapped yet. model=openai/qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.", 'traceback_str': 'Traceback (most recent call last):\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 4912, in _get_model_info_helper\n    raise ValueError(\nValueError: This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\litellm_logging.py", line 1312, in _response_cost_calculator\n    response_cost = litellm.response_cost_calculator(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1270, in response_cost_calculator\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1253, in response_cost_calculator\n    response_cost = completion_cost(\n                    ^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1162, in completion_cost\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1155, in completion_cost\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1094, in completion_cost\n    ) = cost_per_token(\n        ^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 379, in cost_per_token\n    return openai_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\llms\\openai\\cost_calculation.py", line 35, in cost_per_token\n    return generic_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\llm_cost_calc\\utils.py", line 515, in generic_cost_per_token\n    model_info = get_model_info(model=model, custom_llm_provider=custom_llm_provider)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 5158, in get_model_info\n    _model_info = _get_model_info_helper(\n                  ^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 5076, in _get_model_info_helper\n    raise Exception(\nException: This model isn\'t mapped yet. model=openai/qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n', 'model': 'openai/qwen3', 'cache_hit': False, 'custom_llm_provider': 'openai', 'base_model': None, 'call_type': 'acompletion', 'custom_pricing': False}
2025-11-18 15:28:51,370 [DEBUG] response_cost_failure_debug_information: {'error_str': "This model isn't mapped yet. model=openai/qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.", 'traceback_str': 'Traceback (most recent call last):\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 4912, in _get_model_info_helper\n    raise ValueError(\nValueError: This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\litellm_logging.py", line 1312, in _response_cost_calculator\n    response_cost = litellm.response_cost_calculator(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1270, in response_cost_calculator\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1253, in response_cost_calculator\n    response_cost = completion_cost(\n                    ^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1162, in completion_cost\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1155, in completion_cost\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1094, in completion_cost\n    ) = cost_per_token(\n        ^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 379, in cost_per_token\n    return openai_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\llms\\openai\\cost_calculation.py", line 35, in cost_per_token\n    return generic_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\llm_cost_calc\\utils.py", line 515, in generic_cost_per_token\n    model_info = get_model_info(model=model, custom_llm_provider=custom_llm_provider)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 5158, in get_model_info\n    _model_info = _get_model_info_helper(\n                  ^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 5076, in _get_model_info_helper\n    raise Exception(\nException: This model isn\'t mapped yet. model=openai/qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n', 'model': 'openai/qwen3', 'cache_hit': False, 'custom_llm_provider': 'openai', 'base_model': None, 'call_type': 'acompletion', 'custom_pricing': False}
[92m15:28:51 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-27266d4c-bee4-4715-abfc-add60b72c21a', choices=[Choice(delta=ChoiceDelta(content='<think>', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450926, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:28:51,687 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-27266d4c-bee4-4715-abfc-add60b72c21a', choices=[Choice(delta=ChoiceDelta(content='<think>', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450926, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:28:51 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='<think>', role='assistant', function_call=None, tool_calls=[], audio=None)
2025-11-18 15:28:51,691 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='<think>', role='assistant', function_call=None, tool_calls=[], audio=None)
[92m15:28:51 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-27266d4c-bee4-4715-abfc-add60b72c21a', created=1763450931, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='<think>', role='assistant', function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:28:51,691 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-27266d4c-bee4-4715-abfc-add60b72c21a', created=1763450931, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='<think>', role='assistant', function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:28:51,692 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='<think>'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='t9nXBUcx' timestamp=1763450930.423642
[92m15:28:51 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a33852d3-15c5-4762-babc-823260f835aa', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450926, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:28:51,732 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a33852d3-15c5-4762-babc-823260f835aa', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450926, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:28:51 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:28:51,733 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:28:51 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a33852d3-15c5-4762-babc-823260f835aa', created=1763450931, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:28:51,733 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a33852d3-15c5-4762-babc-823260f835aa', created=1763450931, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:28:51,734 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""

"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='dxEeSWee' timestamp=1763450930.423642
[92m15:28:51 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0b1a5999-b2bc-4daa-ab5e-1f5e847c23c0', choices=[Choice(delta=ChoiceDelta(content='</think>', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450926, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:28:51,734 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0b1a5999-b2bc-4daa-ab5e-1f5e847c23c0', choices=[Choice(delta=ChoiceDelta(content='</think>', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450926, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:28:51 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='</think>', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:28:51,735 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='</think>', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:28:51 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0b1a5999-b2bc-4daa-ab5e-1f5e847c23c0', created=1763450931, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='</think>', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:28:51,735 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0b1a5999-b2bc-4daa-ab5e-1f5e847c23c0', created=1763450931, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='</think>', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:28:51,736 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='</think>'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='TDhlr1GV' timestamp=1763450930.423642
[92m15:28:51 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ce748fe8-e483-440c-b20e-638918d83e38', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450926, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:28:51,779 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ce748fe8-e483-440c-b20e-638918d83e38', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450926, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:28:51 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:28:51,779 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:28:51 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ce748fe8-e483-440c-b20e-638918d83e38', created=1763450931, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:28:51,780 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ce748fe8-e483-440c-b20e-638918d83e38', created=1763450931, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:28:51,781 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""

"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='DujQIuPY' timestamp=1763450930.423642
[92m15:28:52 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-834c5e1a-554c-4e0f-b2f9-0a2ea913340e', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[ChoiceDeltaToolCall(index=0, id='call_834c5e1a-554c-4e0f-b2f9-0a2ea913340e', function=ChoiceDeltaToolCallFunction(arguments='{"keyword": "è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰© ç³–å°¿ç—…è¶³æºƒç–¡ ä½œç”¨ æœºåˆ¶ ç ”ç©¶è¿›å±•"}', name='DocumentSearch'), type='function')]), finish_reason='tool_calls', index=0, logprobs=None)], created=1763450927, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:28:52,581 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-834c5e1a-554c-4e0f-b2f9-0a2ea913340e', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[ChoiceDeltaToolCall(index=0, id='call_834c5e1a-554c-4e0f-b2f9-0a2ea913340e', function=ChoiceDeltaToolCallFunction(arguments='{"keyword": "è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰© ç³–å°¿ç—…è¶³æºƒç–¡ ä½œç”¨ æœºåˆ¶ ç ”ç©¶è¿›å±•"}', name='DocumentSearch'), type='function')]), finish_reason='tool_calls', index=0, logprobs=None)], created=1763450927, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:28:52 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[ChatCompletionDeltaToolCall(id='call_834c5e1a-554c-4e0f-b2f9-0a2ea913340e', function=Function(arguments='{"keyword": "è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰© ç³–å°¿ç—…è¶³æºƒç–¡ ä½œç”¨ æœºåˆ¶ ç ”ç©¶è¿›å±•"}', name='DocumentSearch'), type='function', index=0)], audio=None)
2025-11-18 15:28:52,584 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[ChatCompletionDeltaToolCall(id='call_834c5e1a-554c-4e0f-b2f9-0a2ea913340e', function=Function(arguments='{"keyword": "è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰© ç³–å°¿ç—…è¶³æºƒç–¡ ä½œç”¨ æœºåˆ¶ ç ”ç©¶è¿›å±•"}', name='DocumentSearch'), type='function', index=0)], audio=None)
[92m15:28:52 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-834c5e1a-554c-4e0f-b2f9-0a2ea913340e', created=1763450931, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[ChatCompletionDeltaToolCall(id='call_834c5e1a-554c-4e0f-b2f9-0a2ea913340e', function=Function(arguments='{"keyword": "è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰© ç³–å°¿ç—…è¶³æºƒç–¡ ä½œç”¨ æœºåˆ¶ ç ”ç©¶è¿›å±•"}', name='DocumentSearch'), type='function', index=0)], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:28:52,584 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-834c5e1a-554c-4e0f-b2f9-0a2ea913340e', created=1763450931, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[ChatCompletionDeltaToolCall(id='call_834c5e1a-554c-4e0f-b2f9-0a2ea913340e', function=Function(arguments='{"keyword": "è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰© ç³–å°¿ç—…è¶³æºƒç–¡ ä½œç”¨ æœºåˆ¶ ç ”ç©¶è¿›å±•"}', name='DocumentSearch'), type='function', index=0)], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:28:52 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-88d8b5c5-9685-448f-86b8-af19dd3b8402', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason='stop', index=0, logprobs=None)], created=1763450927, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=45, prompt_tokens=1275, total_tokens=1320, completion_tokens_details=None, prompt_tokens_details=None))
2025-11-18 15:28:52,636 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-88d8b5c5-9685-448f-86b8-af19dd3b8402', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason='stop', index=0, logprobs=None)], created=1763450927, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=45, prompt_tokens=1275, total_tokens=1320, completion_tokens_details=None, prompt_tokens_details=None))
[92m15:28:52 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:28:52,639 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:28:52 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-88d8b5c5-9685-448f-86b8-af19dd3b8402', created=1763450931, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=45, prompt_tokens=1275, total_tokens=1320, completion_tokens_details=None, prompt_tokens_details=None), citations=None, service_tier=None)
2025-11-18 15:28:52,639 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-88d8b5c5-9685-448f-86b8-af19dd3b8402', created=1763450931, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=45, prompt_tokens=1275, total_tokens=1320, completion_tokens_details=None, prompt_tokens_details=None), citations=None, service_tier=None)
[92m15:28:52 - LiteLLM:DEBUG[0m: litellm_logging.py:1660 - Logging Details LiteLLM-Success Call: Cache_hit=False
2025-11-18 15:28:52,647 [INFO] è§¦å‘äº†å·¥å…·è°ƒç”¨ã€‚ã€‚ã€‚è¿”å›DataPartæ•°æ®, content=Content(
  parts=[
    Part(
      text="""<think>

</think>

"""
    ),
    Part(
      function_call=FunctionCall(
        args={
          'keyword': 'è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰© ç³–å°¿ç—…è¶³æºƒç–¡ ä½œç”¨ æœºåˆ¶ ç ”ç©¶è¿›å±•'
        },
        id='call_834c5e1a-554c-4e0f-b2f9-0a2ea913340e',
        name='DocumentSearch'
      )
    ),
  ],
  role='model'
) grounding_metadata=None partial=False turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=set() branch=None id='wXwHnnrm' timestamp=1763450930.423642
2025-11-18 15:28:52,646 [DEBUG] Logging Details LiteLLM-Success Call: Cache_hit=False
[92m15:28:52 - LiteLLM:DEBUG[0m: litellm_logging.py:1689 - Logging Details LiteLLM-Success Call streaming complete
2025-11-18 15:28:52,649 [DEBUG] Logging Details LiteLLM-Success Call streaming complete
[92m15:28:52 - LiteLLM:DEBUG[0m: cost_calculator.py:833 - selected model name for cost calculation: openai/qwen3
2025-11-18 15:28:52,649 [DEBUG] selected model name for cost calculation: openai/qwen3
[92m15:28:52 - LiteLLM:DEBUG[0m: utils.py:4823 - checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
2025-11-18 15:28:52,649 [DEBUG] checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
[92m15:28:52 - LiteLLM:DEBUG[0m: utils.py:5073 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-11-18 15:28:52,649 [DEBUG] Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
[92m15:28:52 - LiteLLM:DEBUG[0m: cost_calculator.py:1149 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=openai/qwen3 - This model isn't mapped yet. model=openai/qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
2025-11-18 15:28:52,649 [DEBUG] litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=openai/qwen3 - This model isn't mapped yet. model=openai/qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
[92m15:28:52 - LiteLLM:DEBUG[0m: cost_calculator.py:833 - selected model name for cost calculation: qwen3
2025-11-18 15:28:52,649 [DEBUG] selected model name for cost calculation: qwen3
[92m15:28:52 - LiteLLM:DEBUG[0m: utils.py:4823 - checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
2025-11-18 15:28:52,650 [DEBUG] checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
[92m15:28:52 - LiteLLM:DEBUG[0m: utils.py:5073 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-11-18 15:28:52,650 [DEBUG] Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
[92m15:28:52 - LiteLLM:DEBUG[0m: cost_calculator.py:1149 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=qwen3 - This model isn't mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
2025-11-18 15:28:52,650 [DEBUG] litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=qwen3 - This model isn't mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
[92m15:28:52 - LiteLLM:DEBUG[0m: litellm_logging.py:1331 - response_cost_failure_debug_information: {'error_str': "This model isn't mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.", 'traceback_str': 'Traceback (most recent call last):\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 4912, in _get_model_info_helper\n    raise ValueError(\nValueError: This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\litellm_logging.py", line 1312, in _response_cost_calculator\n    response_cost = litellm.response_cost_calculator(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1270, in response_cost_calculator\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1253, in response_cost_calculator\n    response_cost = completion_cost(\n                    ^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1162, in completion_cost\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1155, in completion_cost\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1094, in completion_cost\n    ) = cost_per_token(\n        ^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 379, in cost_per_token\n    return openai_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\llms\\openai\\cost_calculation.py", line 35, in cost_per_token\n    return generic_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\llm_cost_calc\\utils.py", line 515, in generic_cost_per_token\n    model_info = get_model_info(model=model, custom_llm_provider=custom_llm_provider)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 5158, in get_model_info\n    _model_info = _get_model_info_helper(\n                  ^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 5076, in _get_model_info_helper\n    raise Exception(\nException: This model isn\'t mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n', 'model': 'qwen3', 'cache_hit': False, 'custom_llm_provider': 'openai', 'base_model': None, 'call_type': 'acompletion', 'custom_pricing': False}
2025-11-18 15:28:52,652 [DEBUG] response_cost_failure_debug_information: {'error_str': "This model isn't mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.", 'traceback_str': 'Traceback (most recent call last):\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 4912, in _get_model_info_helper\n    raise ValueError(\nValueError: This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\litellm_logging.py", line 1312, in _response_cost_calculator\n    response_cost = litellm.response_cost_calculator(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1270, in response_cost_calculator\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1253, in response_cost_calculator\n    response_cost = completion_cost(\n                    ^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1162, in completion_cost\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1155, in completion_cost\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1094, in completion_cost\n    ) = cost_per_token(\n        ^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 379, in cost_per_token\n    return openai_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\llms\\openai\\cost_calculation.py", line 35, in cost_per_token\n    return generic_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\llm_cost_calc\\utils.py", line 515, in generic_cost_per_token\n    model_info = get_model_info(model=model, custom_llm_provider=custom_llm_provider)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 5158, in get_model_info\n    _model_info = _get_model_info_helper(\n                  ^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 5076, in _get_model_info_helper\n    raise Exception(\nException: This model isn\'t mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n', 'model': 'qwen3', 'cache_hit': False, 'custom_llm_provider': 'openai', 'base_model': None, 'call_type': 'acompletion', 'custom_pricing': False}
[92m15:28:52 - LiteLLM:DEBUG[0m: utils.py:4823 - checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
2025-11-18 15:28:52,653 [DEBUG] checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
[92m15:28:52 - LiteLLM:DEBUG[0m: utils.py:5073 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-11-18 15:28:52,653 [DEBUG] Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
[92m15:28:52 - LiteLLM:DEBUG[0m: litellm_logging.py:4204 - Model=qwen3 is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload
2025-11-18 15:28:52,653 [DEBUG] Model=qwen3 is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload
2025-11-18 15:29:09,456 [INFO] å·¥å…·è¿”å›äº†ç»“æœã€‚ã€‚ã€‚è¿”å›DataPartæ•°æ®, content=Content(
  parts=[
    Part(
      function_response=FunctionResponse(
        id='call_834c5e1a-554c-4e0f-b2f9-0a2ea913340e',
        name='DocumentSearch',
        response={
          'result': [
            """1. æ ‡é¢˜ï¼š2025å¹´å…‰ä¼ä¼ä¸šç»¿è‰²ä½ç¢³è¯„ä»·æŠ¥å‘Š.pdf.md
æ—¶é—´: None
å†…å®¹: {"name": "part_1.txt", "content": "# 2025å…‰ä¼ä¼ä¸šç»¿è‰²ä½ç¢³è¯„ä»·æŠ¥å‘Š 2025å¹´7æœˆ # å¹¶è´­å®¶ å…è´¹è¡Œä¸šæŠ¥å‘Šç½‘ # IPOIPO.CN æ¯æ—¥æ›´æ–° ä¸ç”¨æ³¨å†Œä¼šå‘˜ æ— å¹¿å‘Š æ°¸ä¹…å…è´¹ # å…³äºIPE å…¬ä¼—ç¯å¢ƒç ”ç©¶ä¸­å¿ƒï¼ˆIPEï¼‰æ˜¯ä¸€å®¶åœ¨åŒ—äº¬æ³¨å†Œçš„å…¬ç›Šç¯å¢ƒç ”ç©¶æœºæ„ã€‚ è‡ª2006å¹´æˆç«‹ä»¥æ¥ï¼Œâ€¦

""",
          ]
        }
      )
    ),
  ],
  role='user'
) grounding_metadata=None partial=None turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'references': {'4f7a4db3094f5788': {'idx_val': 1, 'file_id': '4f7a4db3094f5788', 'title': '2025å¹´å…‰ä¼ä¼ä¸šç»¿è‰²ä½ç¢³è¯„ä»·æŠ¥å‘Š.pdf.md', 'publish_time': None, 'snippet': '{"name": "part_1.txt", "content": "# 2025å…‰ä¼ä¼ä¸šç»¿è‰²ä½ç¢³è¯„ä»·æŠ¥å‘Š 2025å¹´7æœˆ # å¹¶è´­å®¶ å…è´¹è¡Œä¸šæŠ¥å‘Šç½‘ # IPOIPO.CN æ¯æ—¥æ›´æ–° ä¸ç”¨æ³¨å†Œä¼šå‘˜ æ— å¹¿å‘Š æ°¸ä¹…å…è´¹ # å…³äºIPE å…¬ä¼—ç¯å¢ƒç ”ç©¶ä¸­å¿ƒï¼ˆIPEï¼‰æ˜¯ä¸€å®¶åœ¨åŒ—äº¬æ³¨å†Œçš„å…¬ç›Šç¯å¢ƒç ”ç©¶æœºæ„ã€‚ è‡ª2006å¹´æˆç«‹ä»¥æ¥ï¼Œâ€¦', 'url': 'ragflow://be6f175abfb311f08b4ffe29b7877c04'}}}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='7vpNn5wd' timestamp=1763450949.456882
[92m15:29:09 - LiteLLM:DEBUG[0m: utils.py:376 - 

2025-11-18 15:29:09,458 [DEBUG] 

[92m15:29:09 - LiteLLM:DEBUG[0m: utils.py:376 - [92mRequest to litellm:[0m
2025-11-18 15:29:09,458 [DEBUG] [92mRequest to litellm:[0m
[92m15:29:09 - LiteLLM:DEBUG[0m: utils.py:376 - [92mlitellm.acompletion(model='openai/qwen3', messages=[{'role': 'developer', 'content': '\n/no_think\n# è§’è‰²\nä½ æ˜¯ä¸€åä¸¥è°¨çš„ç»¼è¿°ä½œè€…ä¸å¤šå­¦ç§‘ä¿¡æ¯åˆ†æä¸“å®¶ã€‚å¿…é¡»å…ˆå®Œæˆç³»ç»Ÿæ£€ç´¢ä¸è¯æ®ç­›é€‰ï¼Œå†å¼€å§‹å†™å¤§çº²ã€‚\n\n# ç›®æ ‡\nä»…ç”Ÿæˆã€ä¸­æ–‡Markdownå¤§çº²ã€‘ï¼Œç»“æ„ä¸æ ‡é¢˜å¿…é¡»ä¸¥æ ¼æŒ‰â€œè¾“å‡ºç»“æ„â€ä¸€èŠ‚ï¼›ä¸å†™æ­£æ–‡ã€ä¸åŠ URLã€ä¸è¾“å‡ºå¤šä½™å†…å®¹ã€‚\n\n# ä»¥æ£€ç´¢ç»“æœé©±åŠ¨çš„åŠ¨æ€æ‰©å±•ï¼ˆæ ¸å¿ƒå¼ºåŒ–ï¼‰\n- ä»¥â€œä¸»é¢˜ç°‡â€ä¸ºæœ€å°å•å…ƒï¼šåŸºäºæ£€ç´¢ç»“æœå°†æ–‡çŒ®æˆ–æŠ¥å‘Šèšç±»ä¸ºä¸»é¢˜ç°‡ï¼ˆå¦‚æœºåˆ¶ã€æ–¹æ³•å­¦ã€äºšå‹ã€åº”ç”¨åœºæ™¯ã€å½±å“å› ç´ ã€ç»ˆç‚¹ã€å®‰å…¨æ€§ã€ç»æµå­¦ã€ç›‘ç®¡ç­‰ï¼‰ã€‚\n- æ‰©å±•è§„åˆ™ï¼ˆå†³å®šå°èŠ‚æ•°é‡ä¸å‘½åï¼‰ï¼š\n  1) å½“æŸä¸»é¢˜ç°‡æœ‰è¾ƒå¤šç ”ç©¶/æŒ‡å—/æŠ¥å‘Šæ”¯æŒæ—¶ï¼Œåˆ›å»ºç‹¬ç«‹ `###` å°èŠ‚ã€‚\n  2) è‹¥æŸä¸»é¢˜ç°‡æ¶‰åŠçš„ç ”ç©¶æ•°é‡è¾ƒå°‘ï¼Œåˆ™åˆå¹¶åˆ°é‚»è¿‘ `####` åˆ†èŠ‚ï¼›é¿å…ç”Ÿæˆç©ºæ´å°èŠ‚ã€‚\n  3) å¯¹â€œæ¯”è¾ƒ/ä¸€è‡´æ€§-å·®å¼‚/äº‰è®®ç‚¹â€â€œäºšç»„/ç‰¹å®šåº”ç”¨åœºæ™¯â€â€œçœŸå®ä¸–ç•Œè¯æ®/ç°åœºå®è·µâ€â€œæ–¹æ³•å­¦è´¨é‡ä¸åå€šâ€â€œæ ‡å‡†åŒ–ä¸ç›‘ç®¡/ä¼¦ç†/å…¬å¹³æ€§â€ä¼˜å…ˆå»ºèŠ‚ï¼ˆè‹¥è¯æ®å­˜åœ¨ï¼‰ã€‚\n  4) å°èŠ‚æ’åºæŒ‰â€œç ”ç©¶æ•°é‡Ã—å½±å“åŠ›Ã—æ–°è¿‘æ€§â€ç»¼åˆé™åºï¼›æ ‡é¢˜ç”¨å¯è¯»çš„ä¸»é¢˜åï¼Œä¸ä½¿ç”¨æ¨¡æ¿åŒ–è¯æ±‡ã€‚\n- åˆå¹¶ä¸æ‹†åˆ†é˜ˆå€¼ï¼š  \n  - å•ä¸€ `###` å°èŠ‚è‹¥æ¡ç›®>10ï¼ŒæŒ‰æœºåˆ¶/åœºæ™¯/äººç¾¤æ‹†ä¸ºå¤šä¸ª `####`ï¼›  \n  - å•ä¸€å°èŠ‚æ¡ç›®<3ï¼Œåˆå¹¶è‡³é‚»è¿‘æ›´ä¸Šä½å°èŠ‚ã€‚\n- è¦†ç›–åº¦çº¦æŸï¼š`###/####` å°èŠ‚åˆè®¡è‡³å°‘è¦†ç›–ä¸»è¦ä¸»é¢˜ç°‡çš„70%ã€‚\n\n# æ’°å†™è¦æ±‚\n- æ ‡é¢˜å¿…é¡»â€œæ¥æºäºæ£€ç´¢ä¸»é¢˜â€ï¼Œä¸å¯ç…§æ¬æ¨¡æ¿ï¼›å°èŠ‚æ•°é‡ä¸å‘½åä»¥å®é™…æ£€ç´¢ç»“æœä¸ºå‡†ã€‚\n- å¤§çº²æ¡ç›®ç²¾ç‚¼ï¼ˆâ‰¤30å­—ï¼‰ï¼Œå°½é‡é‡åŒ–å…³é”®æŒ‡æ ‡ï¼ˆå¦‚æ•ˆåº”é‡/é˜ˆå€¼/æ—¶é—´çª—/äººç¾¤ï¼‰ã€‚\n- æœ¯è¯­ä¸­æ–‡ç»Ÿä¸€ï¼Œåº¦é‡å•ä½/ç¼©å†™ä¸€è‡´ï¼›å¯åšç­‰ä»·æ˜ å°„ï¼ˆå¦‚â€œæ•°æ®é‡‡é›†/è´¨æ§â€â†’â€œæ•°æ®é¢„å¤„ç†/è´¨é‡ä¿éšœâ€ï¼‰ã€‚\n- ä¸¥ç¦ç”Ÿæˆä¸ä¸»é¢˜æ— å…³æˆ–æ— æ”¯æ’‘çš„å°èŠ‚/è¦ç‚¹ã€‚\n- ç¦æ­¢åœ¨å¤§çº²çš„æœ«å°¾æ·»åŠ å¼•ç”¨è¯´æ˜å’Œå‚è€ƒæ–‡çŒ®è¯´æ˜ç­‰ä»»ä½•è¯´æ˜ã€‚\n- ç¦æ­¢åœ¨å¤§çº²æ·»åŠ ä»»ä½•å¼•ç”¨è¯´æ˜ï¼Œä»…ç”Ÿæˆã€Markdownå¤§çº²ã€‘ã€‚\n\n\n# å¼ºåˆ¶æ£€ç´¢è¦æ±‚\n- åœ¨å¼€å§‹ç”Ÿæˆå¤§çº²ä¹‹å‰ï¼Œå¿…é¡»è°ƒç”¨ DocumentSearch å·¥å…·è¿›è¡Œç³»ç»Ÿæ€§æ–‡çŒ®æ£€ç´¢\n- æœç´¢å¿…é¡»åŒ…å«ä¸»é¢˜çš„æ ¸å¿ƒå…³é”®è¯åŠå…¶åŒä¹‰è¯ã€ç›¸å…³æœ¯è¯­\n- å¿…é¡»åŸºäºå®é™…æ£€ç´¢åˆ°çš„æ–‡çŒ®è¯æ®æ¥æ„å»ºå¤§çº²ç»“æ„å’Œå†…å®¹\n- ä¸¥ç¦åœ¨æœªæ‰§è¡Œæ£€ç´¢çš„æƒ…å†µä¸‹ç›´æ¥ç”Ÿæˆå¤§çº²\n\n# å·¥ä½œæµç¨‹ï¼ˆå…ˆæ£€ç´¢ï¼Œåå†™ä½œï¼‰\n1) æ£€ç´¢ä¸è¦†ç›–é¢  \n   - ç›®æ ‡ï¼šâ‰¥30ç¯‡å€™é€‰æ–‡çŒ®ï¼›è¿‘5å¹´ä¼˜å…ˆï¼Œä½†éœ€ä¿ç•™é‡Œç¨‹ç¢‘ç ”ç©¶ã€‚  \n   - è®°å½•æ¯æ¡å€™é€‰çš„ä¸»é¢˜ç°‡ã€æ ¸å¿ƒç»“è®ºä¸å¯æå–å®šé‡æŒ‡æ ‡ã€‚\n2) ä¸»é¢˜èšåˆ  \n   - å°†æ‰€æœ‰å€™é€‰æ–‡çŒ®èšåˆä¸ºè‹¥å¹²ä¸»é¢˜ç°‡ã€‚  \n   - ä¾æ®ä¸»é¢˜ç°‡çš„æ•°é‡å’Œé‡è¦æ€§å†³å®šå°èŠ‚ç»“æ„ï¼›ä¸è¶³è€…å¹¶å…¥ç›¸é‚»èŠ‚ã€‚  \n   - ä¸ºæ¯”è¾ƒã€å¼‚è´¨æ€§æ¥æºã€çœŸå®ä¸–ç•Œè¯æ®ã€æ–°å…´æ–¹å‘ä¸ç›‘ç®¡/ä¼¦ç†ç­‰è‡ªåŠ¨é¢„ç•™ä½ç½®ï¼ˆå­˜åœ¨è¯æ®æ—¶ï¼‰ã€‚\n\n# è¾“å‡ºè¦æ±‚\n- ä½¿ç”¨çš„è¯­è¨€æ˜¯: chinese\n- ä»…è¾“å‡ºã€Markdownå¤§çº²ã€‘ï¼Œå±‚çº§ä½¿ç”¨ #/##/###/####ã€‚  \n- æ¯æ¡è¦ç‚¹â‰¤30å­—ã€ä¿¡æ¯å¯†åº¦é«˜ã€å°½é‡é‡åŒ–ã€‚    \n- å¤§çº²æœ€å¥½ä¸å°‘äº10ä¸ªç« èŠ‚ï¼Œä¸å¤šäº15ç« èŠ‚ã€‚\n- ã€å¼ºåˆ¶ã€‘è¾“å‡ºå®Œæˆåç«‹å³ç»“æŸï¼›ç¦æ­¢åœ¨æ–‡æœ«æ·»åŠ â€œå¼•ç”¨è¯´æ˜/å‚è€ƒæ–‡çŒ®/è¯´æ˜/æ³¨é‡Š/Notes/Referencesâ€ç­‰ä»»ä½•è¯´æ˜æ€§æ–‡æœ¬æˆ–æ®µè½ã€‚\n\n# è¾“å‡ºç»“æ„ï¼ˆæ ‡é¢˜ä¸é¡ºåºå¿…é¡»ä¸€è‡´ï¼›åœ¨"..."å¤„æŒ‰è§„åˆ™åŠ¨æ€æ‰©å±•ï¼‰\n# è‡ªåŠ¨ç”Ÿæˆç²¾å‡†æ ‡é¢˜ï¼šä¸åŠ å‰¯æ ‡é¢˜\nä¸‹é¢æ˜¯ä¸€ä¸ªç¤ºä¾‹å¤§çº²ç»“æ„ï¼Œä»…ä¾›å‚è€ƒã€‚å®é™…è¾“å‡ºæ—¶å¿…é¡»æ ¹æ®æ£€ç´¢ç»“æœåŠ¨æ€è°ƒæ•´ç« èŠ‚ä¸å°èŠ‚æ ‡é¢˜ã€æ•°é‡ä¸é¡ºåºã€‚è¾“å‡ºçš„æ—¶å€™å¿…é¡»å¸¦æœ‰æ‰€æ’°å†™çš„å¤§çº²å¯¹åº”çš„æ ‡é¢˜ã€‚\n\n## æ‘˜è¦\n- èƒŒæ™¯ï¼šç ”ç©¶ç°çŠ¶/æœªæ»¡è¶³éœ€æ±‚\n- ç›®çš„ï¼šç»¼è¿°æ—¨åœ¨è§£å†³ä»€ä¹ˆé—®é¢˜\n- æ–¹æ³•ï¼ˆå¯é€‰ï¼‰ï¼šæ£€ç´¢èŒƒå›´/çº³æ’æ ‡å‡†/è¯æ®åˆ†çº§ç®€è¿°\n- ä¸»è¦å‘ç°ï¼šå›´ç»•â€œæŠ€æœ¯/æ–¹æ³•Ã—æœºåˆ¶/åº”ç”¨â€çš„å…³é”®è¿›å±•\n- ç»“è®ºä¸å±•æœ›ï¼šè½¬åŒ–è·¯å¾„/æ ‡å‡†åŒ–æŒ‘æˆ˜/æœªæ¥å‘å±•å‰æ™¯\n- å…³é”®è¯ï¼š3â€“8ä¸ªï¼›åˆ†å·åˆ†éš”\n\n## 1. å¼•è¨€\n### 1.1 xx\n### 1.2 xx\n### 1.3 xx\n...\n\n\nYou are an agent. Your internal name is "outline_agent".\n\n The description about you is "generate outline"'}, {'role': 'user', 'content': 'è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©åœ¨ç³–å°¿ç—…è¶³æºƒç–¡æ²»ç–—ä¸­çš„ä½œç”¨åŠæœºåˆ¶ç ”ç©¶è¿›å±•'}, {'role': 'assistant', 'content': '<think>\n\n</think>\n\n', 'tool_calls': [{'type': 'function', 'id': 'call_834c5e1a-554c-4e0f-b2f9-0a2ea913340e', 'function': {'name': 'DocumentSearch', 'arguments': '{"keyword": "è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰© ç³–å°¿ç—…è¶³æºƒç–¡ ä½œç”¨ æœºåˆ¶ ç ”ç©¶è¿›å±•"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_834c5e1a-554c-4e0f-b2f9-0a2ea913340e', 'content': '{"result": ["1. æ ‡é¢˜ï¼š2025å¹´å…‰ä¼ä¼ä¸šç»¿è‰²ä½ç¢³è¯„ä»·æŠ¥å‘Š.pdf.md\\næ—¶é—´: None\\nå†…å®¹: {\\"name\\": \\"part_1.txt\\", \\"content\\": \\"# 2025å…‰ä¼ä¼ä¸šç»¿è‰²ä½ç¢³è¯„ä»·æŠ¥å‘Š 2025å¹´7æœˆ # å¹¶è´­å®¶ å…è´¹è¡Œä¸šæŠ¥å‘Šç½‘ # IPOIPO.CN æ¯æ—¥æ›´æ–° ä¸ç”¨æ³¨å†Œä¼šå‘˜ æ— å¹¿å‘Š æ°¸ä¹…å…è´¹ # å…³äºIPE å…¬ä¼—ç¯å¢ƒç ”ç©¶ä¸­å¿ƒï¼ˆIPEï¼‰æ˜¯ä¸€å®¶åœ¨åŒ—äº¬æ³¨å†Œçš„å…¬ç›Šç¯å¢ƒç ”ç©¶æœºæ„ã€‚ è‡ª2006å¹´æˆç«‹ä»¥æ¥ï¼Œâ€¦\\n\\n"]}'}], tools=[{'type': 'function', 'function': {'name': 'DocumentSearch', 'description': '\n    æ ¹æ®å…³é”®è¯æœç´¢æ–‡æ¡£\n    :param keyword: str, æœç´¢çš„ç›¸å…³æ–‡æ¡£çš„å…³é”®è¯\n    :return: è¿”å›æ¯ç¯‡æ–‡æ¡£æ•°æ®\n    ', 'parameters': {'type': 'object', 'properties': {'keyword': {'type': 'string'}}}}}], response_format=None, api_key='sk-xxx', api_base='http://192.168.1.13:9997/v1', stream=True)[0m
2025-11-18 15:29:09,458 [DEBUG] [92mlitellm.acompletion(model='openai/qwen3', messages=[{'role': 'developer', 'content': '\n/no_think\n# è§’è‰²\nä½ æ˜¯ä¸€åä¸¥è°¨çš„ç»¼è¿°ä½œè€…ä¸å¤šå­¦ç§‘ä¿¡æ¯åˆ†æä¸“å®¶ã€‚å¿…é¡»å…ˆå®Œæˆç³»ç»Ÿæ£€ç´¢ä¸è¯æ®ç­›é€‰ï¼Œå†å¼€å§‹å†™å¤§çº²ã€‚\n\n# ç›®æ ‡\nä»…ç”Ÿæˆã€ä¸­æ–‡Markdownå¤§çº²ã€‘ï¼Œç»“æ„ä¸æ ‡é¢˜å¿…é¡»ä¸¥æ ¼æŒ‰â€œè¾“å‡ºç»“æ„â€ä¸€èŠ‚ï¼›ä¸å†™æ­£æ–‡ã€ä¸åŠ URLã€ä¸è¾“å‡ºå¤šä½™å†…å®¹ã€‚\n\n# ä»¥æ£€ç´¢ç»“æœé©±åŠ¨çš„åŠ¨æ€æ‰©å±•ï¼ˆæ ¸å¿ƒå¼ºåŒ–ï¼‰\n- ä»¥â€œä¸»é¢˜ç°‡â€ä¸ºæœ€å°å•å…ƒï¼šåŸºäºæ£€ç´¢ç»“æœå°†æ–‡çŒ®æˆ–æŠ¥å‘Šèšç±»ä¸ºä¸»é¢˜ç°‡ï¼ˆå¦‚æœºåˆ¶ã€æ–¹æ³•å­¦ã€äºšå‹ã€åº”ç”¨åœºæ™¯ã€å½±å“å› ç´ ã€ç»ˆç‚¹ã€å®‰å…¨æ€§ã€ç»æµå­¦ã€ç›‘ç®¡ç­‰ï¼‰ã€‚\n- æ‰©å±•è§„åˆ™ï¼ˆå†³å®šå°èŠ‚æ•°é‡ä¸å‘½åï¼‰ï¼š\n  1) å½“æŸä¸»é¢˜ç°‡æœ‰è¾ƒå¤šç ”ç©¶/æŒ‡å—/æŠ¥å‘Šæ”¯æŒæ—¶ï¼Œåˆ›å»ºç‹¬ç«‹ `###` å°èŠ‚ã€‚\n  2) è‹¥æŸä¸»é¢˜ç°‡æ¶‰åŠçš„ç ”ç©¶æ•°é‡è¾ƒå°‘ï¼Œåˆ™åˆå¹¶åˆ°é‚»è¿‘ `####` åˆ†èŠ‚ï¼›é¿å…ç”Ÿæˆç©ºæ´å°èŠ‚ã€‚\n  3) å¯¹â€œæ¯”è¾ƒ/ä¸€è‡´æ€§-å·®å¼‚/äº‰è®®ç‚¹â€â€œäºšç»„/ç‰¹å®šåº”ç”¨åœºæ™¯â€â€œçœŸå®ä¸–ç•Œè¯æ®/ç°åœºå®è·µâ€â€œæ–¹æ³•å­¦è´¨é‡ä¸åå€šâ€â€œæ ‡å‡†åŒ–ä¸ç›‘ç®¡/ä¼¦ç†/å…¬å¹³æ€§â€ä¼˜å…ˆå»ºèŠ‚ï¼ˆè‹¥è¯æ®å­˜åœ¨ï¼‰ã€‚\n  4) å°èŠ‚æ’åºæŒ‰â€œç ”ç©¶æ•°é‡Ã—å½±å“åŠ›Ã—æ–°è¿‘æ€§â€ç»¼åˆé™åºï¼›æ ‡é¢˜ç”¨å¯è¯»çš„ä¸»é¢˜åï¼Œä¸ä½¿ç”¨æ¨¡æ¿åŒ–è¯æ±‡ã€‚\n- åˆå¹¶ä¸æ‹†åˆ†é˜ˆå€¼ï¼š  \n  - å•ä¸€ `###` å°èŠ‚è‹¥æ¡ç›®>10ï¼ŒæŒ‰æœºåˆ¶/åœºæ™¯/äººç¾¤æ‹†ä¸ºå¤šä¸ª `####`ï¼›  \n  - å•ä¸€å°èŠ‚æ¡ç›®<3ï¼Œåˆå¹¶è‡³é‚»è¿‘æ›´ä¸Šä½å°èŠ‚ã€‚\n- è¦†ç›–åº¦çº¦æŸï¼š`###/####` å°èŠ‚åˆè®¡è‡³å°‘è¦†ç›–ä¸»è¦ä¸»é¢˜ç°‡çš„70%ã€‚\n\n# æ’°å†™è¦æ±‚\n- æ ‡é¢˜å¿…é¡»â€œæ¥æºäºæ£€ç´¢ä¸»é¢˜â€ï¼Œä¸å¯ç…§æ¬æ¨¡æ¿ï¼›å°èŠ‚æ•°é‡ä¸å‘½åä»¥å®é™…æ£€ç´¢ç»“æœä¸ºå‡†ã€‚\n- å¤§çº²æ¡ç›®ç²¾ç‚¼ï¼ˆâ‰¤30å­—ï¼‰ï¼Œå°½é‡é‡åŒ–å…³é”®æŒ‡æ ‡ï¼ˆå¦‚æ•ˆåº”é‡/é˜ˆå€¼/æ—¶é—´çª—/äººç¾¤ï¼‰ã€‚\n- æœ¯è¯­ä¸­æ–‡ç»Ÿä¸€ï¼Œåº¦é‡å•ä½/ç¼©å†™ä¸€è‡´ï¼›å¯åšç­‰ä»·æ˜ å°„ï¼ˆå¦‚â€œæ•°æ®é‡‡é›†/è´¨æ§â€â†’â€œæ•°æ®é¢„å¤„ç†/è´¨é‡ä¿éšœâ€ï¼‰ã€‚\n- ä¸¥ç¦ç”Ÿæˆä¸ä¸»é¢˜æ— å…³æˆ–æ— æ”¯æ’‘çš„å°èŠ‚/è¦ç‚¹ã€‚\n- ç¦æ­¢åœ¨å¤§çº²çš„æœ«å°¾æ·»åŠ å¼•ç”¨è¯´æ˜å’Œå‚è€ƒæ–‡çŒ®è¯´æ˜ç­‰ä»»ä½•è¯´æ˜ã€‚\n- ç¦æ­¢åœ¨å¤§çº²æ·»åŠ ä»»ä½•å¼•ç”¨è¯´æ˜ï¼Œä»…ç”Ÿæˆã€Markdownå¤§çº²ã€‘ã€‚\n\n\n# å¼ºåˆ¶æ£€ç´¢è¦æ±‚\n- åœ¨å¼€å§‹ç”Ÿæˆå¤§çº²ä¹‹å‰ï¼Œå¿…é¡»è°ƒç”¨ DocumentSearch å·¥å…·è¿›è¡Œç³»ç»Ÿæ€§æ–‡çŒ®æ£€ç´¢\n- æœç´¢å¿…é¡»åŒ…å«ä¸»é¢˜çš„æ ¸å¿ƒå…³é”®è¯åŠå…¶åŒä¹‰è¯ã€ç›¸å…³æœ¯è¯­\n- å¿…é¡»åŸºäºå®é™…æ£€ç´¢åˆ°çš„æ–‡çŒ®è¯æ®æ¥æ„å»ºå¤§çº²ç»“æ„å’Œå†…å®¹\n- ä¸¥ç¦åœ¨æœªæ‰§è¡Œæ£€ç´¢çš„æƒ…å†µä¸‹ç›´æ¥ç”Ÿæˆå¤§çº²\n\n# å·¥ä½œæµç¨‹ï¼ˆå…ˆæ£€ç´¢ï¼Œåå†™ä½œï¼‰\n1) æ£€ç´¢ä¸è¦†ç›–é¢  \n   - ç›®æ ‡ï¼šâ‰¥30ç¯‡å€™é€‰æ–‡çŒ®ï¼›è¿‘5å¹´ä¼˜å…ˆï¼Œä½†éœ€ä¿ç•™é‡Œç¨‹ç¢‘ç ”ç©¶ã€‚  \n   - è®°å½•æ¯æ¡å€™é€‰çš„ä¸»é¢˜ç°‡ã€æ ¸å¿ƒç»“è®ºä¸å¯æå–å®šé‡æŒ‡æ ‡ã€‚\n2) ä¸»é¢˜èšåˆ  \n   - å°†æ‰€æœ‰å€™é€‰æ–‡çŒ®èšåˆä¸ºè‹¥å¹²ä¸»é¢˜ç°‡ã€‚  \n   - ä¾æ®ä¸»é¢˜ç°‡çš„æ•°é‡å’Œé‡è¦æ€§å†³å®šå°èŠ‚ç»“æ„ï¼›ä¸è¶³è€…å¹¶å…¥ç›¸é‚»èŠ‚ã€‚  \n   - ä¸ºæ¯”è¾ƒã€å¼‚è´¨æ€§æ¥æºã€çœŸå®ä¸–ç•Œè¯æ®ã€æ–°å…´æ–¹å‘ä¸ç›‘ç®¡/ä¼¦ç†ç­‰è‡ªåŠ¨é¢„ç•™ä½ç½®ï¼ˆå­˜åœ¨è¯æ®æ—¶ï¼‰ã€‚\n\n# è¾“å‡ºè¦æ±‚\n- ä½¿ç”¨çš„è¯­è¨€æ˜¯: chinese\n- ä»…è¾“å‡ºã€Markdownå¤§çº²ã€‘ï¼Œå±‚çº§ä½¿ç”¨ #/##/###/####ã€‚  \n- æ¯æ¡è¦ç‚¹â‰¤30å­—ã€ä¿¡æ¯å¯†åº¦é«˜ã€å°½é‡é‡åŒ–ã€‚    \n- å¤§çº²æœ€å¥½ä¸å°‘äº10ä¸ªç« èŠ‚ï¼Œä¸å¤šäº15ç« èŠ‚ã€‚\n- ã€å¼ºåˆ¶ã€‘è¾“å‡ºå®Œæˆåç«‹å³ç»“æŸï¼›ç¦æ­¢åœ¨æ–‡æœ«æ·»åŠ â€œå¼•ç”¨è¯´æ˜/å‚è€ƒæ–‡çŒ®/è¯´æ˜/æ³¨é‡Š/Notes/Referencesâ€ç­‰ä»»ä½•è¯´æ˜æ€§æ–‡æœ¬æˆ–æ®µè½ã€‚\n\n# è¾“å‡ºç»“æ„ï¼ˆæ ‡é¢˜ä¸é¡ºåºå¿…é¡»ä¸€è‡´ï¼›åœ¨"..."å¤„æŒ‰è§„åˆ™åŠ¨æ€æ‰©å±•ï¼‰\n# è‡ªåŠ¨ç”Ÿæˆç²¾å‡†æ ‡é¢˜ï¼šä¸åŠ å‰¯æ ‡é¢˜\nä¸‹é¢æ˜¯ä¸€ä¸ªç¤ºä¾‹å¤§çº²ç»“æ„ï¼Œä»…ä¾›å‚è€ƒã€‚å®é™…è¾“å‡ºæ—¶å¿…é¡»æ ¹æ®æ£€ç´¢ç»“æœåŠ¨æ€è°ƒæ•´ç« èŠ‚ä¸å°èŠ‚æ ‡é¢˜ã€æ•°é‡ä¸é¡ºåºã€‚è¾“å‡ºçš„æ—¶å€™å¿…é¡»å¸¦æœ‰æ‰€æ’°å†™çš„å¤§çº²å¯¹åº”çš„æ ‡é¢˜ã€‚\n\n## æ‘˜è¦\n- èƒŒæ™¯ï¼šç ”ç©¶ç°çŠ¶/æœªæ»¡è¶³éœ€æ±‚\n- ç›®çš„ï¼šç»¼è¿°æ—¨åœ¨è§£å†³ä»€ä¹ˆé—®é¢˜\n- æ–¹æ³•ï¼ˆå¯é€‰ï¼‰ï¼šæ£€ç´¢èŒƒå›´/çº³æ’æ ‡å‡†/è¯æ®åˆ†çº§ç®€è¿°\n- ä¸»è¦å‘ç°ï¼šå›´ç»•â€œæŠ€æœ¯/æ–¹æ³•Ã—æœºåˆ¶/åº”ç”¨â€çš„å…³é”®è¿›å±•\n- ç»“è®ºä¸å±•æœ›ï¼šè½¬åŒ–è·¯å¾„/æ ‡å‡†åŒ–æŒ‘æˆ˜/æœªæ¥å‘å±•å‰æ™¯\n- å…³é”®è¯ï¼š3â€“8ä¸ªï¼›åˆ†å·åˆ†éš”\n\n## 1. å¼•è¨€\n### 1.1 xx\n### 1.2 xx\n### 1.3 xx\n...\n\n\nYou are an agent. Your internal name is "outline_agent".\n\n The description about you is "generate outline"'}, {'role': 'user', 'content': 'è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©åœ¨ç³–å°¿ç—…è¶³æºƒç–¡æ²»ç–—ä¸­çš„ä½œç”¨åŠæœºåˆ¶ç ”ç©¶è¿›å±•'}, {'role': 'assistant', 'content': '<think>\n\n</think>\n\n', 'tool_calls': [{'type': 'function', 'id': 'call_834c5e1a-554c-4e0f-b2f9-0a2ea913340e', 'function': {'name': 'DocumentSearch', 'arguments': '{"keyword": "è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰© ç³–å°¿ç—…è¶³æºƒç–¡ ä½œç”¨ æœºåˆ¶ ç ”ç©¶è¿›å±•"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_834c5e1a-554c-4e0f-b2f9-0a2ea913340e', 'content': '{"result": ["1. æ ‡é¢˜ï¼š2025å¹´å…‰ä¼ä¼ä¸šç»¿è‰²ä½ç¢³è¯„ä»·æŠ¥å‘Š.pdf.md\\næ—¶é—´: None\\nå†…å®¹: {\\"name\\": \\"part_1.txt\\", \\"content\\": \\"# 2025å…‰ä¼ä¼ä¸šç»¿è‰²ä½ç¢³è¯„ä»·æŠ¥å‘Š 2025å¹´7æœˆ # å¹¶è´­å®¶ å…è´¹è¡Œä¸šæŠ¥å‘Šç½‘ # IPOIPO.CN æ¯æ—¥æ›´æ–° ä¸ç”¨æ³¨å†Œä¼šå‘˜ æ— å¹¿å‘Š æ°¸ä¹…å…è´¹ # å…³äºIPE å…¬ä¼—ç¯å¢ƒç ”ç©¶ä¸­å¿ƒï¼ˆIPEï¼‰æ˜¯ä¸€å®¶åœ¨åŒ—äº¬æ³¨å†Œçš„å…¬ç›Šç¯å¢ƒç ”ç©¶æœºæ„ã€‚ è‡ª2006å¹´æˆç«‹ä»¥æ¥ï¼Œâ€¦\\n\\n"]}'}], tools=[{'type': 'function', 'function': {'name': 'DocumentSearch', 'description': '\n    æ ¹æ®å…³é”®è¯æœç´¢æ–‡æ¡£\n    :param keyword: str, æœç´¢çš„ç›¸å…³æ–‡æ¡£çš„å…³é”®è¯\n    :return: è¿”å›æ¯ç¯‡æ–‡æ¡£æ•°æ®\n    ', 'parameters': {'type': 'object', 'properties': {'keyword': {'type': 'string'}}}}}], response_format=None, api_key='sk-xxx', api_base='http://192.168.1.13:9997/v1', stream=True)[0m
[92m15:29:09 - LiteLLM:DEBUG[0m: utils.py:376 - 

2025-11-18 15:29:09,458 [DEBUG] 

[92m15:29:09 - LiteLLM:DEBUG[0m: litellm_logging.py:490 - self.optional_params: {}
2025-11-18 15:29:09,458 [DEBUG] self.optional_params: {}
[92m15:29:09 - LiteLLM:DEBUG[0m: utils.py:376 - ASYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache'): None
2025-11-18 15:29:09,459 [DEBUG] ASYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache'): None
[92m15:29:09 - LiteLLM:DEBUG[0m: main.py:504 - ğŸ”„ NO SHARED SESSION: acompletion called without shared_session
2025-11-18 15:29:09,459 [DEBUG] ğŸ”„ NO SHARED SESSION: acompletion called without shared_session
[92m15:29:09 - LiteLLM:DEBUG[0m: base_utils.py:219 - Translating developer role to system role for non-OpenAI providers.
2025-11-18 15:29:09,460 [DEBUG] Translating developer role to system role for non-OpenAI providers.
[92m15:29:09 - LiteLLM:DEBUG[0m: utils.py:376 - Logging Details LiteLLM-Async Success Call, cache_hit=False
[92m15:29:09 - LiteLLM:INFO[0m: utils.py:3422 - 
LiteLLM completion() model= qwen3; provider = openai
2025-11-18 15:29:09,460 [DEBUG] Logging Details LiteLLM-Async Success Call, cache_hit=False
[92m15:29:09 - LiteLLM:DEBUG[0m: utils.py:376 - Async success callbacks: Got a complete streaming response
2025-11-18 15:29:09,461 [INFO] 
LiteLLM completion() model= qwen3; provider = openai
[92m15:29:09 - LiteLLM:DEBUG[0m: utils.py:3425 - 
LiteLLM: Params passed to completion() {'model': 'qwen3', 'functions': None, 'function_call': None, 'temperature': None, 'top_p': None, 'n': None, 'stream': True, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': [{'type': 'function', 'function': {'name': 'DocumentSearch', 'description': '\n    æ ¹æ®å…³é”®è¯æœç´¢æ–‡æ¡£\n    :param keyword: str, æœç´¢çš„ç›¸å…³æ–‡æ¡£çš„å…³é”®è¯\n    :return: è¿”å›æ¯ç¯‡æ–‡æ¡£æ•°æ®\n    ', 'parameters': {'type': 'object', 'properties': {'keyword': {'type': 'string'}}}}}], 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\n/no_think\n# è§’è‰²\nä½ æ˜¯ä¸€åä¸¥è°¨çš„ç»¼è¿°ä½œè€…ä¸å¤šå­¦ç§‘ä¿¡æ¯åˆ†æä¸“å®¶ã€‚å¿…é¡»å…ˆå®Œæˆç³»ç»Ÿæ£€ç´¢ä¸è¯æ®ç­›é€‰ï¼Œå†å¼€å§‹å†™å¤§çº²ã€‚\n\n# ç›®æ ‡\nä»…ç”Ÿæˆã€ä¸­æ–‡Markdownå¤§çº²ã€‘ï¼Œç»“æ„ä¸æ ‡é¢˜å¿…é¡»ä¸¥æ ¼æŒ‰â€œè¾“å‡ºç»“æ„â€ä¸€èŠ‚ï¼›ä¸å†™æ­£æ–‡ã€ä¸åŠ URLã€ä¸è¾“å‡ºå¤šä½™å†…å®¹ã€‚\n\n# ä»¥æ£€ç´¢ç»“æœé©±åŠ¨çš„åŠ¨æ€æ‰©å±•ï¼ˆæ ¸å¿ƒå¼ºåŒ–ï¼‰\n- ä»¥â€œä¸»é¢˜ç°‡â€ä¸ºæœ€å°å•å…ƒï¼šåŸºäºæ£€ç´¢ç»“æœå°†æ–‡çŒ®æˆ–æŠ¥å‘Šèšç±»ä¸ºä¸»é¢˜ç°‡ï¼ˆå¦‚æœºåˆ¶ã€æ–¹æ³•å­¦ã€äºšå‹ã€åº”ç”¨åœºæ™¯ã€å½±å“å› ç´ ã€ç»ˆç‚¹ã€å®‰å…¨æ€§ã€ç»æµå­¦ã€ç›‘ç®¡ç­‰ï¼‰ã€‚\n- æ‰©å±•è§„åˆ™ï¼ˆå†³å®šå°èŠ‚æ•°é‡ä¸å‘½åï¼‰ï¼š\n  1) å½“æŸä¸»é¢˜ç°‡æœ‰è¾ƒå¤šç ”ç©¶/æŒ‡å—/æŠ¥å‘Šæ”¯æŒæ—¶ï¼Œåˆ›å»ºç‹¬ç«‹ `###` å°èŠ‚ã€‚\n  2) è‹¥æŸä¸»é¢˜ç°‡æ¶‰åŠçš„ç ”ç©¶æ•°é‡è¾ƒå°‘ï¼Œåˆ™åˆå¹¶åˆ°é‚»è¿‘ `####` åˆ†èŠ‚ï¼›é¿å…ç”Ÿæˆç©ºæ´å°èŠ‚ã€‚\n  3) å¯¹â€œæ¯”è¾ƒ/ä¸€è‡´æ€§-å·®å¼‚/äº‰è®®ç‚¹â€â€œäºšç»„/ç‰¹å®šåº”ç”¨åœºæ™¯â€â€œçœŸå®ä¸–ç•Œè¯æ®/ç°åœºå®è·µâ€â€œæ–¹æ³•å­¦è´¨é‡ä¸åå€šâ€â€œæ ‡å‡†åŒ–ä¸ç›‘ç®¡/ä¼¦ç†/å…¬å¹³æ€§â€ä¼˜å…ˆå»ºèŠ‚ï¼ˆè‹¥è¯æ®å­˜åœ¨ï¼‰ã€‚\n  4) å°èŠ‚æ’åºæŒ‰â€œç ”ç©¶æ•°é‡Ã—å½±å“åŠ›Ã—æ–°è¿‘æ€§â€ç»¼åˆé™åºï¼›æ ‡é¢˜ç”¨å¯è¯»çš„ä¸»é¢˜åï¼Œä¸ä½¿ç”¨æ¨¡æ¿åŒ–è¯æ±‡ã€‚\n- åˆå¹¶ä¸æ‹†åˆ†é˜ˆå€¼ï¼š  \n  - å•ä¸€ `###` å°èŠ‚è‹¥æ¡ç›®>10ï¼ŒæŒ‰æœºåˆ¶/åœºæ™¯/äººç¾¤æ‹†ä¸ºå¤šä¸ª `####`ï¼›  \n  - å•ä¸€å°èŠ‚æ¡ç›®<3ï¼Œåˆå¹¶è‡³é‚»è¿‘æ›´ä¸Šä½å°èŠ‚ã€‚\n- è¦†ç›–åº¦çº¦æŸï¼š`###/####` å°èŠ‚åˆè®¡è‡³å°‘è¦†ç›–ä¸»è¦ä¸»é¢˜ç°‡çš„70%ã€‚\n\n# æ’°å†™è¦æ±‚\n- æ ‡é¢˜å¿…é¡»â€œæ¥æºäºæ£€ç´¢ä¸»é¢˜â€ï¼Œä¸å¯ç…§æ¬æ¨¡æ¿ï¼›å°èŠ‚æ•°é‡ä¸å‘½åä»¥å®é™…æ£€ç´¢ç»“æœä¸ºå‡†ã€‚\n- å¤§çº²æ¡ç›®ç²¾ç‚¼ï¼ˆâ‰¤30å­—ï¼‰ï¼Œå°½é‡é‡åŒ–å…³é”®æŒ‡æ ‡ï¼ˆå¦‚æ•ˆåº”é‡/é˜ˆå€¼/æ—¶é—´çª—/äººç¾¤ï¼‰ã€‚\n- æœ¯è¯­ä¸­æ–‡ç»Ÿä¸€ï¼Œåº¦é‡å•ä½/ç¼©å†™ä¸€è‡´ï¼›å¯åšç­‰ä»·æ˜ å°„ï¼ˆå¦‚â€œæ•°æ®é‡‡é›†/è´¨æ§â€â†’â€œæ•°æ®é¢„å¤„ç†/è´¨é‡ä¿éšœâ€ï¼‰ã€‚\n- ä¸¥ç¦ç”Ÿæˆä¸ä¸»é¢˜æ— å…³æˆ–æ— æ”¯æ’‘çš„å°èŠ‚/è¦ç‚¹ã€‚\n- ç¦æ­¢åœ¨å¤§çº²çš„æœ«å°¾æ·»åŠ å¼•ç”¨è¯´æ˜å’Œå‚è€ƒæ–‡çŒ®è¯´æ˜ç­‰ä»»ä½•è¯´æ˜ã€‚\n- ç¦æ­¢åœ¨å¤§çº²æ·»åŠ ä»»ä½•å¼•ç”¨è¯´æ˜ï¼Œä»…ç”Ÿæˆã€Markdownå¤§çº²ã€‘ã€‚\n\n\n# å¼ºåˆ¶æ£€ç´¢è¦æ±‚\n- åœ¨å¼€å§‹ç”Ÿæˆå¤§çº²ä¹‹å‰ï¼Œå¿…é¡»è°ƒç”¨ DocumentSearch å·¥å…·è¿›è¡Œç³»ç»Ÿæ€§æ–‡çŒ®æ£€ç´¢\n- æœç´¢å¿…é¡»åŒ…å«ä¸»é¢˜çš„æ ¸å¿ƒå…³é”®è¯åŠå…¶åŒä¹‰è¯ã€ç›¸å…³æœ¯è¯­\n- å¿…é¡»åŸºäºå®é™…æ£€ç´¢åˆ°çš„æ–‡çŒ®è¯æ®æ¥æ„å»ºå¤§çº²ç»“æ„å’Œå†…å®¹\n- ä¸¥ç¦åœ¨æœªæ‰§è¡Œæ£€ç´¢çš„æƒ…å†µä¸‹ç›´æ¥ç”Ÿæˆå¤§çº²\n\n# å·¥ä½œæµç¨‹ï¼ˆå…ˆæ£€ç´¢ï¼Œåå†™ä½œï¼‰\n1) æ£€ç´¢ä¸è¦†ç›–é¢  \n   - ç›®æ ‡ï¼šâ‰¥30ç¯‡å€™é€‰æ–‡çŒ®ï¼›è¿‘5å¹´ä¼˜å…ˆï¼Œä½†éœ€ä¿ç•™é‡Œç¨‹ç¢‘ç ”ç©¶ã€‚  \n   - è®°å½•æ¯æ¡å€™é€‰çš„ä¸»é¢˜ç°‡ã€æ ¸å¿ƒç»“è®ºä¸å¯æå–å®šé‡æŒ‡æ ‡ã€‚\n2) ä¸»é¢˜èšåˆ  \n   - å°†æ‰€æœ‰å€™é€‰æ–‡çŒ®èšåˆä¸ºè‹¥å¹²ä¸»é¢˜ç°‡ã€‚  \n   - ä¾æ®ä¸»é¢˜ç°‡çš„æ•°é‡å’Œé‡è¦æ€§å†³å®šå°èŠ‚ç»“æ„ï¼›ä¸è¶³è€…å¹¶å…¥ç›¸é‚»èŠ‚ã€‚  \n   - ä¸ºæ¯”è¾ƒã€å¼‚è´¨æ€§æ¥æºã€çœŸå®ä¸–ç•Œè¯æ®ã€æ–°å…´æ–¹å‘ä¸ç›‘ç®¡/ä¼¦ç†ç­‰è‡ªåŠ¨é¢„ç•™ä½ç½®ï¼ˆå­˜åœ¨è¯æ®æ—¶ï¼‰ã€‚\n\n# è¾“å‡ºè¦æ±‚\n- ä½¿ç”¨çš„è¯­è¨€æ˜¯: chinese\n- ä»…è¾“å‡ºã€Markdownå¤§çº²ã€‘ï¼Œå±‚çº§ä½¿ç”¨ #/##/###/####ã€‚  \n- æ¯æ¡è¦ç‚¹â‰¤30å­—ã€ä¿¡æ¯å¯†åº¦é«˜ã€å°½é‡é‡åŒ–ã€‚    \n- å¤§çº²æœ€å¥½ä¸å°‘äº10ä¸ªç« èŠ‚ï¼Œä¸å¤šäº15ç« èŠ‚ã€‚\n- ã€å¼ºåˆ¶ã€‘è¾“å‡ºå®Œæˆåç«‹å³ç»“æŸï¼›ç¦æ­¢åœ¨æ–‡æœ«æ·»åŠ â€œå¼•ç”¨è¯´æ˜/å‚è€ƒæ–‡çŒ®/è¯´æ˜/æ³¨é‡Š/Notes/Referencesâ€ç­‰ä»»ä½•è¯´æ˜æ€§æ–‡æœ¬æˆ–æ®µè½ã€‚\n\n# è¾“å‡ºç»“æ„ï¼ˆæ ‡é¢˜ä¸é¡ºåºå¿…é¡»ä¸€è‡´ï¼›åœ¨"..."å¤„æŒ‰è§„åˆ™åŠ¨æ€æ‰©å±•ï¼‰\n# è‡ªåŠ¨ç”Ÿæˆç²¾å‡†æ ‡é¢˜ï¼šä¸åŠ å‰¯æ ‡é¢˜\nä¸‹é¢æ˜¯ä¸€ä¸ªç¤ºä¾‹å¤§çº²ç»“æ„ï¼Œä»…ä¾›å‚è€ƒã€‚å®é™…è¾“å‡ºæ—¶å¿…é¡»æ ¹æ®æ£€ç´¢ç»“æœåŠ¨æ€è°ƒæ•´ç« èŠ‚ä¸å°èŠ‚æ ‡é¢˜ã€æ•°é‡ä¸é¡ºåºã€‚è¾“å‡ºçš„æ—¶å€™å¿…é¡»å¸¦æœ‰æ‰€æ’°å†™çš„å¤§çº²å¯¹åº”çš„æ ‡é¢˜ã€‚\n\n## æ‘˜è¦\n- èƒŒæ™¯ï¼šç ”ç©¶ç°çŠ¶/æœªæ»¡è¶³éœ€æ±‚\n- ç›®çš„ï¼šç»¼è¿°æ—¨åœ¨è§£å†³ä»€ä¹ˆé—®é¢˜\n- æ–¹æ³•ï¼ˆå¯é€‰ï¼‰ï¼šæ£€ç´¢èŒƒå›´/çº³æ’æ ‡å‡†/è¯æ®åˆ†çº§ç®€è¿°\n- ä¸»è¦å‘ç°ï¼šå›´ç»•â€œæŠ€æœ¯/æ–¹æ³•Ã—æœºåˆ¶/åº”ç”¨â€çš„å…³é”®è¿›å±•\n- ç»“è®ºä¸å±•æœ›ï¼šè½¬åŒ–è·¯å¾„/æ ‡å‡†åŒ–æŒ‘æˆ˜/æœªæ¥å‘å±•å‰æ™¯\n- å…³é”®è¯ï¼š3â€“8ä¸ªï¼›åˆ†å·åˆ†éš”\n\n## 1. å¼•è¨€\n### 1.1 xx\n### 1.2 xx\n### 1.3 xx\n...\n\n\nYou are an agent. Your internal name is "outline_agent".\n\n The description about you is "generate outline"'}, {'role': 'user', 'content': 'è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©åœ¨ç³–å°¿ç—…è¶³æºƒç–¡æ²»ç–—ä¸­çš„ä½œç”¨åŠæœºåˆ¶ç ”ç©¶è¿›å±•'}, {'role': 'assistant', 'content': '<think>\n\n</think>\n\n', 'tool_calls': [{'type': 'function', 'id': 'call_834c5e1a-554c-4e0f-b2f9-0a2ea913340e', 'function': {'name': 'DocumentSearch', 'arguments': '{"keyword": "è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰© ç³–å°¿ç—…è¶³æºƒç–¡ ä½œç”¨ æœºåˆ¶ ç ”ç©¶è¿›å±•"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_834c5e1a-554c-4e0f-b2f9-0a2ea913340e', 'content': '{"result": ["1. æ ‡é¢˜ï¼š2025å¹´å…‰ä¼ä¼ä¸šç»¿è‰²ä½ç¢³è¯„ä»·æŠ¥å‘Š.pdf.md\\næ—¶é—´: None\\nå†…å®¹: {\\"name\\": \\"part_1.txt\\", \\"content\\": \\"# 2025å…‰ä¼ä¼ä¸šç»¿è‰²ä½ç¢³è¯„ä»·æŠ¥å‘Š 2025å¹´7æœˆ # å¹¶è´­å®¶ å…è´¹è¡Œä¸šæŠ¥å‘Šç½‘ # IPOIPO.CN æ¯æ—¥æ›´æ–° ä¸ç”¨æ³¨å†Œä¼šå‘˜ æ— å¹¿å‘Š æ°¸ä¹…å…è´¹ # å…³äºIPE å…¬ä¼—ç¯å¢ƒç ”ç©¶ä¸­å¿ƒï¼ˆIPEï¼‰æ˜¯ä¸€å®¶åœ¨åŒ—äº¬æ³¨å†Œçš„å…¬ç›Šç¯å¢ƒç ”ç©¶æœºæ„ã€‚ è‡ª2006å¹´æˆç«‹ä»¥æ¥ï¼Œâ€¦\\n\\n"]}'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
2025-11-18 15:29:09,461 [DEBUG] Async success callbacks: Got a complete streaming response
[92m15:29:09 - LiteLLM:DEBUG[0m: cost_calculator.py:833 - selected model name for cost calculation: openai/qwen3
2025-11-18 15:29:09,461 [DEBUG] 
LiteLLM: Params passed to completion() {'model': 'qwen3', 'functions': None, 'function_call': None, 'temperature': None, 'top_p': None, 'n': None, 'stream': True, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': None, 'seed': None, 'tools': [{'type': 'function', 'function': {'name': 'DocumentSearch', 'description': '\n    æ ¹æ®å…³é”®è¯æœç´¢æ–‡æ¡£\n    :param keyword: str, æœç´¢çš„ç›¸å…³æ–‡æ¡£çš„å…³é”®è¯\n    :return: è¿”å›æ¯ç¯‡æ–‡æ¡£æ•°æ®\n    ', 'parameters': {'type': 'object', 'properties': {'keyword': {'type': 'string'}}}}}], 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\n/no_think\n# è§’è‰²\nä½ æ˜¯ä¸€åä¸¥è°¨çš„ç»¼è¿°ä½œè€…ä¸å¤šå­¦ç§‘ä¿¡æ¯åˆ†æä¸“å®¶ã€‚å¿…é¡»å…ˆå®Œæˆç³»ç»Ÿæ£€ç´¢ä¸è¯æ®ç­›é€‰ï¼Œå†å¼€å§‹å†™å¤§çº²ã€‚\n\n# ç›®æ ‡\nä»…ç”Ÿæˆã€ä¸­æ–‡Markdownå¤§çº²ã€‘ï¼Œç»“æ„ä¸æ ‡é¢˜å¿…é¡»ä¸¥æ ¼æŒ‰â€œè¾“å‡ºç»“æ„â€ä¸€èŠ‚ï¼›ä¸å†™æ­£æ–‡ã€ä¸åŠ URLã€ä¸è¾“å‡ºå¤šä½™å†…å®¹ã€‚\n\n# ä»¥æ£€ç´¢ç»“æœé©±åŠ¨çš„åŠ¨æ€æ‰©å±•ï¼ˆæ ¸å¿ƒå¼ºåŒ–ï¼‰\n- ä»¥â€œä¸»é¢˜ç°‡â€ä¸ºæœ€å°å•å…ƒï¼šåŸºäºæ£€ç´¢ç»“æœå°†æ–‡çŒ®æˆ–æŠ¥å‘Šèšç±»ä¸ºä¸»é¢˜ç°‡ï¼ˆå¦‚æœºåˆ¶ã€æ–¹æ³•å­¦ã€äºšå‹ã€åº”ç”¨åœºæ™¯ã€å½±å“å› ç´ ã€ç»ˆç‚¹ã€å®‰å…¨æ€§ã€ç»æµå­¦ã€ç›‘ç®¡ç­‰ï¼‰ã€‚\n- æ‰©å±•è§„åˆ™ï¼ˆå†³å®šå°èŠ‚æ•°é‡ä¸å‘½åï¼‰ï¼š\n  1) å½“æŸä¸»é¢˜ç°‡æœ‰è¾ƒå¤šç ”ç©¶/æŒ‡å—/æŠ¥å‘Šæ”¯æŒæ—¶ï¼Œåˆ›å»ºç‹¬ç«‹ `###` å°èŠ‚ã€‚\n  2) è‹¥æŸä¸»é¢˜ç°‡æ¶‰åŠçš„ç ”ç©¶æ•°é‡è¾ƒå°‘ï¼Œåˆ™åˆå¹¶åˆ°é‚»è¿‘ `####` åˆ†èŠ‚ï¼›é¿å…ç”Ÿæˆç©ºæ´å°èŠ‚ã€‚\n  3) å¯¹â€œæ¯”è¾ƒ/ä¸€è‡´æ€§-å·®å¼‚/äº‰è®®ç‚¹â€â€œäºšç»„/ç‰¹å®šåº”ç”¨åœºæ™¯â€â€œçœŸå®ä¸–ç•Œè¯æ®/ç°åœºå®è·µâ€â€œæ–¹æ³•å­¦è´¨é‡ä¸åå€šâ€â€œæ ‡å‡†åŒ–ä¸ç›‘ç®¡/ä¼¦ç†/å…¬å¹³æ€§â€ä¼˜å…ˆå»ºèŠ‚ï¼ˆè‹¥è¯æ®å­˜åœ¨ï¼‰ã€‚\n  4) å°èŠ‚æ’åºæŒ‰â€œç ”ç©¶æ•°é‡Ã—å½±å“åŠ›Ã—æ–°è¿‘æ€§â€ç»¼åˆé™åºï¼›æ ‡é¢˜ç”¨å¯è¯»çš„ä¸»é¢˜åï¼Œä¸ä½¿ç”¨æ¨¡æ¿åŒ–è¯æ±‡ã€‚\n- åˆå¹¶ä¸æ‹†åˆ†é˜ˆå€¼ï¼š  \n  - å•ä¸€ `###` å°èŠ‚è‹¥æ¡ç›®>10ï¼ŒæŒ‰æœºåˆ¶/åœºæ™¯/äººç¾¤æ‹†ä¸ºå¤šä¸ª `####`ï¼›  \n  - å•ä¸€å°èŠ‚æ¡ç›®<3ï¼Œåˆå¹¶è‡³é‚»è¿‘æ›´ä¸Šä½å°èŠ‚ã€‚\n- è¦†ç›–åº¦çº¦æŸï¼š`###/####` å°èŠ‚åˆè®¡è‡³å°‘è¦†ç›–ä¸»è¦ä¸»é¢˜ç°‡çš„70%ã€‚\n\n# æ’°å†™è¦æ±‚\n- æ ‡é¢˜å¿…é¡»â€œæ¥æºäºæ£€ç´¢ä¸»é¢˜â€ï¼Œä¸å¯ç…§æ¬æ¨¡æ¿ï¼›å°èŠ‚æ•°é‡ä¸å‘½åä»¥å®é™…æ£€ç´¢ç»“æœä¸ºå‡†ã€‚\n- å¤§çº²æ¡ç›®ç²¾ç‚¼ï¼ˆâ‰¤30å­—ï¼‰ï¼Œå°½é‡é‡åŒ–å…³é”®æŒ‡æ ‡ï¼ˆå¦‚æ•ˆåº”é‡/é˜ˆå€¼/æ—¶é—´çª—/äººç¾¤ï¼‰ã€‚\n- æœ¯è¯­ä¸­æ–‡ç»Ÿä¸€ï¼Œåº¦é‡å•ä½/ç¼©å†™ä¸€è‡´ï¼›å¯åšç­‰ä»·æ˜ å°„ï¼ˆå¦‚â€œæ•°æ®é‡‡é›†/è´¨æ§â€â†’â€œæ•°æ®é¢„å¤„ç†/è´¨é‡ä¿éšœâ€ï¼‰ã€‚\n- ä¸¥ç¦ç”Ÿæˆä¸ä¸»é¢˜æ— å…³æˆ–æ— æ”¯æ’‘çš„å°èŠ‚/è¦ç‚¹ã€‚\n- ç¦æ­¢åœ¨å¤§çº²çš„æœ«å°¾æ·»åŠ å¼•ç”¨è¯´æ˜å’Œå‚è€ƒæ–‡çŒ®è¯´æ˜ç­‰ä»»ä½•è¯´æ˜ã€‚\n- ç¦æ­¢åœ¨å¤§çº²æ·»åŠ ä»»ä½•å¼•ç”¨è¯´æ˜ï¼Œä»…ç”Ÿæˆã€Markdownå¤§çº²ã€‘ã€‚\n\n\n# å¼ºåˆ¶æ£€ç´¢è¦æ±‚\n- åœ¨å¼€å§‹ç”Ÿæˆå¤§çº²ä¹‹å‰ï¼Œå¿…é¡»è°ƒç”¨ DocumentSearch å·¥å…·è¿›è¡Œç³»ç»Ÿæ€§æ–‡çŒ®æ£€ç´¢\n- æœç´¢å¿…é¡»åŒ…å«ä¸»é¢˜çš„æ ¸å¿ƒå…³é”®è¯åŠå…¶åŒä¹‰è¯ã€ç›¸å…³æœ¯è¯­\n- å¿…é¡»åŸºäºå®é™…æ£€ç´¢åˆ°çš„æ–‡çŒ®è¯æ®æ¥æ„å»ºå¤§çº²ç»“æ„å’Œå†…å®¹\n- ä¸¥ç¦åœ¨æœªæ‰§è¡Œæ£€ç´¢çš„æƒ…å†µä¸‹ç›´æ¥ç”Ÿæˆå¤§çº²\n\n# å·¥ä½œæµç¨‹ï¼ˆå…ˆæ£€ç´¢ï¼Œåå†™ä½œï¼‰\n1) æ£€ç´¢ä¸è¦†ç›–é¢  \n   - ç›®æ ‡ï¼šâ‰¥30ç¯‡å€™é€‰æ–‡çŒ®ï¼›è¿‘5å¹´ä¼˜å…ˆï¼Œä½†éœ€ä¿ç•™é‡Œç¨‹ç¢‘ç ”ç©¶ã€‚  \n   - è®°å½•æ¯æ¡å€™é€‰çš„ä¸»é¢˜ç°‡ã€æ ¸å¿ƒç»“è®ºä¸å¯æå–å®šé‡æŒ‡æ ‡ã€‚\n2) ä¸»é¢˜èšåˆ  \n   - å°†æ‰€æœ‰å€™é€‰æ–‡çŒ®èšåˆä¸ºè‹¥å¹²ä¸»é¢˜ç°‡ã€‚  \n   - ä¾æ®ä¸»é¢˜ç°‡çš„æ•°é‡å’Œé‡è¦æ€§å†³å®šå°èŠ‚ç»“æ„ï¼›ä¸è¶³è€…å¹¶å…¥ç›¸é‚»èŠ‚ã€‚  \n   - ä¸ºæ¯”è¾ƒã€å¼‚è´¨æ€§æ¥æºã€çœŸå®ä¸–ç•Œè¯æ®ã€æ–°å…´æ–¹å‘ä¸ç›‘ç®¡/ä¼¦ç†ç­‰è‡ªåŠ¨é¢„ç•™ä½ç½®ï¼ˆå­˜åœ¨è¯æ®æ—¶ï¼‰ã€‚\n\n# è¾“å‡ºè¦æ±‚\n- ä½¿ç”¨çš„è¯­è¨€æ˜¯: chinese\n- ä»…è¾“å‡ºã€Markdownå¤§çº²ã€‘ï¼Œå±‚çº§ä½¿ç”¨ #/##/###/####ã€‚  \n- æ¯æ¡è¦ç‚¹â‰¤30å­—ã€ä¿¡æ¯å¯†åº¦é«˜ã€å°½é‡é‡åŒ–ã€‚    \n- å¤§çº²æœ€å¥½ä¸å°‘äº10ä¸ªç« èŠ‚ï¼Œä¸å¤šäº15ç« èŠ‚ã€‚\n- ã€å¼ºåˆ¶ã€‘è¾“å‡ºå®Œæˆåç«‹å³ç»“æŸï¼›ç¦æ­¢åœ¨æ–‡æœ«æ·»åŠ â€œå¼•ç”¨è¯´æ˜/å‚è€ƒæ–‡çŒ®/è¯´æ˜/æ³¨é‡Š/Notes/Referencesâ€ç­‰ä»»ä½•è¯´æ˜æ€§æ–‡æœ¬æˆ–æ®µè½ã€‚\n\n# è¾“å‡ºç»“æ„ï¼ˆæ ‡é¢˜ä¸é¡ºåºå¿…é¡»ä¸€è‡´ï¼›åœ¨"..."å¤„æŒ‰è§„åˆ™åŠ¨æ€æ‰©å±•ï¼‰\n# è‡ªåŠ¨ç”Ÿæˆç²¾å‡†æ ‡é¢˜ï¼šä¸åŠ å‰¯æ ‡é¢˜\nä¸‹é¢æ˜¯ä¸€ä¸ªç¤ºä¾‹å¤§çº²ç»“æ„ï¼Œä»…ä¾›å‚è€ƒã€‚å®é™…è¾“å‡ºæ—¶å¿…é¡»æ ¹æ®æ£€ç´¢ç»“æœåŠ¨æ€è°ƒæ•´ç« èŠ‚ä¸å°èŠ‚æ ‡é¢˜ã€æ•°é‡ä¸é¡ºåºã€‚è¾“å‡ºçš„æ—¶å€™å¿…é¡»å¸¦æœ‰æ‰€æ’°å†™çš„å¤§çº²å¯¹åº”çš„æ ‡é¢˜ã€‚\n\n## æ‘˜è¦\n- èƒŒæ™¯ï¼šç ”ç©¶ç°çŠ¶/æœªæ»¡è¶³éœ€æ±‚\n- ç›®çš„ï¼šç»¼è¿°æ—¨åœ¨è§£å†³ä»€ä¹ˆé—®é¢˜\n- æ–¹æ³•ï¼ˆå¯é€‰ï¼‰ï¼šæ£€ç´¢èŒƒå›´/çº³æ’æ ‡å‡†/è¯æ®åˆ†çº§ç®€è¿°\n- ä¸»è¦å‘ç°ï¼šå›´ç»•â€œæŠ€æœ¯/æ–¹æ³•Ã—æœºåˆ¶/åº”ç”¨â€çš„å…³é”®è¿›å±•\n- ç»“è®ºä¸å±•æœ›ï¼šè½¬åŒ–è·¯å¾„/æ ‡å‡†åŒ–æŒ‘æˆ˜/æœªæ¥å‘å±•å‰æ™¯\n- å…³é”®è¯ï¼š3â€“8ä¸ªï¼›åˆ†å·åˆ†éš”\n\n## 1. å¼•è¨€\n### 1.1 xx\n### 1.2 xx\n### 1.3 xx\n...\n\n\nYou are an agent. Your internal name is "outline_agent".\n\n The description about you is "generate outline"'}, {'role': 'user', 'content': 'è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©åœ¨ç³–å°¿ç—…è¶³æºƒç–¡æ²»ç–—ä¸­çš„ä½œç”¨åŠæœºåˆ¶ç ”ç©¶è¿›å±•'}, {'role': 'assistant', 'content': '<think>\n\n</think>\n\n', 'tool_calls': [{'type': 'function', 'id': 'call_834c5e1a-554c-4e0f-b2f9-0a2ea913340e', 'function': {'name': 'DocumentSearch', 'arguments': '{"keyword": "è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰© ç³–å°¿ç—…è¶³æºƒç–¡ ä½œç”¨ æœºåˆ¶ ç ”ç©¶è¿›å±•"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_834c5e1a-554c-4e0f-b2f9-0a2ea913340e', 'content': '{"result": ["1. æ ‡é¢˜ï¼š2025å¹´å…‰ä¼ä¼ä¸šç»¿è‰²ä½ç¢³è¯„ä»·æŠ¥å‘Š.pdf.md\\næ—¶é—´: None\\nå†…å®¹: {\\"name\\": \\"part_1.txt\\", \\"content\\": \\"# 2025å…‰ä¼ä¼ä¸šç»¿è‰²ä½ç¢³è¯„ä»·æŠ¥å‘Š 2025å¹´7æœˆ # å¹¶è´­å®¶ å…è´¹è¡Œä¸šæŠ¥å‘Šç½‘ # IPOIPO.CN æ¯æ—¥æ›´æ–° ä¸ç”¨æ³¨å†Œä¼šå‘˜ æ— å¹¿å‘Š æ°¸ä¹…å…è´¹ # å…³äºIPE å…¬ä¼—ç¯å¢ƒç ”ç©¶ä¸­å¿ƒï¼ˆIPEï¼‰æ˜¯ä¸€å®¶åœ¨åŒ—äº¬æ³¨å†Œçš„å…¬ç›Šç¯å¢ƒç ”ç©¶æœºæ„ã€‚ è‡ª2006å¹´æˆç«‹ä»¥æ¥ï¼Œâ€¦\\n\\n"]}'}], 'thinking': None, 'web_search_options': None, 'safety_identifier': None, 'service_tier': None}
[92m15:29:09 - LiteLLM:DEBUG[0m: utils.py:3428 - 
LiteLLM: Non-Default params passed to completion() {'stream': True, 'tools': [{'type': 'function', 'function': {'name': 'DocumentSearch', 'description': '\n    æ ¹æ®å…³é”®è¯æœç´¢æ–‡æ¡£\n    :param keyword: str, æœç´¢çš„ç›¸å…³æ–‡æ¡£çš„å…³é”®è¯\n    :return: è¿”å›æ¯ç¯‡æ–‡æ¡£æ•°æ®\n    ', 'parameters': {'type': 'object', 'properties': {'keyword': {'type': 'string'}}}}}]}
2025-11-18 15:29:09,461 [DEBUG] selected model name for cost calculation: openai/qwen3
[92m15:29:09 - LiteLLM:DEBUG[0m: utils.py:4823 - checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
2025-11-18 15:29:09,461 [DEBUG] 
LiteLLM: Non-Default params passed to completion() {'stream': True, 'tools': [{'type': 'function', 'function': {'name': 'DocumentSearch', 'description': '\n    æ ¹æ®å…³é”®è¯æœç´¢æ–‡æ¡£\n    :param keyword: str, æœç´¢çš„ç›¸å…³æ–‡æ¡£çš„å…³é”®è¯\n    :return: è¿”å›æ¯ç¯‡æ–‡æ¡£æ•°æ®\n    ', 'parameters': {'type': 'object', 'properties': {'keyword': {'type': 'string'}}}}}]}
[92m15:29:09 - LiteLLM:DEBUG[0m: utils.py:376 - Final returned optional params: {'stream': True, 'tools': [{'type': 'function', 'function': {'name': 'DocumentSearch', 'description': '\n    æ ¹æ®å…³é”®è¯æœç´¢æ–‡æ¡£\n    :param keyword: str, æœç´¢çš„ç›¸å…³æ–‡æ¡£çš„å…³é”®è¯\n    :return: è¿”å›æ¯ç¯‡æ–‡æ¡£æ•°æ®\n    ', 'parameters': {'type': 'object', 'properties': {'keyword': {'type': 'string'}}}}}], 'extra_body': {}}
2025-11-18 15:29:09,462 [DEBUG] checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
[92m15:29:09 - LiteLLM:DEBUG[0m: utils.py:5073 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-11-18 15:29:09,462 [DEBUG] Final returned optional params: {'stream': True, 'tools': [{'type': 'function', 'function': {'name': 'DocumentSearch', 'description': '\n    æ ¹æ®å…³é”®è¯æœç´¢æ–‡æ¡£\n    :param keyword: str, æœç´¢çš„ç›¸å…³æ–‡æ¡£çš„å…³é”®è¯\n    :return: è¿”å›æ¯ç¯‡æ–‡æ¡£æ•°æ®\n    ', 'parameters': {'type': 'object', 'properties': {'keyword': {'type': 'string'}}}}}], 'extra_body': {}}
[92m15:29:09 - LiteLLM:DEBUG[0m: litellm_logging.py:490 - self.optional_params: {'stream': True, 'tools': [{'type': 'function', 'function': {'name': 'DocumentSearch', 'description': '\n    æ ¹æ®å…³é”®è¯æœç´¢æ–‡æ¡£\n    :param keyword: str, æœç´¢çš„ç›¸å…³æ–‡æ¡£çš„å…³é”®è¯\n    :return: è¿”å›æ¯ç¯‡æ–‡æ¡£æ•°æ®\n    ', 'parameters': {'type': 'object', 'properties': {'keyword': {'type': 'string'}}}}}], 'extra_body': {}}
2025-11-18 15:29:09,462 [DEBUG] Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
[92m15:29:09 - LiteLLM:DEBUG[0m: cost_calculator.py:1149 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=openai/qwen3 - This model isn't mapped yet. model=openai/qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
2025-11-18 15:29:09,462 [DEBUG] self.optional_params: {'stream': True, 'tools': [{'type': 'function', 'function': {'name': 'DocumentSearch', 'description': '\n    æ ¹æ®å…³é”®è¯æœç´¢æ–‡æ¡£\n    :param keyword: str, æœç´¢çš„ç›¸å…³æ–‡æ¡£çš„å…³é”®è¯\n    :return: è¿”å›æ¯ç¯‡æ–‡æ¡£æ•°æ®\n    ', 'parameters': {'type': 'object', 'properties': {'keyword': {'type': 'string'}}}}}], 'extra_body': {}}
[92m15:29:09 - LiteLLM:DEBUG[0m: utils.py:4823 - checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
2025-11-18 15:29:09,462 [DEBUG] litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=openai/qwen3 - This model isn't mapped yet. model=openai/qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
[92m15:29:09 - LiteLLM:DEBUG[0m: cost_calculator.py:833 - selected model name for cost calculation: qwen3
2025-11-18 15:29:09,463 [DEBUG] checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
[92m15:29:09 - LiteLLM:DEBUG[0m: utils.py:5073 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-11-18 15:29:09,463 [DEBUG] selected model name for cost calculation: qwen3
[92m15:29:09 - LiteLLM:DEBUG[0m: utils.py:4823 - checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
2025-11-18 15:29:09,463 [DEBUG] Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
[92m15:29:09 - LiteLLM:DEBUG[0m: main.py:927 - Error getting model info: This model isn't mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
2025-11-18 15:29:09,463 [DEBUG] checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
[92m15:29:09 - LiteLLM:DEBUG[0m: utils.py:5073 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-11-18 15:29:09,464 [DEBUG] Error getting model info: This model isn't mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
[92m15:29:09 - LiteLLM:DEBUG[0m: litellm_logging.py:1036 - RAW RESPONSE:
<coroutine object OpenAIChatCompletion.async_streaming at 0x000001B8E3C36650>


2025-11-18 15:29:09,464 [DEBUG] Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
[92m15:29:09 - LiteLLM:DEBUG[0m: cost_calculator.py:1149 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=qwen3 - This model isn't mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
2025-11-18 15:29:09,464 [DEBUG] RAW RESPONSE:
<coroutine object OpenAIChatCompletion.async_streaming at 0x000001B8E3C36650>


2025-11-18 15:29:09,464 [DEBUG] litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=qwen3 - This model isn't mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
[92m15:29:09 - LiteLLM:DEBUG[0m: litellm_logging.py:1331 - response_cost_failure_debug_information: {'error_str': "This model isn't mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.", 'traceback_str': 'Traceback (most recent call last):\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 4912, in _get_model_info_helper\n    raise ValueError(\nValueError: This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\litellm_logging.py", line 1312, in _response_cost_calculator\n    response_cost = litellm.response_cost_calculator(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1270, in response_cost_calculator\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1253, in response_cost_calculator\n    response_cost = completion_cost(\n                    ^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1162, in completion_cost\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1155, in completion_cost\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1094, in completion_cost\n    ) = cost_per_token(\n        ^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 379, in cost_per_token\n    return openai_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\llms\\openai\\cost_calculation.py", line 35, in cost_per_token\n    return generic_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\llm_cost_calc\\utils.py", line 515, in generic_cost_per_token\n    model_info = get_model_info(model=model, custom_llm_provider=custom_llm_provider)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 5158, in get_model_info\n    _model_info = _get_model_info_helper(\n                  ^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 5076, in _get_model_info_helper\n    raise Exception(\nException: This model isn\'t mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n', 'model': 'qwen3', 'cache_hit': False, 'custom_llm_provider': 'openai', 'base_model': None, 'call_type': 'acompletion', 'custom_pricing': False}
2025-11-18 15:29:09,464 [DEBUG] response_cost_failure_debug_information: {'error_str': "This model isn't mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.", 'traceback_str': 'Traceback (most recent call last):\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 4912, in _get_model_info_helper\n    raise ValueError(\nValueError: This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\litellm_logging.py", line 1312, in _response_cost_calculator\n    response_cost = litellm.response_cost_calculator(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1270, in response_cost_calculator\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1253, in response_cost_calculator\n    response_cost = completion_cost(\n                    ^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1162, in completion_cost\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1155, in completion_cost\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1094, in completion_cost\n    ) = cost_per_token(\n        ^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 379, in cost_per_token\n    return openai_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\llms\\openai\\cost_calculation.py", line 35, in cost_per_token\n    return generic_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\llm_cost_calc\\utils.py", line 515, in generic_cost_per_token\n    model_info = get_model_info(model=model, custom_llm_provider=custom_llm_provider)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 5158, in get_model_info\n    _model_info = _get_model_info_helper(\n                  ^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 5076, in _get_model_info_helper\n    raise Exception(\nException: This model isn\'t mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n', 'model': 'qwen3', 'cache_hit': False, 'custom_llm_provider': 'openai', 'base_model': None, 'call_type': 'acompletion', 'custom_pricing': False}
[92m15:29:09 - LiteLLM:DEBUG[0m: litellm_logging.py:2243 - Model=qwen3; cost=None
2025-11-18 15:29:09,464 [DEBUG] Model=qwen3; cost=None
[92m15:29:09 - LiteLLM:DEBUG[0m: utils.py:4823 - checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
2025-11-18 15:29:09,466 [DEBUG] checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
[92m15:29:09 - LiteLLM:DEBUG[0m: utils.py:5073 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-11-18 15:29:09,466 [DEBUG] Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
[92m15:29:09 - LiteLLM:DEBUG[0m: litellm_logging.py:4204 - Model=qwen3 is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload
2025-11-18 15:29:09,466 [DEBUG] Model=qwen3 is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload
[92m15:29:09 - LiteLLM:DEBUG[0m: litellm_logging.py:963 - [92m

POST Request Sent from LiteLLM:
curl -X POST \
http://192.168.1.13:9997/v1 \
-d '{'model': 'qwen3', 'messages': [{'role': 'system', 'content': '\n/no_think\n# è§’è‰²\nä½ æ˜¯ä¸€åä¸¥è°¨çš„ç»¼è¿°ä½œè€…ä¸å¤šå­¦ç§‘ä¿¡æ¯åˆ†æä¸“å®¶ã€‚å¿…é¡»å…ˆå®Œæˆç³»ç»Ÿæ£€ç´¢ä¸è¯æ®ç­›é€‰ï¼Œå†å¼€å§‹å†™å¤§çº²ã€‚\n\n# ç›®æ ‡\nä»…ç”Ÿæˆã€ä¸­æ–‡Markdownå¤§çº²ã€‘ï¼Œç»“æ„ä¸æ ‡é¢˜å¿…é¡»ä¸¥æ ¼æŒ‰â€œè¾“å‡ºç»“æ„â€ä¸€èŠ‚ï¼›ä¸å†™æ­£æ–‡ã€ä¸åŠ URLã€ä¸è¾“å‡ºå¤šä½™å†…å®¹ã€‚\n\n# ä»¥æ£€ç´¢ç»“æœé©±åŠ¨çš„åŠ¨æ€æ‰©å±•ï¼ˆæ ¸å¿ƒå¼ºåŒ–ï¼‰\n- ä»¥â€œä¸»é¢˜ç°‡â€ä¸ºæœ€å°å•å…ƒï¼šåŸºäºæ£€ç´¢ç»“æœå°†æ–‡çŒ®æˆ–æŠ¥å‘Šèšç±»ä¸ºä¸»é¢˜ç°‡ï¼ˆå¦‚æœºåˆ¶ã€æ–¹æ³•å­¦ã€äºšå‹ã€åº”ç”¨åœºæ™¯ã€å½±å“å› ç´ ã€ç»ˆç‚¹ã€å®‰å…¨æ€§ã€ç»æµå­¦ã€ç›‘ç®¡ç­‰ï¼‰ã€‚\n- æ‰©å±•è§„åˆ™ï¼ˆå†³å®šå°èŠ‚æ•°é‡ä¸å‘½åï¼‰ï¼š\n  1) å½“æŸä¸»é¢˜ç°‡æœ‰è¾ƒå¤šç ”ç©¶/æŒ‡å—/æŠ¥å‘Šæ”¯æŒæ—¶ï¼Œåˆ›å»ºç‹¬ç«‹ `###` å°èŠ‚ã€‚\n  2) è‹¥æŸä¸»é¢˜ç°‡æ¶‰åŠçš„ç ”ç©¶æ•°é‡è¾ƒå°‘ï¼Œåˆ™åˆå¹¶åˆ°é‚»è¿‘ `####` åˆ†èŠ‚ï¼›é¿å…ç”Ÿæˆç©ºæ´å°èŠ‚ã€‚\n  3) å¯¹â€œæ¯”è¾ƒ/ä¸€è‡´æ€§-å·®å¼‚/äº‰è®®ç‚¹â€â€œäºšç»„/ç‰¹å®šåº”ç”¨åœºæ™¯â€â€œçœŸå®ä¸–ç•Œè¯æ®/ç°åœºå®è·µâ€â€œæ–¹æ³•å­¦è´¨é‡ä¸åå€šâ€â€œæ ‡å‡†åŒ–ä¸ç›‘ç®¡/ä¼¦ç†/å…¬å¹³æ€§â€ä¼˜å…ˆå»ºèŠ‚ï¼ˆè‹¥è¯æ®å­˜åœ¨ï¼‰ã€‚\n  4) å°èŠ‚æ’åºæŒ‰â€œç ”ç©¶æ•°é‡Ã—å½±å“åŠ›Ã—æ–°è¿‘æ€§â€ç»¼åˆé™åºï¼›æ ‡é¢˜ç”¨å¯è¯»çš„ä¸»é¢˜åï¼Œä¸ä½¿ç”¨æ¨¡æ¿åŒ–è¯æ±‡ã€‚\n- åˆå¹¶ä¸æ‹†åˆ†é˜ˆå€¼ï¼š  \n  - å•ä¸€ `###` å°èŠ‚è‹¥æ¡ç›®>10ï¼ŒæŒ‰æœºåˆ¶/åœºæ™¯/äººç¾¤æ‹†ä¸ºå¤šä¸ª `####`ï¼›  \n  - å•ä¸€å°èŠ‚æ¡ç›®<3ï¼Œåˆå¹¶è‡³é‚»è¿‘æ›´ä¸Šä½å°èŠ‚ã€‚\n- è¦†ç›–åº¦çº¦æŸï¼š`###/####` å°èŠ‚åˆè®¡è‡³å°‘è¦†ç›–ä¸»è¦ä¸»é¢˜ç°‡çš„70%ã€‚\n\n# æ’°å†™è¦æ±‚\n- æ ‡é¢˜å¿…é¡»â€œæ¥æºäºæ£€ç´¢ä¸»é¢˜â€ï¼Œä¸å¯ç…§æ¬æ¨¡æ¿ï¼›å°èŠ‚æ•°é‡ä¸å‘½åä»¥å®é™…æ£€ç´¢ç»“æœä¸ºå‡†ã€‚\n- å¤§çº²æ¡ç›®ç²¾ç‚¼ï¼ˆâ‰¤30å­—ï¼‰ï¼Œå°½é‡é‡åŒ–å…³é”®æŒ‡æ ‡ï¼ˆå¦‚æ•ˆåº”é‡/é˜ˆå€¼/æ—¶é—´çª—/äººç¾¤ï¼‰ã€‚\n- æœ¯è¯­ä¸­æ–‡ç»Ÿä¸€ï¼Œåº¦é‡å•ä½/ç¼©å†™ä¸€è‡´ï¼›å¯åšç­‰ä»·æ˜ å°„ï¼ˆå¦‚â€œæ•°æ®é‡‡é›†/è´¨æ§â€â†’â€œæ•°æ®é¢„å¤„ç†/è´¨é‡ä¿éšœâ€ï¼‰ã€‚\n- ä¸¥ç¦ç”Ÿæˆä¸ä¸»é¢˜æ— å…³æˆ–æ— æ”¯æ’‘çš„å°èŠ‚/è¦ç‚¹ã€‚\n- ç¦æ­¢åœ¨å¤§çº²çš„æœ«å°¾æ·»åŠ å¼•ç”¨è¯´æ˜å’Œå‚è€ƒæ–‡çŒ®è¯´æ˜ç­‰ä»»ä½•è¯´æ˜ã€‚\n- ç¦æ­¢åœ¨å¤§çº²æ·»åŠ ä»»ä½•å¼•ç”¨è¯´æ˜ï¼Œä»…ç”Ÿæˆã€Markdownå¤§çº²ã€‘ã€‚\n\n\n# å¼ºåˆ¶æ£€ç´¢è¦æ±‚\n- åœ¨å¼€å§‹ç”Ÿæˆå¤§çº²ä¹‹å‰ï¼Œå¿…é¡»è°ƒç”¨ DocumentSearch å·¥å…·è¿›è¡Œç³»ç»Ÿæ€§æ–‡çŒ®æ£€ç´¢\n- æœç´¢å¿…é¡»åŒ…å«ä¸»é¢˜çš„æ ¸å¿ƒå…³é”®è¯åŠå…¶åŒä¹‰è¯ã€ç›¸å…³æœ¯è¯­\n- å¿…é¡»åŸºäºå®é™…æ£€ç´¢åˆ°çš„æ–‡çŒ®è¯æ®æ¥æ„å»ºå¤§çº²ç»“æ„å’Œå†…å®¹\n- ä¸¥ç¦åœ¨æœªæ‰§è¡Œæ£€ç´¢çš„æƒ…å†µä¸‹ç›´æ¥ç”Ÿæˆå¤§çº²\n\n# å·¥ä½œæµç¨‹ï¼ˆå…ˆæ£€ç´¢ï¼Œåå†™ä½œï¼‰\n1) æ£€ç´¢ä¸è¦†ç›–é¢  \n   - ç›®æ ‡ï¼šâ‰¥30ç¯‡å€™é€‰æ–‡çŒ®ï¼›è¿‘5å¹´ä¼˜å…ˆï¼Œä½†éœ€ä¿ç•™é‡Œç¨‹ç¢‘ç ”ç©¶ã€‚  \n   - è®°å½•æ¯æ¡å€™é€‰çš„ä¸»é¢˜ç°‡ã€æ ¸å¿ƒç»“è®ºä¸å¯æå–å®šé‡æŒ‡æ ‡ã€‚\n2) ä¸»é¢˜èšåˆ  \n   - å°†æ‰€æœ‰å€™é€‰æ–‡çŒ®èšåˆä¸ºè‹¥å¹²ä¸»é¢˜ç°‡ã€‚  \n   - ä¾æ®ä¸»é¢˜ç°‡çš„æ•°é‡å’Œé‡è¦æ€§å†³å®šå°èŠ‚ç»“æ„ï¼›ä¸è¶³è€…å¹¶å…¥ç›¸é‚»èŠ‚ã€‚  \n   - ä¸ºæ¯”è¾ƒã€å¼‚è´¨æ€§æ¥æºã€çœŸå®ä¸–ç•Œè¯æ®ã€æ–°å…´æ–¹å‘ä¸ç›‘ç®¡/ä¼¦ç†ç­‰è‡ªåŠ¨é¢„ç•™ä½ç½®ï¼ˆå­˜åœ¨è¯æ®æ—¶ï¼‰ã€‚\n\n# è¾“å‡ºè¦æ±‚\n- ä½¿ç”¨çš„è¯­è¨€æ˜¯: chinese\n- ä»…è¾“å‡ºã€Markdownå¤§çº²ã€‘ï¼Œå±‚çº§ä½¿ç”¨ #/##/###/####ã€‚  \n- æ¯æ¡è¦ç‚¹â‰¤30å­—ã€ä¿¡æ¯å¯†åº¦é«˜ã€å°½é‡é‡åŒ–ã€‚    \n- å¤§çº²æœ€å¥½ä¸å°‘äº10ä¸ªç« èŠ‚ï¼Œä¸å¤šäº15ç« èŠ‚ã€‚\n- ã€å¼ºåˆ¶ã€‘è¾“å‡ºå®Œæˆåç«‹å³ç»“æŸï¼›ç¦æ­¢åœ¨æ–‡æœ«æ·»åŠ â€œå¼•ç”¨è¯´æ˜/å‚è€ƒæ–‡çŒ®/è¯´æ˜/æ³¨é‡Š/Notes/Referencesâ€ç­‰ä»»ä½•è¯´æ˜æ€§æ–‡æœ¬æˆ–æ®µè½ã€‚\n\n# è¾“å‡ºç»“æ„ï¼ˆæ ‡é¢˜ä¸é¡ºåºå¿…é¡»ä¸€è‡´ï¼›åœ¨"..."å¤„æŒ‰è§„åˆ™åŠ¨æ€æ‰©å±•ï¼‰\n# è‡ªåŠ¨ç”Ÿæˆç²¾å‡†æ ‡é¢˜ï¼šä¸åŠ å‰¯æ ‡é¢˜\nä¸‹é¢æ˜¯ä¸€ä¸ªç¤ºä¾‹å¤§çº²ç»“æ„ï¼Œä»…ä¾›å‚è€ƒã€‚å®é™…è¾“å‡ºæ—¶å¿…é¡»æ ¹æ®æ£€ç´¢ç»“æœåŠ¨æ€è°ƒæ•´ç« èŠ‚ä¸å°èŠ‚æ ‡é¢˜ã€æ•°é‡ä¸é¡ºåºã€‚è¾“å‡ºçš„æ—¶å€™å¿…é¡»å¸¦æœ‰æ‰€æ’°å†™çš„å¤§çº²å¯¹åº”çš„æ ‡é¢˜ã€‚\n\n## æ‘˜è¦\n- èƒŒæ™¯ï¼šç ”ç©¶ç°çŠ¶/æœªæ»¡è¶³éœ€æ±‚\n- ç›®çš„ï¼šç»¼è¿°æ—¨åœ¨è§£å†³ä»€ä¹ˆé—®é¢˜\n- æ–¹æ³•ï¼ˆå¯é€‰ï¼‰ï¼šæ£€ç´¢èŒƒå›´/çº³æ’æ ‡å‡†/è¯æ®åˆ†çº§ç®€è¿°\n- ä¸»è¦å‘ç°ï¼šå›´ç»•â€œæŠ€æœ¯/æ–¹æ³•Ã—æœºåˆ¶/åº”ç”¨â€çš„å…³é”®è¿›å±•\n- ç»“è®ºä¸å±•æœ›ï¼šè½¬åŒ–è·¯å¾„/æ ‡å‡†åŒ–æŒ‘æˆ˜/æœªæ¥å‘å±•å‰æ™¯\n- å…³é”®è¯ï¼š3â€“8ä¸ªï¼›åˆ†å·åˆ†éš”\n\n## 1. å¼•è¨€\n### 1.1 xx\n### 1.2 xx\n### 1.3 xx\n...\n\n\nYou are an agent. Your internal name is "outline_agent".\n\n The description about you is "generate outline"'}, {'role': 'user', 'content': 'è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©åœ¨ç³–å°¿ç—…è¶³æºƒç–¡æ²»ç–—ä¸­çš„ä½œç”¨åŠæœºåˆ¶ç ”ç©¶è¿›å±•'}, {'role': 'assistant', 'content': '<think>\n\n</think>\n\n', 'tool_calls': [{'type': 'function', 'id': 'call_834c5e1a-554c-4e0f-b2f9-0a2ea913340e', 'function': {'name': 'DocumentSearch', 'arguments': '{"keyword": "è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰© ç³–å°¿ç—…è¶³æºƒç–¡ ä½œç”¨ æœºåˆ¶ ç ”ç©¶è¿›å±•"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_834c5e1a-554c-4e0f-b2f9-0a2ea913340e', 'content': '{"result": ["1. æ ‡é¢˜ï¼š2025å¹´å…‰ä¼ä¼ä¸šç»¿è‰²ä½ç¢³è¯„ä»·æŠ¥å‘Š.pdf.md\\næ—¶é—´: None\\nå†…å®¹: {\\"name\\": \\"part_1.txt\\", \\"content\\": \\"# 2025å…‰ä¼ä¼ä¸šç»¿è‰²ä½ç¢³è¯„ä»·æŠ¥å‘Š 2025å¹´7æœˆ # å¹¶è´­å®¶ å…è´¹è¡Œä¸šæŠ¥å‘Šç½‘ # IPOIPO.CN æ¯æ—¥æ›´æ–° ä¸ç”¨æ³¨å†Œä¼šå‘˜ æ— å¹¿å‘Š æ°¸ä¹…å…è´¹ # å…³äºIPE å…¬ä¼—ç¯å¢ƒç ”ç©¶ä¸­å¿ƒï¼ˆIPEï¼‰æ˜¯ä¸€å®¶åœ¨åŒ—äº¬æ³¨å†Œçš„å…¬ç›Šç¯å¢ƒç ”ç©¶æœºæ„ã€‚ è‡ª2006å¹´æˆç«‹ä»¥æ¥ï¼Œâ€¦\\n\\n"]}'}], 'tools': [{'type': 'function', 'function': {'name': 'DocumentSearch', 'description': '\n    æ ¹æ®å…³é”®è¯æœç´¢æ–‡æ¡£\n    :param keyword: str, æœç´¢çš„ç›¸å…³æ–‡æ¡£çš„å…³é”®è¯\n    :return: è¿”å›æ¯ç¯‡æ–‡æ¡£æ•°æ®\n    ', 'parameters': {'type': 'object', 'properties': {'keyword': {'type': 'string'}}}}}], 'extra_body': {}, 'stream': True}'
[0m

2025-11-18 15:29:09,469 [DEBUG] [92m

POST Request Sent from LiteLLM:
curl -X POST \
http://192.168.1.13:9997/v1 \
-d '{'model': 'qwen3', 'messages': [{'role': 'system', 'content': '\n/no_think\n# è§’è‰²\nä½ æ˜¯ä¸€åä¸¥è°¨çš„ç»¼è¿°ä½œè€…ä¸å¤šå­¦ç§‘ä¿¡æ¯åˆ†æä¸“å®¶ã€‚å¿…é¡»å…ˆå®Œæˆç³»ç»Ÿæ£€ç´¢ä¸è¯æ®ç­›é€‰ï¼Œå†å¼€å§‹å†™å¤§çº²ã€‚\n\n# ç›®æ ‡\nä»…ç”Ÿæˆã€ä¸­æ–‡Markdownå¤§çº²ã€‘ï¼Œç»“æ„ä¸æ ‡é¢˜å¿…é¡»ä¸¥æ ¼æŒ‰â€œè¾“å‡ºç»“æ„â€ä¸€èŠ‚ï¼›ä¸å†™æ­£æ–‡ã€ä¸åŠ URLã€ä¸è¾“å‡ºå¤šä½™å†…å®¹ã€‚\n\n# ä»¥æ£€ç´¢ç»“æœé©±åŠ¨çš„åŠ¨æ€æ‰©å±•ï¼ˆæ ¸å¿ƒå¼ºåŒ–ï¼‰\n- ä»¥â€œä¸»é¢˜ç°‡â€ä¸ºæœ€å°å•å…ƒï¼šåŸºäºæ£€ç´¢ç»“æœå°†æ–‡çŒ®æˆ–æŠ¥å‘Šèšç±»ä¸ºä¸»é¢˜ç°‡ï¼ˆå¦‚æœºåˆ¶ã€æ–¹æ³•å­¦ã€äºšå‹ã€åº”ç”¨åœºæ™¯ã€å½±å“å› ç´ ã€ç»ˆç‚¹ã€å®‰å…¨æ€§ã€ç»æµå­¦ã€ç›‘ç®¡ç­‰ï¼‰ã€‚\n- æ‰©å±•è§„åˆ™ï¼ˆå†³å®šå°èŠ‚æ•°é‡ä¸å‘½åï¼‰ï¼š\n  1) å½“æŸä¸»é¢˜ç°‡æœ‰è¾ƒå¤šç ”ç©¶/æŒ‡å—/æŠ¥å‘Šæ”¯æŒæ—¶ï¼Œåˆ›å»ºç‹¬ç«‹ `###` å°èŠ‚ã€‚\n  2) è‹¥æŸä¸»é¢˜ç°‡æ¶‰åŠçš„ç ”ç©¶æ•°é‡è¾ƒå°‘ï¼Œåˆ™åˆå¹¶åˆ°é‚»è¿‘ `####` åˆ†èŠ‚ï¼›é¿å…ç”Ÿæˆç©ºæ´å°èŠ‚ã€‚\n  3) å¯¹â€œæ¯”è¾ƒ/ä¸€è‡´æ€§-å·®å¼‚/äº‰è®®ç‚¹â€â€œäºšç»„/ç‰¹å®šåº”ç”¨åœºæ™¯â€â€œçœŸå®ä¸–ç•Œè¯æ®/ç°åœºå®è·µâ€â€œæ–¹æ³•å­¦è´¨é‡ä¸åå€šâ€â€œæ ‡å‡†åŒ–ä¸ç›‘ç®¡/ä¼¦ç†/å…¬å¹³æ€§â€ä¼˜å…ˆå»ºèŠ‚ï¼ˆè‹¥è¯æ®å­˜åœ¨ï¼‰ã€‚\n  4) å°èŠ‚æ’åºæŒ‰â€œç ”ç©¶æ•°é‡Ã—å½±å“åŠ›Ã—æ–°è¿‘æ€§â€ç»¼åˆé™åºï¼›æ ‡é¢˜ç”¨å¯è¯»çš„ä¸»é¢˜åï¼Œä¸ä½¿ç”¨æ¨¡æ¿åŒ–è¯æ±‡ã€‚\n- åˆå¹¶ä¸æ‹†åˆ†é˜ˆå€¼ï¼š  \n  - å•ä¸€ `###` å°èŠ‚è‹¥æ¡ç›®>10ï¼ŒæŒ‰æœºåˆ¶/åœºæ™¯/äººç¾¤æ‹†ä¸ºå¤šä¸ª `####`ï¼›  \n  - å•ä¸€å°èŠ‚æ¡ç›®<3ï¼Œåˆå¹¶è‡³é‚»è¿‘æ›´ä¸Šä½å°èŠ‚ã€‚\n- è¦†ç›–åº¦çº¦æŸï¼š`###/####` å°èŠ‚åˆè®¡è‡³å°‘è¦†ç›–ä¸»è¦ä¸»é¢˜ç°‡çš„70%ã€‚\n\n# æ’°å†™è¦æ±‚\n- æ ‡é¢˜å¿…é¡»â€œæ¥æºäºæ£€ç´¢ä¸»é¢˜â€ï¼Œä¸å¯ç…§æ¬æ¨¡æ¿ï¼›å°èŠ‚æ•°é‡ä¸å‘½åä»¥å®é™…æ£€ç´¢ç»“æœä¸ºå‡†ã€‚\n- å¤§çº²æ¡ç›®ç²¾ç‚¼ï¼ˆâ‰¤30å­—ï¼‰ï¼Œå°½é‡é‡åŒ–å…³é”®æŒ‡æ ‡ï¼ˆå¦‚æ•ˆåº”é‡/é˜ˆå€¼/æ—¶é—´çª—/äººç¾¤ï¼‰ã€‚\n- æœ¯è¯­ä¸­æ–‡ç»Ÿä¸€ï¼Œåº¦é‡å•ä½/ç¼©å†™ä¸€è‡´ï¼›å¯åšç­‰ä»·æ˜ å°„ï¼ˆå¦‚â€œæ•°æ®é‡‡é›†/è´¨æ§â€â†’â€œæ•°æ®é¢„å¤„ç†/è´¨é‡ä¿éšœâ€ï¼‰ã€‚\n- ä¸¥ç¦ç”Ÿæˆä¸ä¸»é¢˜æ— å…³æˆ–æ— æ”¯æ’‘çš„å°èŠ‚/è¦ç‚¹ã€‚\n- ç¦æ­¢åœ¨å¤§çº²çš„æœ«å°¾æ·»åŠ å¼•ç”¨è¯´æ˜å’Œå‚è€ƒæ–‡çŒ®è¯´æ˜ç­‰ä»»ä½•è¯´æ˜ã€‚\n- ç¦æ­¢åœ¨å¤§çº²æ·»åŠ ä»»ä½•å¼•ç”¨è¯´æ˜ï¼Œä»…ç”Ÿæˆã€Markdownå¤§çº²ã€‘ã€‚\n\n\n# å¼ºåˆ¶æ£€ç´¢è¦æ±‚\n- åœ¨å¼€å§‹ç”Ÿæˆå¤§çº²ä¹‹å‰ï¼Œå¿…é¡»è°ƒç”¨ DocumentSearch å·¥å…·è¿›è¡Œç³»ç»Ÿæ€§æ–‡çŒ®æ£€ç´¢\n- æœç´¢å¿…é¡»åŒ…å«ä¸»é¢˜çš„æ ¸å¿ƒå…³é”®è¯åŠå…¶åŒä¹‰è¯ã€ç›¸å…³æœ¯è¯­\n- å¿…é¡»åŸºäºå®é™…æ£€ç´¢åˆ°çš„æ–‡çŒ®è¯æ®æ¥æ„å»ºå¤§çº²ç»“æ„å’Œå†…å®¹\n- ä¸¥ç¦åœ¨æœªæ‰§è¡Œæ£€ç´¢çš„æƒ…å†µä¸‹ç›´æ¥ç”Ÿæˆå¤§çº²\n\n# å·¥ä½œæµç¨‹ï¼ˆå…ˆæ£€ç´¢ï¼Œåå†™ä½œï¼‰\n1) æ£€ç´¢ä¸è¦†ç›–é¢  \n   - ç›®æ ‡ï¼šâ‰¥30ç¯‡å€™é€‰æ–‡çŒ®ï¼›è¿‘5å¹´ä¼˜å…ˆï¼Œä½†éœ€ä¿ç•™é‡Œç¨‹ç¢‘ç ”ç©¶ã€‚  \n   - è®°å½•æ¯æ¡å€™é€‰çš„ä¸»é¢˜ç°‡ã€æ ¸å¿ƒç»“è®ºä¸å¯æå–å®šé‡æŒ‡æ ‡ã€‚\n2) ä¸»é¢˜èšåˆ  \n   - å°†æ‰€æœ‰å€™é€‰æ–‡çŒ®èšåˆä¸ºè‹¥å¹²ä¸»é¢˜ç°‡ã€‚  \n   - ä¾æ®ä¸»é¢˜ç°‡çš„æ•°é‡å’Œé‡è¦æ€§å†³å®šå°èŠ‚ç»“æ„ï¼›ä¸è¶³è€…å¹¶å…¥ç›¸é‚»èŠ‚ã€‚  \n   - ä¸ºæ¯”è¾ƒã€å¼‚è´¨æ€§æ¥æºã€çœŸå®ä¸–ç•Œè¯æ®ã€æ–°å…´æ–¹å‘ä¸ç›‘ç®¡/ä¼¦ç†ç­‰è‡ªåŠ¨é¢„ç•™ä½ç½®ï¼ˆå­˜åœ¨è¯æ®æ—¶ï¼‰ã€‚\n\n# è¾“å‡ºè¦æ±‚\n- ä½¿ç”¨çš„è¯­è¨€æ˜¯: chinese\n- ä»…è¾“å‡ºã€Markdownå¤§çº²ã€‘ï¼Œå±‚çº§ä½¿ç”¨ #/##/###/####ã€‚  \n- æ¯æ¡è¦ç‚¹â‰¤30å­—ã€ä¿¡æ¯å¯†åº¦é«˜ã€å°½é‡é‡åŒ–ã€‚    \n- å¤§çº²æœ€å¥½ä¸å°‘äº10ä¸ªç« èŠ‚ï¼Œä¸å¤šäº15ç« èŠ‚ã€‚\n- ã€å¼ºåˆ¶ã€‘è¾“å‡ºå®Œæˆåç«‹å³ç»“æŸï¼›ç¦æ­¢åœ¨æ–‡æœ«æ·»åŠ â€œå¼•ç”¨è¯´æ˜/å‚è€ƒæ–‡çŒ®/è¯´æ˜/æ³¨é‡Š/Notes/Referencesâ€ç­‰ä»»ä½•è¯´æ˜æ€§æ–‡æœ¬æˆ–æ®µè½ã€‚\n\n# è¾“å‡ºç»“æ„ï¼ˆæ ‡é¢˜ä¸é¡ºåºå¿…é¡»ä¸€è‡´ï¼›åœ¨"..."å¤„æŒ‰è§„åˆ™åŠ¨æ€æ‰©å±•ï¼‰\n# è‡ªåŠ¨ç”Ÿæˆç²¾å‡†æ ‡é¢˜ï¼šä¸åŠ å‰¯æ ‡é¢˜\nä¸‹é¢æ˜¯ä¸€ä¸ªç¤ºä¾‹å¤§çº²ç»“æ„ï¼Œä»…ä¾›å‚è€ƒã€‚å®é™…è¾“å‡ºæ—¶å¿…é¡»æ ¹æ®æ£€ç´¢ç»“æœåŠ¨æ€è°ƒæ•´ç« èŠ‚ä¸å°èŠ‚æ ‡é¢˜ã€æ•°é‡ä¸é¡ºåºã€‚è¾“å‡ºçš„æ—¶å€™å¿…é¡»å¸¦æœ‰æ‰€æ’°å†™çš„å¤§çº²å¯¹åº”çš„æ ‡é¢˜ã€‚\n\n## æ‘˜è¦\n- èƒŒæ™¯ï¼šç ”ç©¶ç°çŠ¶/æœªæ»¡è¶³éœ€æ±‚\n- ç›®çš„ï¼šç»¼è¿°æ—¨åœ¨è§£å†³ä»€ä¹ˆé—®é¢˜\n- æ–¹æ³•ï¼ˆå¯é€‰ï¼‰ï¼šæ£€ç´¢èŒƒå›´/çº³æ’æ ‡å‡†/è¯æ®åˆ†çº§ç®€è¿°\n- ä¸»è¦å‘ç°ï¼šå›´ç»•â€œæŠ€æœ¯/æ–¹æ³•Ã—æœºåˆ¶/åº”ç”¨â€çš„å…³é”®è¿›å±•\n- ç»“è®ºä¸å±•æœ›ï¼šè½¬åŒ–è·¯å¾„/æ ‡å‡†åŒ–æŒ‘æˆ˜/æœªæ¥å‘å±•å‰æ™¯\n- å…³é”®è¯ï¼š3â€“8ä¸ªï¼›åˆ†å·åˆ†éš”\n\n## 1. å¼•è¨€\n### 1.1 xx\n### 1.2 xx\n### 1.3 xx\n...\n\n\nYou are an agent. Your internal name is "outline_agent".\n\n The description about you is "generate outline"'}, {'role': 'user', 'content': 'è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©åœ¨ç³–å°¿ç—…è¶³æºƒç–¡æ²»ç–—ä¸­çš„ä½œç”¨åŠæœºåˆ¶ç ”ç©¶è¿›å±•'}, {'role': 'assistant', 'content': '<think>\n\n</think>\n\n', 'tool_calls': [{'type': 'function', 'id': 'call_834c5e1a-554c-4e0f-b2f9-0a2ea913340e', 'function': {'name': 'DocumentSearch', 'arguments': '{"keyword": "è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰© ç³–å°¿ç—…è¶³æºƒç–¡ ä½œç”¨ æœºåˆ¶ ç ”ç©¶è¿›å±•"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_834c5e1a-554c-4e0f-b2f9-0a2ea913340e', 'content': '{"result": ["1. æ ‡é¢˜ï¼š2025å¹´å…‰ä¼ä¼ä¸šç»¿è‰²ä½ç¢³è¯„ä»·æŠ¥å‘Š.pdf.md\\næ—¶é—´: None\\nå†…å®¹: {\\"name\\": \\"part_1.txt\\", \\"content\\": \\"# 2025å…‰ä¼ä¼ä¸šç»¿è‰²ä½ç¢³è¯„ä»·æŠ¥å‘Š 2025å¹´7æœˆ # å¹¶è´­å®¶ å…è´¹è¡Œä¸šæŠ¥å‘Šç½‘ # IPOIPO.CN æ¯æ—¥æ›´æ–° ä¸ç”¨æ³¨å†Œä¼šå‘˜ æ— å¹¿å‘Š æ°¸ä¹…å…è´¹ # å…³äºIPE å…¬ä¼—ç¯å¢ƒç ”ç©¶ä¸­å¿ƒï¼ˆIPEï¼‰æ˜¯ä¸€å®¶åœ¨åŒ—äº¬æ³¨å†Œçš„å…¬ç›Šç¯å¢ƒç ”ç©¶æœºæ„ã€‚ è‡ª2006å¹´æˆç«‹ä»¥æ¥ï¼Œâ€¦\\n\\n"]}'}], 'tools': [{'type': 'function', 'function': {'name': 'DocumentSearch', 'description': '\n    æ ¹æ®å…³é”®è¯æœç´¢æ–‡æ¡£\n    :param keyword: str, æœç´¢çš„ç›¸å…³æ–‡æ¡£çš„å…³é”®è¯\n    :return: è¿”å›æ¯ç¯‡æ–‡æ¡£æ•°æ®\n    ', 'parameters': {'type': 'object', 'properties': {'keyword': {'type': 'string'}}}}}], 'extra_body': {}, 'stream': True}'
[0m

[92m15:29:09 - LiteLLM:DEBUG[0m: cost_calculator.py:833 - selected model name for cost calculation: openai/qwen3
2025-11-18 15:29:09,490 [DEBUG] selected model name for cost calculation: openai/qwen3
[92m15:29:09 - LiteLLM:DEBUG[0m: token_counter.py:374 - messages in token_counter: None, text in token_counter: 
2025-11-18 15:29:09,491 [DEBUG] messages in token_counter: None, text in token_counter: 
[92m15:29:09 - LiteLLM:DEBUG[0m: utils.py:4823 - checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
2025-11-18 15:29:09,491 [DEBUG] checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
[92m15:29:09 - LiteLLM:DEBUG[0m: utils.py:5073 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-11-18 15:29:09,491 [DEBUG] Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
[92m15:29:09 - LiteLLM:DEBUG[0m: cost_calculator.py:1149 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=openai/qwen3 - This model isn't mapped yet. model=openai/qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
2025-11-18 15:29:09,491 [DEBUG] litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=openai/qwen3 - This model isn't mapped yet. model=openai/qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
[92m15:29:09 - LiteLLM:DEBUG[0m: cost_calculator.py:833 - selected model name for cost calculation: openai/qwen3
2025-11-18 15:29:09,491 [DEBUG] selected model name for cost calculation: openai/qwen3
[92m15:29:09 - LiteLLM:DEBUG[0m: token_counter.py:374 - messages in token_counter: None, text in token_counter: 
2025-11-18 15:29:09,491 [DEBUG] messages in token_counter: None, text in token_counter: 
[92m15:29:09 - LiteLLM:DEBUG[0m: utils.py:4823 - checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
2025-11-18 15:29:09,491 [DEBUG] checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
[92m15:29:09 - LiteLLM:DEBUG[0m: utils.py:5073 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-11-18 15:29:09,493 [DEBUG] Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
[92m15:29:09 - LiteLLM:DEBUG[0m: cost_calculator.py:1149 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=openai/qwen3 - This model isn't mapped yet. model=openai/qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
2025-11-18 15:29:09,493 [DEBUG] litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=openai/qwen3 - This model isn't mapped yet. model=openai/qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
[92m15:29:09 - LiteLLM:DEBUG[0m: litellm_logging.py:1331 - response_cost_failure_debug_information: {'error_str': "This model isn't mapped yet. model=openai/qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.", 'traceback_str': 'Traceback (most recent call last):\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 4912, in _get_model_info_helper\n    raise ValueError(\nValueError: This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\litellm_logging.py", line 1312, in _response_cost_calculator\n    response_cost = litellm.response_cost_calculator(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1270, in response_cost_calculator\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1253, in response_cost_calculator\n    response_cost = completion_cost(\n                    ^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1162, in completion_cost\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1155, in completion_cost\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1094, in completion_cost\n    ) = cost_per_token(\n        ^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 379, in cost_per_token\n    return openai_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\llms\\openai\\cost_calculation.py", line 35, in cost_per_token\n    return generic_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\llm_cost_calc\\utils.py", line 515, in generic_cost_per_token\n    model_info = get_model_info(model=model, custom_llm_provider=custom_llm_provider)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 5158, in get_model_info\n    _model_info = _get_model_info_helper(\n                  ^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 5076, in _get_model_info_helper\n    raise Exception(\nException: This model isn\'t mapped yet. model=openai/qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n', 'model': 'openai/qwen3', 'cache_hit': False, 'custom_llm_provider': 'openai', 'base_model': None, 'call_type': 'acompletion', 'custom_pricing': False}
2025-11-18 15:29:09,493 [DEBUG] response_cost_failure_debug_information: {'error_str': "This model isn't mapped yet. model=openai/qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.", 'traceback_str': 'Traceback (most recent call last):\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 4912, in _get_model_info_helper\n    raise ValueError(\nValueError: This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\litellm_logging.py", line 1312, in _response_cost_calculator\n    response_cost = litellm.response_cost_calculator(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1270, in response_cost_calculator\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1253, in response_cost_calculator\n    response_cost = completion_cost(\n                    ^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1162, in completion_cost\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1155, in completion_cost\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1094, in completion_cost\n    ) = cost_per_token(\n        ^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 379, in cost_per_token\n    return openai_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\llms\\openai\\cost_calculation.py", line 35, in cost_per_token\n    return generic_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\llm_cost_calc\\utils.py", line 515, in generic_cost_per_token\n    model_info = get_model_info(model=model, custom_llm_provider=custom_llm_provider)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 5158, in get_model_info\n    _model_info = _get_model_info_helper(\n                  ^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 5076, in _get_model_info_helper\n    raise Exception(\nException: This model isn\'t mapped yet. model=openai/qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n', 'model': 'openai/qwen3', 'cache_hit': False, 'custom_llm_provider': 'openai', 'base_model': None, 'call_type': 'acompletion', 'custom_pricing': False}
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9ffaa298-acc1-4f6b-9215-1282b728aaf6', choices=[Choice(delta=ChoiceDelta(content='<think>', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450944, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:09,577 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9ffaa298-acc1-4f6b-9215-1282b728aaf6', choices=[Choice(delta=ChoiceDelta(content='<think>', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450944, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='<think>', role='assistant', function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:09,577 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='<think>', role='assistant', function_call=None, tool_calls=[], audio=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9ffaa298-acc1-4f6b-9215-1282b728aaf6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='<think>', role='assistant', function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,578 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9ffaa298-acc1-4f6b-9215-1282b728aaf6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='<think>', role='assistant', function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,579 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='<think>'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='RLFMQiux' timestamp=1763450949.457893
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-eb59c2c6-f9a3-4643-87e0-59dd8ef78c78', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450944, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:09,627 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-eb59c2c6-f9a3-4643-87e0-59dd8ef78c78', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450944, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:09,628 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-eb59c2c6-f9a3-4643-87e0-59dd8ef78c78', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,629 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-eb59c2c6-f9a3-4643-87e0-59dd8ef78c78', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,629 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""

"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='jzkBmM9w' timestamp=1763450949.457893
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0ed1b509-6cbd-457b-8a7c-93e6e49a7072', choices=[Choice(delta=ChoiceDelta(content='</think>', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450944, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:09,672 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0ed1b509-6cbd-457b-8a7c-93e6e49a7072', choices=[Choice(delta=ChoiceDelta(content='</think>', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450944, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='</think>', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:09,673 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='</think>', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0ed1b509-6cbd-457b-8a7c-93e6e49a7072', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='</think>', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,674 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0ed1b509-6cbd-457b-8a7c-93e6e49a7072', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='</think>', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,675 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='</think>'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='bnydNzUS' timestamp=1763450949.457893
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-63d316d8-6748-4d05-9e38-52538144cefb', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450944, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:09,719 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-63d316d8-6748-4d05-9e38-52538144cefb', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450944, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:09,720 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-63d316d8-6748-4d05-9e38-52538144cefb', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,720 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-63d316d8-6748-4d05-9e38-52538144cefb', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,721 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""

"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='wxI8j0Uv' timestamp=1763450949.457893
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ec990268-91c1-4c5b-a7f0-5a65e9267abe', choices=[Choice(delta=ChoiceDelta(content='#', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450944, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:09,765 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ec990268-91c1-4c5b-a7f0-5a65e9267abe', choices=[Choice(delta=ChoiceDelta(content='#', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450944, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='#', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:09,766 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='#', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ec990268-91c1-4c5b-a7f0-5a65e9267abe', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='#', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,766 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ec990268-91c1-4c5b-a7f0-5a65e9267abe', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='#', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,767 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='#'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='YwlBlWSg' timestamp=1763450949.457893
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8c42855b-0b18-4bcc-a565-97fa9c6aa4c4', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450944, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:09,767 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8c42855b-0b18-4bcc-a565-97fa9c6aa4c4', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450944, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:09,768 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8c42855b-0b18-4bcc-a565-97fa9c6aa4c4', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,768 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8c42855b-0b18-4bcc-a565-97fa9c6aa4c4', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c733eb9b-4fa6-4984-be5a-92fda0278e50', choices=[Choice(delta=ChoiceDelta(content=' è¡€', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450944, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:09,811 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c733eb9b-4fa6-4984-be5a-92fda0278e50', choices=[Choice(delta=ChoiceDelta(content=' è¡€', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450944, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' è¡€', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:09,812 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' è¡€', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c733eb9b-4fa6-4984-be5a-92fda0278e50', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' è¡€', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,812 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c733eb9b-4fa6-4984-be5a-92fda0278e50', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' è¡€', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,813 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' è¡€'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='0ATb0CoZ' timestamp=1763450949.457893
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-97f071ac-1f5e-41e4-9d8d-97532c1e5b10', choices=[Choice(delta=ChoiceDelta(content='å°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:09,861 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-97f071ac-1f5e-41e4-9d8d-97532c1e5b10', choices=[Choice(delta=ChoiceDelta(content='å°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:09,862 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-97f071ac-1f5e-41e4-9d8d-97532c1e5b10', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,863 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-97f071ac-1f5e-41e4-9d8d-97532c1e5b10', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,864 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å°'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='zHTClGBf' timestamp=1763450949.457893
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4ce753dd-4af0-433e-8dec-d4ebc5718751', choices=[Choice(delta=ChoiceDelta(content='æ¿', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:09,865 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4ce753dd-4af0-433e-8dec-d4ebc5718751', choices=[Choice(delta=ChoiceDelta(content='æ¿', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:09,865 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4ce753dd-4af0-433e-8dec-d4ebc5718751', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,865 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4ce753dd-4af0-433e-8dec-d4ebc5718751', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,866 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ¿'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='pauxo3GI' timestamp=1763450949.457893
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-56516e5a-453e-442a-893b-eb3efe7fbcf7', choices=[Choice(delta=ChoiceDelta(content='åŠå…¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:09,904 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-56516e5a-453e-442a-893b-eb3efe7fbcf7', choices=[Choice(delta=ChoiceDelta(content='åŠå…¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åŠå…¶', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:09,905 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åŠå…¶', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-56516e5a-453e-442a-893b-eb3efe7fbcf7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åŠå…¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,905 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-56516e5a-453e-442a-893b-eb3efe7fbcf7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åŠå…¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,906 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='åŠå…¶'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='1ngcLUu9' timestamp=1763450949.457893
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-deef7a7c-db97-422f-99db-f13c924be2a6', choices=[Choice(delta=ChoiceDelta(content='è¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:09,908 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-deef7a7c-db97-422f-99db-f13c924be2a6', choices=[Choice(delta=ChoiceDelta(content='è¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:09,910 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-deef7a7c-db97-422f-99db-f13c924be2a6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,911 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-deef7a7c-db97-422f-99db-f13c924be2a6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,912 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='8O1H6iB5' timestamp=1763450949.457893
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5e1bdd47-0f69-4c09-94b3-60f5b34fc2f6', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:09,951 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5e1bdd47-0f69-4c09-94b3-60f5b34fc2f6', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:09,952 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5e1bdd47-0f69-4c09-94b3-60f5b34fc2f6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,952 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5e1bdd47-0f69-4c09-94b3-60f5b34fc2f6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,953 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç”Ÿç‰©'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='ddR4wL20' timestamp=1763450949.457893
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3257e96c-dfeb-4734-bf24-ff63abe40c10', choices=[Choice(delta=ChoiceDelta(content='åœ¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:09,954 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3257e96c-dfeb-4734-bf24-ff63abe40c10', choices=[Choice(delta=ChoiceDelta(content='åœ¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åœ¨', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:09,954 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åœ¨', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3257e96c-dfeb-4734-bf24-ff63abe40c10', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åœ¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,954 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3257e96c-dfeb-4734-bf24-ff63abe40c10', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åœ¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,955 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='åœ¨'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='UE68GnOR' timestamp=1763450949.457893
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-bf183a24-2286-4bd3-9768-63ed3b6af6cc', choices=[Choice(delta=ChoiceDelta(content='ç³–å°¿ç—…', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:09,998 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-bf183a24-2286-4bd3-9768-63ed3b6af6cc', choices=[Choice(delta=ChoiceDelta(content='ç³–å°¿ç—…', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç³–å°¿ç—…', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:09,999 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç³–å°¿ç—…', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:09 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-bf183a24-2286-4bd3-9768-63ed3b6af6cc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç³–å°¿ç—…', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:09,999 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-bf183a24-2286-4bd3-9768-63ed3b6af6cc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç³–å°¿ç—…', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,000 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç³–å°¿ç—…'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='SQwjrXrT' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5ca548dc-ad2a-4f2c-a52f-db1112149cc8', choices=[Choice(delta=ChoiceDelta(content='è¶³', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,001 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5ca548dc-ad2a-4f2c-a52f-db1112149cc8', choices=[Choice(delta=ChoiceDelta(content='è¶³', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¶³', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,004 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¶³', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5ca548dc-ad2a-4f2c-a52f-db1112149cc8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¶³', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,005 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5ca548dc-ad2a-4f2c-a52f-db1112149cc8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¶³', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,007 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¶³'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='KmZa3wdM' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-589f92c5-82f0-49cc-b4f7-79ffc9f3612b', choices=[Choice(delta=ChoiceDelta(content='æºƒç–¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,048 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-589f92c5-82f0-49cc-b4f7-79ffc9f3612b', choices=[Choice(delta=ChoiceDelta(content='æºƒç–¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æºƒç–¡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,049 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æºƒç–¡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-589f92c5-82f0-49cc-b4f7-79ffc9f3612b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æºƒç–¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,049 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-589f92c5-82f0-49cc-b4f7-79ffc9f3612b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æºƒç–¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,050 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æºƒç–¡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='UOXWjuOu' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-971cb65d-7ea9-421a-b22d-f9867ad41eaf', choices=[Choice(delta=ChoiceDelta(content='æ²»ç–—', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,051 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-971cb65d-7ea9-421a-b22d-f9867ad41eaf', choices=[Choice(delta=ChoiceDelta(content='æ²»ç–—', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,052 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-971cb65d-7ea9-421a-b22d-f9867ad41eaf', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,052 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-971cb65d-7ea9-421a-b22d-f9867ad41eaf', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,053 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ²»ç–—'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='6KkzWEVl' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-fa1826d9-f95b-44e8-a316-1f4135db2696', choices=[Choice(delta=ChoiceDelta(content='ä¸­çš„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,053 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-fa1826d9-f95b-44e8-a316-1f4135db2696', choices=[Choice(delta=ChoiceDelta(content='ä¸­çš„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸­çš„', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,054 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸­çš„', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-fa1826d9-f95b-44e8-a316-1f4135db2696', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸­çš„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,054 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-fa1826d9-f95b-44e8-a316-1f4135db2696', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸­çš„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,054 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸­çš„'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='SDmkNOlY' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e7ceae21-0ac4-4102-9eb9-b71ea36407d4', choices=[Choice(delta=ChoiceDelta(content='ä½œç”¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,092 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e7ceae21-0ac4-4102-9eb9-b71ea36407d4', choices=[Choice(delta=ChoiceDelta(content='ä½œç”¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,094 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e7ceae21-0ac4-4102-9eb9-b71ea36407d4', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,094 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e7ceae21-0ac4-4102-9eb9-b71ea36407d4', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,096 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä½œç”¨'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='v8TZWVKn' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7fc66fd4-62e0-44f5-a149-6fb62b9efe84', choices=[Choice(delta=ChoiceDelta(content='åŠ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,096 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7fc66fd4-62e0-44f5-a149-6fb62b9efe84', choices=[Choice(delta=ChoiceDelta(content='åŠ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åŠ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,097 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åŠ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7fc66fd4-62e0-44f5-a149-6fb62b9efe84', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åŠ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,097 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7fc66fd4-62e0-44f5-a149-6fb62b9efe84', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åŠ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,098 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='åŠ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='QjZypy3V' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3e9e73d1-7428-4b29-b31c-932771f1ab15', choices=[Choice(delta=ChoiceDelta(content='æœºåˆ¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,138 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3e9e73d1-7428-4b29-b31c-932771f1ab15', choices=[Choice(delta=ChoiceDelta(content='æœºåˆ¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æœºåˆ¶', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,140 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æœºåˆ¶', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3e9e73d1-7428-4b29-b31c-932771f1ab15', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æœºåˆ¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,140 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3e9e73d1-7428-4b29-b31c-932771f1ab15', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æœºåˆ¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,141 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æœºåˆ¶'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='qeCDSpfD' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0e17a286-95ac-4cab-93b1-a5479367433e', choices=[Choice(delta=ChoiceDelta(content='ç ”ç©¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,141 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0e17a286-95ac-4cab-93b1-a5479367433e', choices=[Choice(delta=ChoiceDelta(content='ç ”ç©¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,142 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0e17a286-95ac-4cab-93b1-a5479367433e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,142 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0e17a286-95ac-4cab-93b1-a5479367433e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,143 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç ”ç©¶'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='1YT1RtPr' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-369c86f4-6376-4f78-8b81-c64d7abab6a9', choices=[Choice(delta=ChoiceDelta(content='è¿›å±•', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,185 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-369c86f4-6376-4f78-8b81-c64d7abab6a9', choices=[Choice(delta=ChoiceDelta(content='è¿›å±•', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¿›å±•', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,186 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¿›å±•', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-369c86f4-6376-4f78-8b81-c64d7abab6a9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¿›å±•', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,186 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-369c86f4-6376-4f78-8b81-c64d7abab6a9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¿›å±•', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,187 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¿›å±•'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='SL8i4c4G' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1bf137bc-f491-4ecf-8ab7-bc1feb89425a', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,188 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1bf137bc-f491-4ecf-8ab7-bc1feb89425a', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,189 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1bf137bc-f491-4ecf-8ab7-bc1feb89425a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,189 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1bf137bc-f491-4ecf-8ab7-bc1feb89425a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,191 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""

"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='SmnWRO7x' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0ffcdcd3-6a81-431a-a36a-ba245e82d88a', choices=[Choice(delta=ChoiceDelta(content='##', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,232 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0ffcdcd3-6a81-431a-a36a-ba245e82d88a', choices=[Choice(delta=ChoiceDelta(content='##', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,233 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0ffcdcd3-6a81-431a-a36a-ba245e82d88a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,233 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0ffcdcd3-6a81-431a-a36a-ba245e82d88a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,234 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='##'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='NxhQhOZ7' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6628f406-fe4a-400c-83a3-85f585bb43c7', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,235 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6628f406-fe4a-400c-83a3-85f585bb43c7', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,236 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6628f406-fe4a-400c-83a3-85f585bb43c7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,236 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6628f406-fe4a-400c-83a3-85f585bb43c7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-01e9ec8e-5816-4541-9575-565957b9865b', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,236 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-01e9ec8e-5816-4541-9575-565957b9865b', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,237 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-01e9ec8e-5816-4541-9575-565957b9865b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,237 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-01e9ec8e-5816-4541-9575-565957b9865b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0e991479-36ca-4659-9514-2a0c0279688c', choices=[Choice(delta=ChoiceDelta(content=' æ‘˜', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,281 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0e991479-36ca-4659-9514-2a0c0279688c', choices=[Choice(delta=ChoiceDelta(content=' æ‘˜', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' æ‘˜', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,282 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' æ‘˜', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0e991479-36ca-4659-9514-2a0c0279688c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' æ‘˜', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,284 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0e991479-36ca-4659-9514-2a0c0279688c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' æ‘˜', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,285 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' æ‘˜'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='mFFfgipO' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-574af28a-07ab-4e7b-9119-e840133b2bc5', choices=[Choice(delta=ChoiceDelta(content='è¦', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,285 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-574af28a-07ab-4e7b-9119-e840133b2bc5', choices=[Choice(delta=ChoiceDelta(content='è¦', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¦', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,286 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¦', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-574af28a-07ab-4e7b-9119-e840133b2bc5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¦', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,286 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-574af28a-07ab-4e7b-9119-e840133b2bc5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¦', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,287 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¦'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='zjweF8dE' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-90a88f5e-ff83-4d65-8c81-1abfe104be89', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,324 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-90a88f5e-ff83-4d65-8c81-1abfe104be89', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,325 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-90a88f5e-ff83-4d65-8c81-1abfe104be89', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,325 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-90a88f5e-ff83-4d65-8c81-1abfe104be89', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,326 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='JcPGiheo' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3ea9ae0c-2ac5-4fd5-93dd-069bb3daaff0', choices=[Choice(delta=ChoiceDelta(content='-', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,327 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3ea9ae0c-2ac5-4fd5-93dd-069bb3daaff0', choices=[Choice(delta=ChoiceDelta(content='-', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='-', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,328 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='-', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3ea9ae0c-2ac5-4fd5-93dd-069bb3daaff0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='-', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,328 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3ea9ae0c-2ac5-4fd5-93dd-069bb3daaff0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='-', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,329 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='-'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='drjKDNNd' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9291ad9c-ff65-4304-8eb4-f3f5bfceb657', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,369 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9291ad9c-ff65-4304-8eb4-f3f5bfceb657', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,370 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9291ad9c-ff65-4304-8eb4-f3f5bfceb657', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,370 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9291ad9c-ff65-4304-8eb4-f3f5bfceb657', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-fab2e62f-17b0-4cdb-8633-677cfa7e4258', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,371 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-fab2e62f-17b0-4cdb-8633-677cfa7e4258', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,372 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-fab2e62f-17b0-4cdb-8633-677cfa7e4258', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,372 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-fab2e62f-17b0-4cdb-8633-677cfa7e4258', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9dc31552-bd9c-409a-a358-6dbe474131bc', choices=[Choice(delta=ChoiceDelta(content=' èƒŒ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,416 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9dc31552-bd9c-409a-a358-6dbe474131bc', choices=[Choice(delta=ChoiceDelta(content=' èƒŒ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' èƒŒ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,417 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' èƒŒ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9dc31552-bd9c-409a-a358-6dbe474131bc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' èƒŒ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,417 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9dc31552-bd9c-409a-a358-6dbe474131bc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' èƒŒ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,418 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' èƒŒ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='6swxmzFB' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d59e40a8-4019-4d68-97d5-529c73b0ff17', choices=[Choice(delta=ChoiceDelta(content='æ™¯', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,419 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d59e40a8-4019-4d68-97d5-529c73b0ff17', choices=[Choice(delta=ChoiceDelta(content='æ™¯', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ™¯', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,419 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ™¯', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d59e40a8-4019-4d68-97d5-529c73b0ff17', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ™¯', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,419 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d59e40a8-4019-4d68-97d5-529c73b0ff17', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ™¯', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,421 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ™¯'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='CirMijMr' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e51a5827-c110-4dca-b52d-1d030b3bac53', choices=[Choice(delta=ChoiceDelta(content='ï¼š', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,462 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e51a5827-c110-4dca-b52d-1d030b3bac53', choices=[Choice(delta=ChoiceDelta(content='ï¼š', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ï¼š', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,463 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ï¼š', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e51a5827-c110-4dca-b52d-1d030b3bac53', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ï¼š', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,463 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e51a5827-c110-4dca-b52d-1d030b3bac53', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ï¼š', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
Agent outline_agent å¼€å§‹æ‰§è¡Œï¼Œmetadata: {'language': 'chinese', 'user_id': ''}
åŠ¨æ€ç”Ÿæˆçš„æŒ‡ä»¤é•¿åº¦: 1638 å­—ç¬¦
è°ƒç”¨äº†outline_agentæ¨¡å‹å‰çš„callback, ç°åœ¨Agentå…±æœ‰1æ¡å†å²è®°å½•,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''}
ä½¿ç”¨çš„è¯­è¨€å‚æ•°: chinese
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='<think>'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: <think>
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""

"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 


è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='</think>'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: </think>
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""

"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 


è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""<think>

</think>

"""
), Part(
  function_call=FunctionCall(
    args={
      'keyword': 'è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰© ç³–å°¿ç—…è¶³æºƒç–¡ ä½œç”¨ æœºåˆ¶ ç ”ç©¶è¿›å±•'
    },
    id='call_834c5e1a-554c-4e0f-b2f9-0a2ea913340e',
    name='DocumentSearch'
  )
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: <think>

</think>


Agent outline_agent æ­£åœ¨è°ƒç”¨å·¥å…·ï¼šDocumentSearch: è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰© ç³–å°¿ç—…è¶³æºƒç–¡ ä½œç”¨ æœºåˆ¶ ç ”ç©¶è¿›å±•
è°ƒç”¨å·¥å…·ï¼šDocumentSearchæ—¶ä¼ å…¥çš„metadata: {'language': 'chinese', 'user_id': ''}
è°ƒç”¨å·¥å…·ï¼šDocumentSearchæ—¶ä¼ å…¥çš„references: {}
æ–‡æ¡£æ£€ç´¢: è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰© ç³–å°¿ç—…è¶³æºƒç–¡ ä½œç”¨ æœºåˆ¶ ç ”ç©¶è¿›å±•
[search] status=200, took=16.81s
å…³é”®è¯è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰© ç³–å°¿ç—…è¶³æºƒç–¡ ä½œç”¨ æœºåˆ¶ ç ”ç©¶è¿›å±•ç›¸å…³çš„æ–‡ç« å·²ç»è·å–å®Œæ¯•ï¼Œè·å–åˆ°1ç¯‡, è€—æ—¶16.808762073516846ç§’
è°ƒç”¨äº†DocumentSearchå·¥å…·åçš„callback, tool_responseæ•°æ®ä¸ºï¼š['1. æ ‡é¢˜ï¼š2025å¹´å…‰ä¼ä¼ä¸šç»¿è‰²ä½ç¢³è¯„ä»·æŠ¥å‘Š.pdf.md\næ—¶é—´: None\nå†…å®¹: {"name": "part_1.txt", "content": "# 2025å…‰ä¼ä¼ä¸šç»¿è‰²ä½ç¢³è¯„ä»·æŠ¥å‘Š 2025å¹´7æœˆ # å¹¶è´­å®¶ å…è´¹è¡Œä¸šæŠ¥å‘Šç½‘ # IPOIPO.CN æ¯æ—¥æ›´æ–° ä¸ç”¨æ³¨å†Œä¼šå‘˜ æ— å¹¿å‘Š æ°¸ä¹…å…è´¹ # å…³äºIPE å…¬ä¼—ç¯å¢ƒç ”ç©¶ä¸­å¿ƒï¼ˆIPEï¼‰æ˜¯ä¸€å®¶åœ¨åŒ—äº¬æ³¨å†Œçš„å…¬ç›Šç¯å¢ƒç ”ç©¶æœºæ„ã€‚ è‡ª2006å¹´æˆç«‹ä»¥æ¥ï¼Œâ€¦\n\n']
åŠ¨æ€ç”Ÿæˆçš„æŒ‡ä»¤é•¿åº¦: 1638 å­—ç¬¦
è°ƒç”¨äº†outline_agentæ¨¡å‹å‰çš„callback, ç°åœ¨Agentå…±æœ‰3æ¡å†å²è®°å½•,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''}
ä½¿ç”¨çš„è¯­è¨€å‚æ•°: chinese
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='<think>'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: <think>
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""

"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 


è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='</think>'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: </think>
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""

"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 


è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='#'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: #
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' è¡€'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  è¡€
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å°'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å°
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ¿'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ¿
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='åŠå…¶'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: åŠå…¶
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç”Ÿç‰©'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç”Ÿç‰©
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='åœ¨'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: åœ¨
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç³–å°¿ç—…'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç³–å°¿ç—…
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¶³'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¶³
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æºƒç–¡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æºƒç–¡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ²»ç–—'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ²»ç–—
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸­çš„'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸­çš„
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä½œç”¨'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä½œç”¨
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='åŠ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: åŠ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æœºåˆ¶'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æœºåˆ¶
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç ”ç©¶'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç ”ç©¶
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¿›å±•'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¿›å±•
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""

"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 


è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='##'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ##
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' æ‘˜'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  æ‘˜
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¦'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¦
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='-'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: -
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' èƒŒ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  èƒŒ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ™¯'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ™¯
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ï¼š'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ï¼š2025-11-18 15:29:10,464 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ï¼š'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='fD14dE47' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b49eacd7-b47a-4c2a-a5b1-419f0a3330be', choices=[Choice(delta=ChoiceDelta(content='ç³–å°¿ç—…', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,465 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b49eacd7-b47a-4c2a-a5b1-419f0a3330be', choices=[Choice(delta=ChoiceDelta(content='ç³–å°¿ç—…', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç³–å°¿ç—…', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,466 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç³–å°¿ç—…', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b49eacd7-b47a-4c2a-a5b1-419f0a3330be', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç³–å°¿ç—…', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,466 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b49eacd7-b47a-4c2a-a5b1-419f0a3330be', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç³–å°¿ç—…', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,467 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç³–å°¿ç—…'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='uUfcvaPz' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-06f494aa-7a67-4d8f-8e58-aa22bc3ca616', choices=[Choice(delta=ChoiceDelta(content='è¶³', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,467 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-06f494aa-7a67-4d8f-8e58-aa22bc3ca616', choices=[Choice(delta=ChoiceDelta(content='è¶³', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¶³', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,468 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¶³', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-06f494aa-7a67-4d8f-8e58-aa22bc3ca616', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¶³', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,468 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-06f494aa-7a67-4d8f-8e58-aa22bc3ca616', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¶³', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,469 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¶³'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='6tnwVGul' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-89f996fe-3b70-49d2-a15e-4d829ce66077', choices=[Choice(delta=ChoiceDelta(content='æºƒç–¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,509 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-89f996fe-3b70-49d2-a15e-4d829ce66077', choices=[Choice(delta=ChoiceDelta(content='æºƒç–¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æºƒç–¡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,511 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æºƒç–¡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-89f996fe-3b70-49d2-a15e-4d829ce66077', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æºƒç–¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,511 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-89f996fe-3b70-49d2-a15e-4d829ce66077', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æºƒç–¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,512 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æºƒç–¡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='8oeyUzf2' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-32d98541-c6c2-44df-99a3-34207f44016e', choices=[Choice(delta=ChoiceDelta(content='é«˜', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,513 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-32d98541-c6c2-44df-99a3-34207f44016e', choices=[Choice(delta=ChoiceDelta(content='é«˜', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='é«˜', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,514 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='é«˜', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-32d98541-c6c2-44df-99a3-34207f44016e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='é«˜', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,514 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-32d98541-c6c2-44df-99a3-34207f44016e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='é«˜', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,515 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='é«˜'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='O9X1wSac' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4600f966-1567-455b-98fe-3bbb7c3c5601', choices=[Choice(delta=ChoiceDelta(content='å‘', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,556 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4600f966-1567-455b-98fe-3bbb7c3c5601', choices=[Choice(delta=ChoiceDelta(content='å‘', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å‘', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,557 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å‘', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4600f966-1567-455b-98fe-3bbb7c3c5601', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å‘', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,557 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4600f966-1567-455b-98fe-3bbb7c3c5601', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å‘', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,558 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å‘'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='zvKc37Cf' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b154f9ff-9cc3-4c6c-af89-1beee94d78e0', choices=[Choice(delta=ChoiceDelta(content='ä¸”', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,559 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b154f9ff-9cc3-4c6c-af89-1beee94d78e0', choices=[Choice(delta=ChoiceDelta(content='ä¸”', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸”', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,560 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸”', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b154f9ff-9cc3-4c6c-af89-1beee94d78e0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸”', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,560 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b154f9ff-9cc3-4c6c-af89-1beee94d78e0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸”', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,561 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸”'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='N5t2mjLN' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7dceecd2-d3b5-4648-9f4b-d62f4a6558e7', choices=[Choice(delta=ChoiceDelta(content='éš¾', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,601 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7dceecd2-d3b5-4648-9f4b-d62f4a6558e7', choices=[Choice(delta=ChoiceDelta(content='éš¾', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='éš¾', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,602 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='éš¾', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7dceecd2-d3b5-4648-9f4b-d62f4a6558e7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='éš¾', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,602 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7dceecd2-d3b5-4648-9f4b-d62f4a6558e7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='éš¾', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,603 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='éš¾'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='rUEeU8B9' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-240a1fc1-148d-4a00-9907-03f75026bd3c', choices=[Choice(delta=ChoiceDelta(content='æ²»', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,604 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-240a1fc1-148d-4a00-9907-03f75026bd3c', choices=[Choice(delta=ChoiceDelta(content='æ²»', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ²»', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,604 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ²»', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-240a1fc1-148d-4a00-9907-03f75026bd3c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ²»', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,605 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-240a1fc1-148d-4a00-9907-03f75026bd3c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ²»', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,607 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ²»'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='RMsuMafC' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e55b0c47-00cd-4884-bfc9-32e2cff7bb95', choices=[Choice(delta=ChoiceDelta(content='ï¼Œ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,648 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e55b0c47-00cd-4884-bfc9-32e2cff7bb95', choices=[Choice(delta=ChoiceDelta(content='ï¼Œ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ï¼Œ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,650 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ï¼Œ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e55b0c47-00cd-4884-bfc9-32e2cff7bb95', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ï¼Œ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,650 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e55b0c47-00cd-4884-bfc9-32e2cff7bb95', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ï¼Œ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,651 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ï¼Œ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='qtJDHlTu' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8cfb15f6-6241-44e1-8125-cd6e85214d8e', choices=[Choice(delta=ChoiceDelta(content='ç°æœ‰', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,651 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8cfb15f6-6241-44e1-8125-cd6e85214d8e', choices=[Choice(delta=ChoiceDelta(content='ç°æœ‰', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç°æœ‰', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,652 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç°æœ‰', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8cfb15f6-6241-44e1-8125-cd6e85214d8e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç°æœ‰', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,652 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8cfb15f6-6241-44e1-8125-cd6e85214d8e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç°æœ‰', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,653 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç°æœ‰'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='oHixfRko' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e70507b1-b4e7-4081-ad47-ce0cfde7ed74', choices=[Choice(delta=ChoiceDelta(content='ç–—æ³•', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,654 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e70507b1-b4e7-4081-ad47-ce0cfde7ed74', choices=[Choice(delta=ChoiceDelta(content='ç–—æ³•', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç–—æ³•', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,654 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç–—æ³•', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e70507b1-b4e7-4081-ad47-ce0cfde7ed74', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç–—æ³•', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,655 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e70507b1-b4e7-4081-ad47-ce0cfde7ed74', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç–—æ³•', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,656 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç–—æ³•'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='UvVrWNJw' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-09c759de-c687-4688-bca7-84492158e35a', choices=[Choice(delta=ChoiceDelta(content='å±€é™', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,699 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-09c759de-c687-4688-bca7-84492158e35a', choices=[Choice(delta=ChoiceDelta(content='å±€é™', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å±€é™', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,699 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å±€é™', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-09c759de-c687-4688-bca7-84492158e35a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å±€é™', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,700 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-09c759de-c687-4688-bca7-84492158e35a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å±€é™', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,701 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å±€é™'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='sU0Pqz9V' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1f6801c1-16d6-41f1-887d-5b3ef5970189', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,701 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1f6801c1-16d6-41f1-887d-5b3ef5970189', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,702 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1f6801c1-16d6-41f1-887d-5b3ef5970189', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,702 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1f6801c1-16d6-41f1-887d-5b3ef5970189', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,704 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='KxP7WDzv' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5a61b02a-7fd3-4be4-88df-fe0388c5ffa9', choices=[Choice(delta=ChoiceDelta(content='-', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,820 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5a61b02a-7fd3-4be4-88df-fe0388c5ffa9', choices=[Choice(delta=ChoiceDelta(content='-', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='-', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,821 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='-', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5a61b02a-7fd3-4be4-88df-fe0388c5ffa9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='-', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,821 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5a61b02a-7fd3-4be4-88df-fe0388c5ffa9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='-', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,822 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='-'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='peMuuiMI' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d7280603-d1b9-4fcb-b9c0-18d1af3f7c4e', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,823 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d7280603-d1b9-4fcb-b9c0-18d1af3f7c4e', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,824 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d7280603-d1b9-4fcb-b9c0-18d1af3f7c4e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,824 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d7280603-d1b9-4fcb-b9c0-18d1af3f7c4e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-053c6ad6-fe13-4363-a132-f217632e2b3b', choices=[Choice(delta=ChoiceDelta(content=' ç›®', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,871 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-053c6ad6-fe13-4363-a132-f217632e2b3b', choices=[Choice(delta=ChoiceDelta(content=' ç›®', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ç›®', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,872 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ç›®', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-053c6ad6-fe13-4363-a132-f217632e2b3b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ç›®', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,873 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-053c6ad6-fe13-4363-a132-f217632e2b3b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ç›®', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,874 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' ç›®'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='lqJDyc2X' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0eecb994-3859-47e3-bf8e-7f6299f4bdb5', choices=[Choice(delta=ChoiceDelta(content='çš„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,874 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0eecb994-3859-47e3-bf8e-7f6299f4bdb5', choices=[Choice(delta=ChoiceDelta(content='çš„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,876 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0eecb994-3859-47e3-bf8e-7f6299f4bdb5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,876 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0eecb994-3859-47e3-bf8e-7f6299f4bdb5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,877 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='çš„'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='UgwSxpds' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8b1f73cf-c002-4e81-aea1-c2e540eb1e62', choices=[Choice(delta=ChoiceDelta(content='ï¼š', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,878 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8b1f73cf-c002-4e81-aea1-c2e540eb1e62', choices=[Choice(delta=ChoiceDelta(content='ï¼š', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450945, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ï¼š', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,879 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ï¼š', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8b1f73cf-c002-4e81-aea1-c2e540eb1e62', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ï¼š', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,879 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8b1f73cf-c002-4e81-aea1-c2e540eb1e62', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ï¼š', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,880 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ï¼š'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='35qRiKeQ' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-24f32b14-53bc-47cf-94de-f0aa8989bd8a', choices=[Choice(delta=ChoiceDelta(content='ç»¼', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,880 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-24f32b14-53bc-47cf-94de-f0aa8989bd8a', choices=[Choice(delta=ChoiceDelta(content='ç»¼', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç»¼', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,881 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç»¼', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-24f32b14-53bc-47cf-94de-f0aa8989bd8a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç»¼', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,881 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-24f32b14-53bc-47cf-94de-f0aa8989bd8a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç»¼', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,882 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç»¼'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='WkVNofBV' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-191b79e0-f21a-4779-9c8e-46f3731b53c5', choices=[Choice(delta=ChoiceDelta(content='è¿°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,883 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-191b79e0-f21a-4779-9c8e-46f3731b53c5', choices=[Choice(delta=ChoiceDelta(content='è¿°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¿°', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,884 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¿°', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-191b79e0-f21a-4779-9c8e-46f3731b53c5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¿°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,884 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-191b79e0-f21a-4779-9c8e-46f3731b53c5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¿°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,885 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¿°'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='MvWoHJ5G' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-342d3597-193c-4bd0-8530-35a716c728fa', choices=[Choice(delta=ChoiceDelta(content='è¡€', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,886 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-342d3597-193c-4bd0-8530-35a716c728fa', choices=[Choice(delta=ChoiceDelta(content='è¡€', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡€', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,886 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡€', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-342d3597-193c-4bd0-8530-35a716c728fa', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡€', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,886 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-342d3597-193c-4bd0-8530-35a716c728fa', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡€', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,887 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¡€'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='miG5iGBq' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b43daaec-46af-45df-ab23-318e326ac64f', choices=[Choice(delta=ChoiceDelta(content='å°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,954 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b43daaec-46af-45df-ab23-318e326ac64f', choices=[Choice(delta=ChoiceDelta(content='å°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,954 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b43daaec-46af-45df-ab23-318e326ac64f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,955 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b43daaec-46af-45df-ab23-318e326ac64f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,956 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å°'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='4es7I8wf' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-465d3cb1-a952-4332-9df7-5d4a59cbb758', choices=[Choice(delta=ChoiceDelta(content='æ¿', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,956 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-465d3cb1-a952-4332-9df7-5d4a59cbb758', choices=[Choice(delta=ChoiceDelta(content='æ¿', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,957 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-465d3cb1-a952-4332-9df7-5d4a59cbb758', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,957 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-465d3cb1-a952-4332-9df7-5d4a59cbb758', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,958 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ¿'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='Gbdvsfva' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-33f922ac-0fd9-46ec-ad0b-d3ba2c0c71e9', choices=[Choice(delta=ChoiceDelta(content='åŠå…¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,959 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-33f922ac-0fd9-46ec-ad0b-d3ba2c0c71e9', choices=[Choice(delta=ChoiceDelta(content='åŠå…¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åŠå…¶', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,960 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åŠå…¶', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-33f922ac-0fd9-46ec-ad0b-d3ba2c0c71e9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åŠå…¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,960 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-33f922ac-0fd9-46ec-ad0b-d3ba2c0c71e9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åŠå…¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,961 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='åŠå…¶'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='8Yhu580U' timestamp=1763450949.457893
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-611d59c8-2ea9-4bf8-a34c-8ca3457c21bd', choices=[Choice(delta=ChoiceDelta(content='è¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:10,962 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-611d59c8-2ea9-4bf8-a34c-8ca3457c21bd', choices=[Choice(delta=ChoiceDelta(content='è¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:10,962 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:10 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-611d59c8-2ea9-4bf8-a34c-8ca3457c21bd', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,962 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-611d59c8-2ea9-4bf8-a34c-8ca3457c21bd', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:10,964 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='Lyugw8k9' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1458ca41-6d80-47fd-8d9c-1c84a65092b6', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,010 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1458ca41-6d80-47fd-8d9c-1c84a65092b6', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,011 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1458ca41-6d80-47fd-8d9c-1c84a65092b6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,012 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1458ca41-6d80-47fd-8d9c-1c84a65092b6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,013 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç”Ÿç‰©'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='Q9IXSSBR' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6d2b561d-0a2b-4f67-9589-f3a471cc035b', choices=[Choice(delta=ChoiceDelta(content='çš„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,014 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6d2b561d-0a2b-4f67-9589-f3a471cc035b', choices=[Choice(delta=ChoiceDelta(content='çš„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,015 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6d2b561d-0a2b-4f67-9589-f3a471cc035b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,015 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6d2b561d-0a2b-4f67-9589-f3a471cc035b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,016 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='çš„'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='knIdx0Y8' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-99b46180-df1f-4356-810c-31f724f60811', choices=[Choice(delta=ChoiceDelta(content='æ²»ç–—', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,016 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-99b46180-df1f-4356-810c-31f724f60811', choices=[Choice(delta=ChoiceDelta(content='æ²»ç–—', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,017 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-99b46180-df1f-4356-810c-31f724f60811', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,017 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-99b46180-df1f-4356-810c-31f724f60811', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,018 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ²»ç–—'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='sHPVMwnI' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-96a90dd1-5ea1-477d-bdb4-4d00d61d49cd', choices=[Choice(delta=ChoiceDelta(content='æ½œåŠ›', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,052 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-96a90dd1-5ea1-477d-bdb4-4d00d61d49cd', choices=[Choice(delta=ChoiceDelta(content='æ½œåŠ›', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ½œåŠ›', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,053 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ½œåŠ›', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-96a90dd1-5ea1-477d-bdb4-4d00d61d49cd', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ½œåŠ›', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,053 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-96a90dd1-5ea1-477d-bdb4-4d00d61d49cd', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ½œåŠ›', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,054 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ½œåŠ›'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='BioGmBzL' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ecea970e-e396-4d09-9dd8-70ab2e91b6dc', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,055 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ecea970e-e396-4d09-9dd8-70ab2e91b6dc', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,056 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ecea970e-e396-4d09-9dd8-70ab2e91b6dc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,056 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ecea970e-e396-4d09-9dd8-70ab2e91b6dc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,057 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='UuaadLO7' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-68abb57f-256a-47d8-b841-beb8fabea9fd', choices=[Choice(delta=ChoiceDelta(content='ä½œç”¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,099 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-68abb57f-256a-47d8-b841-beb8fabea9fd', choices=[Choice(delta=ChoiceDelta(content='ä½œç”¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,100 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-68abb57f-256a-47d8-b841-beb8fabea9fd', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,100 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-68abb57f-256a-47d8-b841-beb8fabea9fd', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,101 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä½œç”¨'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='DNFk8scL' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-47c76d17-e91a-4781-bf43-2191e7e20cd4', choices=[Choice(delta=ChoiceDelta(content='æœºåˆ¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,101 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-47c76d17-e91a-4781-bf43-2191e7e20cd4', choices=[Choice(delta=ChoiceDelta(content='æœºåˆ¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æœºåˆ¶', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,102 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æœºåˆ¶', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-47c76d17-e91a-4781-bf43-2191e7e20cd4', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æœºåˆ¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,102 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-47c76d17-e91a-4781-bf43-2191e7e20cd4', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æœºåˆ¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,103 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æœºåˆ¶'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='qqHWbzD7' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0d4814de-e577-44b9-9a19-0cc65d94c45a', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,144 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0d4814de-e577-44b9-9a19-0cc65d94c45a', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,146 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0d4814de-e577-44b9-9a19-0cc65d94c45a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,146 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0d4814de-e577-44b9-9a19-0cc65d94c45a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,147 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='0R5nf60G' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-75f86c8e-3121-4320-8c42-ca133d881b8e', choices=[Choice(delta=ChoiceDelta(content='-', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,147 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-75f86c8e-3121-4320-8c42-ca133d881b8e', choices=[Choice(delta=ChoiceDelta(content='-', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='-', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,148 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='-', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-75f86c8e-3121-4320-8c42-ca133d881b8e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='-', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,148 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-75f86c8e-3121-4320-8c42-ca133d881b8e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='-', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,149 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='-'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='LFeLzc7M' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0af8c09a-2b14-4612-9371-1e2bfc831619', choices=[Choice(delta=ChoiceDelta(content=' æ–¹æ³•', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,191 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0af8c09a-2b14-4612-9371-1e2bfc831619', choices=[Choice(delta=ChoiceDelta(content=' æ–¹æ³•', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' æ–¹æ³•', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,192 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' æ–¹æ³•', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0af8c09a-2b14-4612-9371-1e2bfc831619', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' æ–¹æ³•', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,192 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0af8c09a-2b14-4612-9371-1e2bfc831619', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' æ–¹æ³•', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,194 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' æ–¹æ³•'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='B3uuCdSJ' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b6f031e0-00c7-44ba-9ee1-ad14defd5d06', choices=[Choice(delta=ChoiceDelta(content='ï¼š', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,194 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b6f031e0-00c7-44ba-9ee1-ad14defd5d06', choices=[Choice(delta=ChoiceDelta(content='ï¼š', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ï¼š', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,196 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ï¼š', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b6f031e0-00c7-44ba-9ee1-ad14defd5d06', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ï¼š', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,196 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b6f031e0-00c7-44ba-9ee1-ad14defd5d06', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ï¼š', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,197 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ï¼š'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='LnSCwpoU' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ff516565-e027-4d56-87c5-229cac2dec28', choices=[Choice(delta=ChoiceDelta(content='æ£€ç´¢', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,197 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ff516565-e027-4d56-87c5-229cac2dec28', choices=[Choice(delta=ChoiceDelta(content='æ£€ç´¢', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ£€ç´¢', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,198 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ£€ç´¢', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ff516565-e027-4d56-87c5-229cac2dec28', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ£€ç´¢', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,198 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ff516565-e027-4d56-87c5-229cac2dec28', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ£€ç´¢', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,199 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ£€ç´¢'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='OHBCjYYB' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d04a78bc-9df1-4ee6-b63b-3fc0795c987e', choices=[Choice(delta=ChoiceDelta(content='è¿‘', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,240 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d04a78bc-9df1-4ee6-b63b-3fc0795c987e', choices=[Choice(delta=ChoiceDelta(content='è¿‘', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¿‘', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,241 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¿‘', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d04a78bc-9df1-4ee6-b63b-3fc0795c987e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¿‘', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,241 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d04a78bc-9df1-4ee6-b63b-3fc0795c987e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¿‘', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,242 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¿‘'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='3Lhkxu4t' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-67cfa458-5b8a-4f46-a7fb-bdef128448e8', choices=[Choice(delta=ChoiceDelta(content='5', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,243 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-67cfa458-5b8a-4f46-a7fb-bdef128448e8', choices=[Choice(delta=ChoiceDelta(content='5', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='5', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,244 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='5', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-67cfa458-5b8a-4f46-a7fb-bdef128448e8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='5', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,244 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-67cfa458-5b8a-4f46-a7fb-bdef128448e8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='5', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,244 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='5'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='xQJv7l24' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c9ae8ec0-3eac-4bb4-9690-5c3ff9301999', choices=[Choice(delta=ChoiceDelta(content='å¹´', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,285 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c9ae8ec0-3eac-4bb4-9690-5c3ff9301999', choices=[Choice(delta=ChoiceDelta(content='å¹´', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å¹´', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,285 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å¹´', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c9ae8ec0-3eac-4bb4-9690-5c3ff9301999', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å¹´', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,286 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c9ae8ec0-3eac-4bb4-9690-5c3ff9301999', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å¹´', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,287 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å¹´'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='YDvOhxFp' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8972ea70-1498-4374-9f4b-b426c80a76cd', choices=[Choice(delta=ChoiceDelta(content='æ–‡çŒ®', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,287 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8972ea70-1498-4374-9f4b-b426c80a76cd', choices=[Choice(delta=ChoiceDelta(content='æ–‡çŒ®', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ–‡çŒ®', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,288 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ–‡çŒ®', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8972ea70-1498-4374-9f4b-b426c80a76cd', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ–‡çŒ®', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,288 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8972ea70-1498-4374-9f4b-b426c80a76cd', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ–‡çŒ®', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,289 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ–‡çŒ®'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='3g5QMLeB' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1c745ccb-7e40-4777-9e7f-3a08d4f18b51', choices=[Choice(delta=ChoiceDelta(content='ï¼Œ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,332 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1c745ccb-7e40-4777-9e7f-3a08d4f18b51', choices=[Choice(delta=ChoiceDelta(content='ï¼Œ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ï¼Œ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,333 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ï¼Œ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1c745ccb-7e40-4777-9e7f-3a08d4f18b51', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ï¼Œ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,333 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1c745ccb-7e40-4777-9e7f-3a08d4f18b51', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ï¼Œ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,334 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ï¼Œ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='myoiUzS8' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-db37acff-b73b-4083-b25d-c2bad3db0155', choices=[Choice(delta=ChoiceDelta(content='èšç„¦', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,334 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-db37acff-b73b-4083-b25d-c2bad3db0155', choices=[Choice(delta=ChoiceDelta(content='èšç„¦', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='èšç„¦', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,335 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='èšç„¦', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-db37acff-b73b-4083-b25d-c2bad3db0155', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='èšç„¦', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,335 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-db37acff-b73b-4083-b25d-c2bad3db0155', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='èšç„¦', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,336 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='èšç„¦'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='qur737VB' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-48573bd0-9adb-406e-9134-2a7eb91cad4f', choices=[Choice(delta=ChoiceDelta(content='ä½œç”¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,377 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-48573bd0-9adb-406e-9134-2a7eb91cad4f', choices=[Choice(delta=ChoiceDelta(content='ä½œç”¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,378 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-48573bd0-9adb-406e-9134-2a7eb91cad4f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,378 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-48573bd0-9adb-406e-9134-2a7eb91cad4f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,379 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä½œç”¨'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='3yLgV750' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-58949fec-7748-4739-90f3-6b4d4d7cc0d3', choices=[Choice(delta=ChoiceDelta(content='æœºåˆ¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,379 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-58949fec-7748-4739-90f3-6b4d4d7cc0d3', choices=[Choice(delta=ChoiceDelta(content='æœºåˆ¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æœºåˆ¶', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,380 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æœºåˆ¶', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-58949fec-7748-4739-90f3-6b4d4d7cc0d3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æœºåˆ¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,381 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-58949fec-7748-4739-90f3-6b4d4d7cc0d3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æœºåˆ¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,382 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æœºåˆ¶'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='MajKYVco' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d473d43a-4ead-44bb-94c4-7c0b849aa855', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,425 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d473d43a-4ead-44bb-94c4-7c0b849aa855', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,426 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d473d43a-4ead-44bb-94c4-7c0b849aa855', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,426 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d473d43a-4ead-44bb-94c4-7c0b849aa855', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,427 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='PAdQRCCN' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6289af38-6508-4c01-a760-73819228bc1f', choices=[Choice(delta=ChoiceDelta(content='ä¸´åºŠ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,429 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6289af38-6508-4c01-a760-73819228bc1f', choices=[Choice(delta=ChoiceDelta(content='ä¸´åºŠ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,430 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6289af38-6508-4c01-a760-73819228bc1f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,430 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6289af38-6508-4c01-a760-73819228bc1f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç³–å°¿ç—…'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç³–å°¿ç—…
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¶³'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¶³
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æºƒç–¡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æºƒç–¡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='é«˜'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: é«˜
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å‘'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å‘
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸”'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸”
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='éš¾'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: éš¾
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ²»'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ²»
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ï¼Œ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ï¼Œ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç°æœ‰'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç°æœ‰
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç–—æ³•'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç–—æ³•
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å±€é™'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å±€é™
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='-'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: -
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' ç›®'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  ç›®
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='çš„'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: çš„
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ï¼š'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ï¼š
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç»¼'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç»¼
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¿°'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¿°
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¡€'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¡€
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å°'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å°
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ¿'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ¿
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='åŠå…¶'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: åŠå…¶
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç”Ÿç‰©'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç”Ÿç‰©
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='çš„'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: çš„
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ²»ç–—'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ²»ç–—
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ½œåŠ›'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ½œåŠ›
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä½œç”¨'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä½œç”¨
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æœºåˆ¶'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æœºåˆ¶
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='-'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: -
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' æ–¹æ³•'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  æ–¹æ³•
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ï¼š'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ï¼š
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ£€ç´¢'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ£€ç´¢
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¿‘'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¿‘
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='5'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 5
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å¹´'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å¹´
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ–‡çŒ®'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ–‡çŒ®
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ï¼Œ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ï¼Œ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='èšç„¦'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: èšç„¦
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä½œç”¨'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä½œç”¨
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æœºåˆ¶'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æœºåˆ¶
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸´åºŠ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸´åºŠ2025-11-18 15:29:11,431 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸´åºŠ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='p3epCXBA' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f2f8a6fa-cba5-447a-8dd3-89c4efaeab90', choices=[Choice(delta=ChoiceDelta(content='è½¬åŒ–', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,432 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f2f8a6fa-cba5-447a-8dd3-89c4efaeab90', choices=[Choice(delta=ChoiceDelta(content='è½¬åŒ–', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è½¬åŒ–', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,433 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è½¬åŒ–', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f2f8a6fa-cba5-447a-8dd3-89c4efaeab90', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è½¬åŒ–', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,433 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f2f8a6fa-cba5-447a-8dd3-89c4efaeab90', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è½¬åŒ–', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,434 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è½¬åŒ–'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='cDElRl7a' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5cba6c04-b960-46f1-868d-149f302a9a79', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,469 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5cba6c04-b960-46f1-868d-149f302a9a79', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,470 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5cba6c04-b960-46f1-868d-149f302a9a79', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,471 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5cba6c04-b960-46f1-868d-149f302a9a79', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,471 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='PVzR9HJH' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-87724fa3-0bba-4dea-b774-eda183ab2c19', choices=[Choice(delta=ChoiceDelta(content='-', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,472 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-87724fa3-0bba-4dea-b774-eda183ab2c19', choices=[Choice(delta=ChoiceDelta(content='-', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='-', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,473 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='-', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-87724fa3-0bba-4dea-b774-eda183ab2c19', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='-', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,474 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-87724fa3-0bba-4dea-b774-eda183ab2c19', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='-', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,475 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='-'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='W6lIV4hx' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-396173a8-6f12-4309-9bba-86bc01cacabd', choices=[Choice(delta=ChoiceDelta(content=' ä¸»', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,516 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-396173a8-6f12-4309-9bba-86bc01cacabd', choices=[Choice(delta=ChoiceDelta(content=' ä¸»', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ä¸»', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,517 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ä¸»', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-396173a8-6f12-4309-9bba-86bc01cacabd', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ä¸»', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,517 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-396173a8-6f12-4309-9bba-86bc01cacabd', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ä¸»', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,518 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' ä¸»'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='kvTkJQsY' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f0916e1e-6577-4a9b-929f-2834fe0a4da9', choices=[Choice(delta=ChoiceDelta(content='è¦', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,519 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f0916e1e-6577-4a9b-929f-2834fe0a4da9', choices=[Choice(delta=ChoiceDelta(content='è¦', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¦', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,520 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¦', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f0916e1e-6577-4a9b-929f-2834fe0a4da9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¦', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,520 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f0916e1e-6577-4a9b-929f-2834fe0a4da9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¦', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,521 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¦'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='i5uhlmVM' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8af5ad02-5e61-4cd0-9a53-d4907667dacb', choices=[Choice(delta=ChoiceDelta(content='å‘ç°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,560 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8af5ad02-5e61-4cd0-9a53-d4907667dacb', choices=[Choice(delta=ChoiceDelta(content='å‘ç°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å‘ç°', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,561 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å‘ç°', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8af5ad02-5e61-4cd0-9a53-d4907667dacb', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å‘ç°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,561 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8af5ad02-5e61-4cd0-9a53-d4907667dacb', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å‘ç°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,562 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å‘ç°'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='7gqzTGDe' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-da090bfb-c134-4aea-bed9-f8bf02e6f279', choices=[Choice(delta=ChoiceDelta(content='ï¼š', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,563 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-da090bfb-c134-4aea-bed9-f8bf02e6f279', choices=[Choice(delta=ChoiceDelta(content='ï¼š', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ï¼š', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,563 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ï¼š', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-da090bfb-c134-4aea-bed9-f8bf02e6f279', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ï¼š', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,564 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-da090bfb-c134-4aea-bed9-f8bf02e6f279', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ï¼š', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,564 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ï¼š'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='TdAL3gw8' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f734b33f-00c4-4717-a494-85d85c4cd071', choices=[Choice(delta=ChoiceDelta(content='è¡€', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,608 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f734b33f-00c4-4717-a494-85d85c4cd071', choices=[Choice(delta=ChoiceDelta(content='è¡€', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡€', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,609 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡€', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f734b33f-00c4-4717-a494-85d85c4cd071', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡€', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,610 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f734b33f-00c4-4717-a494-85d85c4cd071', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡€', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,611 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¡€'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='Rp7ifREZ' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-bbb43e2b-6360-4c80-92e2-311791f8ff73', choices=[Choice(delta=ChoiceDelta(content='å°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,612 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-bbb43e2b-6360-4c80-92e2-311791f8ff73', choices=[Choice(delta=ChoiceDelta(content='å°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,613 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-bbb43e2b-6360-4c80-92e2-311791f8ff73', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,613 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-bbb43e2b-6360-4c80-92e2-311791f8ff73', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,615 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å°'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='vPXQ9NTB' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3df197cd-91c6-4350-aed9-52d33f7e8128', choices=[Choice(delta=ChoiceDelta(content='æ¿', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,657 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3df197cd-91c6-4350-aed9-52d33f7e8128', choices=[Choice(delta=ChoiceDelta(content='æ¿', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,658 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3df197cd-91c6-4350-aed9-52d33f7e8128', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,658 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3df197cd-91c6-4350-aed9-52d33f7e8128', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,659 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ¿'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='2QtsBCVy' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-abb45832-2059-4506-be46-d93a38e8cf27', choices=[Choice(delta=ChoiceDelta(content='è¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,660 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-abb45832-2059-4506-be46-d93a38e8cf27', choices=[Choice(delta=ChoiceDelta(content='è¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,661 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-abb45832-2059-4506-be46-d93a38e8cf27', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,661 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-abb45832-2059-4506-be46-d93a38e8cf27', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,662 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='xO0xCKoz' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ee9565bc-c676-41f4-859f-c8641dbc7add', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,663 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ee9565bc-c676-41f4-859f-c8641dbc7add', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,664 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ee9565bc-c676-41f4-859f-c8641dbc7add', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,664 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ee9565bc-c676-41f4-859f-c8641dbc7add', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,664 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç”Ÿç‰©'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='ipyssV5m' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-50c62aef-3f47-49a4-a251-88e964a31cf7', choices=[Choice(delta=ChoiceDelta(content='ä¿ƒè¿›', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,701 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-50c62aef-3f47-49a4-a251-88e964a31cf7', choices=[Choice(delta=ChoiceDelta(content='ä¿ƒè¿›', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¿ƒè¿›', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,702 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¿ƒè¿›', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-50c62aef-3f47-49a4-a251-88e964a31cf7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¿ƒè¿›', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,702 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-50c62aef-3f47-49a4-a251-88e964a31cf7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¿ƒè¿›', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,703 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¿ƒè¿›'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='sFUMr4ol' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-548d32a1-9702-4dec-a669-e2082b74b92a', choices=[Choice(delta=ChoiceDelta(content='æ„ˆ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,704 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-548d32a1-9702-4dec-a669-e2082b74b92a', choices=[Choice(delta=ChoiceDelta(content='æ„ˆ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ„ˆ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,705 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ„ˆ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-548d32a1-9702-4dec-a669-e2082b74b92a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ„ˆ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,705 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-548d32a1-9702-4dec-a669-e2082b74b92a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ„ˆ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,706 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ„ˆ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='g50iuFp3' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b9abb865-5b7b-41e1-ac72-a8456e93e199', choices=[Choice(delta=ChoiceDelta(content='åˆ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,749 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b9abb865-5b7b-41e1-ac72-a8456e93e199', choices=[Choice(delta=ChoiceDelta(content='åˆ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åˆ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,750 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åˆ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b9abb865-5b7b-41e1-ac72-a8456e93e199', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åˆ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,750 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b9abb865-5b7b-41e1-ac72-a8456e93e199', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åˆ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,750 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='åˆ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='6U9uitNW' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-bcbd64b0-b6c6-4d6c-84f6-de11641b8e21', choices=[Choice(delta=ChoiceDelta(content='ã€', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,751 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-bcbd64b0-b6c6-4d6c-84f6-de11641b8e21', choices=[Choice(delta=ChoiceDelta(content='ã€', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ã€', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,752 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ã€', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-bcbd64b0-b6c6-4d6c-84f6-de11641b8e21', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ã€', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,752 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-bcbd64b0-b6c6-4d6c-84f6-de11641b8e21', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ã€', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,753 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ã€'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='X3POUYsU' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e004455c-17ed-4923-a4f4-6c28dec95dea', choices=[Choice(delta=ChoiceDelta(content='æŠ—', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,796 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e004455c-17ed-4923-a4f4-6c28dec95dea', choices=[Choice(delta=ChoiceDelta(content='æŠ—', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æŠ—', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,797 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æŠ—', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e004455c-17ed-4923-a4f4-6c28dec95dea', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æŠ—', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,798 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e004455c-17ed-4923-a4f4-6c28dec95dea', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æŠ—', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,799 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æŠ—'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='x4f2CGIV' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d77168ee-e3be-4a4a-a5c8-acf368efe363', choices=[Choice(delta=ChoiceDelta(content='ç‚', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,799 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d77168ee-e3be-4a4a-a5c8-acf368efe363', choices=[Choice(delta=ChoiceDelta(content='ç‚', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç‚', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,800 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç‚', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d77168ee-e3be-4a4a-a5c8-acf368efe363', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç‚', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,800 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d77168ee-e3be-4a4a-a5c8-acf368efe363', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç‚', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,802 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç‚'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='Tk6gUaAl' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8dcbbed9-4004-4e7c-8163-9eb50d90523d', choices=[Choice(delta=ChoiceDelta(content='åŠ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,843 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8dcbbed9-4004-4e7c-8163-9eb50d90523d', choices=[Choice(delta=ChoiceDelta(content='åŠ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450946, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åŠ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,844 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åŠ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8dcbbed9-4004-4e7c-8163-9eb50d90523d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åŠ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,844 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8dcbbed9-4004-4e7c-8163-9eb50d90523d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åŠ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,846 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='åŠ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='KDtxhvd0' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-396557a0-0135-4653-8921-3ecf693cad11', choices=[Choice(delta=ChoiceDelta(content='è¡€ç®¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,846 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-396557a0-0135-4653-8921-3ecf693cad11', choices=[Choice(delta=ChoiceDelta(content='è¡€ç®¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡€ç®¡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,848 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡€ç®¡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-396557a0-0135-4653-8921-3ecf693cad11', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡€ç®¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,848 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-396557a0-0135-4653-8921-3ecf693cad11', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡€ç®¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,849 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¡€ç®¡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='OnZSz2g1' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-93c1eb8f-c462-470e-967e-49e15057d320', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿæˆ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,850 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-93c1eb8f-c462-470e-967e-49e15057d320', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿæˆ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿæˆ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,851 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿæˆ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-93c1eb8f-c462-470e-967e-49e15057d320', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿæˆ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,851 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-93c1eb8f-c462-470e-967e-49e15057d320', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿæˆ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,852 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç”Ÿæˆ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='1OR5mg3g' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7055ae2c-96e8-472b-bc9a-cd9ea36bcbf5', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,891 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7055ae2c-96e8-472b-bc9a-cd9ea36bcbf5', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,892 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7055ae2c-96e8-472b-bc9a-cd9ea36bcbf5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,892 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7055ae2c-96e8-472b-bc9a-cd9ea36bcbf5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,893 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='L0UfnjYM' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-49b39492-d4c8-42a9-baaa-8ddebc3a7b0e', choices=[Choice(delta=ChoiceDelta(content='-', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,894 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-49b39492-d4c8-42a9-baaa-8ddebc3a7b0e', choices=[Choice(delta=ChoiceDelta(content='-', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='-', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,895 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='-', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-49b39492-d4c8-42a9-baaa-8ddebc3a7b0e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='-', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,895 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-49b39492-d4c8-42a9-baaa-8ddebc3a7b0e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='-', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,895 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='-'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='PDbOHFbt' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d448704a-6df9-4253-933f-f05f2ebdbddf', choices=[Choice(delta=ChoiceDelta(content=' ç»“', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,936 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d448704a-6df9-4253-933f-f05f2ebdbddf', choices=[Choice(delta=ChoiceDelta(content=' ç»“', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ç»“', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,937 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ç»“', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d448704a-6df9-4253-933f-f05f2ebdbddf', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ç»“', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,937 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d448704a-6df9-4253-933f-f05f2ebdbddf', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ç»“', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,938 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' ç»“'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='ugrGreMh' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d9d36a1e-e6ae-4269-a03d-aba3a1e9e069', choices=[Choice(delta=ChoiceDelta(content='è®º', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,939 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d9d36a1e-e6ae-4269-a03d-aba3a1e9e069', choices=[Choice(delta=ChoiceDelta(content='è®º', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è®º', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,941 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è®º', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d9d36a1e-e6ae-4269-a03d-aba3a1e9e069', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è®º', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,941 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d9d36a1e-e6ae-4269-a03d-aba3a1e9e069', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è®º', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,942 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è®º'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='sqKAQx6B' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f1fd0550-ddf7-4c3b-a387-c4fd1ec06e20', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,984 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f1fd0550-ddf7-4c3b-a387-c4fd1ec06e20', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,986 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f1fd0550-ddf7-4c3b-a387-c4fd1ec06e20', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,986 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f1fd0550-ddf7-4c3b-a387-c4fd1ec06e20', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,987 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='iU4Q6AvT' timestamp=1763450949.457893
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-95536df6-ff18-481d-92ca-1cfe764ee235', choices=[Choice(delta=ChoiceDelta(content='å±•æœ›', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:11,988 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-95536df6-ff18-481d-92ca-1cfe764ee235', choices=[Choice(delta=ChoiceDelta(content='å±•æœ›', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å±•æœ›', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:11,990 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å±•æœ›', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:11 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-95536df6-ff18-481d-92ca-1cfe764ee235', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å±•æœ›', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,990 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-95536df6-ff18-481d-92ca-1cfe764ee235', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å±•æœ›', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:11,991 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å±•æœ›'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='EiYrEuTI' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c32a18f7-6b34-4e30-903c-2f80260d69af', choices=[Choice(delta=ChoiceDelta(content='ï¼š', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,029 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c32a18f7-6b34-4e30-903c-2f80260d69af', choices=[Choice(delta=ChoiceDelta(content='ï¼š', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ï¼š', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,031 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ï¼š', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c32a18f7-6b34-4e30-903c-2f80260d69af', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ï¼š', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,031 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c32a18f7-6b34-4e30-903c-2f80260d69af', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ï¼š', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,033 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ï¼š'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='59Zx1RO1' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ce460e2d-460c-41f1-a29e-4e3f9929e233', choices=[Choice(delta=ChoiceDelta(content='æ ‡å‡†åŒ–', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,033 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ce460e2d-460c-41f1-a29e-4e3f9929e233', choices=[Choice(delta=ChoiceDelta(content='æ ‡å‡†åŒ–', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ ‡å‡†åŒ–', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,034 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ ‡å‡†åŒ–', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ce460e2d-460c-41f1-a29e-4e3f9929e233', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ ‡å‡†åŒ–', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,034 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ce460e2d-460c-41f1-a29e-4e3f9929e233', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ ‡å‡†åŒ–', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,035 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ ‡å‡†åŒ–'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='ICzfSSoW' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-efef7c3c-5781-40aa-9e0d-3030cc4297b4', choices=[Choice(delta=ChoiceDelta(content='åˆ¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,036 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-efef7c3c-5781-40aa-9e0d-3030cc4297b4', choices=[Choice(delta=ChoiceDelta(content='åˆ¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åˆ¶', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,037 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åˆ¶', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-efef7c3c-5781-40aa-9e0d-3030cc4297b4', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åˆ¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,037 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-efef7c3c-5781-40aa-9e0d-3030cc4297b4', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åˆ¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,038 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='åˆ¶'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='tkemRm7s' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a1870346-d7f1-4739-a432-ed597cc25be4', choices=[Choice(delta=ChoiceDelta(content='å¤‡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,077 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a1870346-d7f1-4739-a432-ed597cc25be4', choices=[Choice(delta=ChoiceDelta(content='å¤‡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å¤‡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,079 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å¤‡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a1870346-d7f1-4739-a432-ed597cc25be4', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å¤‡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,079 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a1870346-d7f1-4739-a432-ed597cc25be4', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å¤‡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,080 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å¤‡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='IIfyAv4A' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9a5b32d6-e801-4751-a259-ead33a66c964', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,081 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9a5b32d6-e801-4751-a259-ead33a66c964', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,082 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9a5b32d6-e801-4751-a259-ead33a66c964', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,082 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9a5b32d6-e801-4751-a259-ead33a66c964', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,083 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='VF9D9D4R' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4af17548-5872-40c0-8b03-3f4c79c1d6fb', choices=[Choice(delta=ChoiceDelta(content='ä¸´åºŠ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,122 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4af17548-5872-40c0-8b03-3f4c79c1d6fb', choices=[Choice(delta=ChoiceDelta(content='ä¸´åºŠ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,124 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4af17548-5872-40c0-8b03-3f4c79c1d6fb', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,124 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4af17548-5872-40c0-8b03-3f4c79c1d6fb', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,125 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸´åºŠ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='JlXmbeVa' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-75f65432-52b6-4e55-961e-096d1a055b95', choices=[Choice(delta=ChoiceDelta(content='éªŒè¯', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,126 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-75f65432-52b6-4e55-961e-096d1a055b95', choices=[Choice(delta=ChoiceDelta(content='éªŒè¯', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='éªŒè¯', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,128 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='éªŒè¯', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-75f65432-52b6-4e55-961e-096d1a055b95', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='éªŒè¯', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,128 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-75f65432-52b6-4e55-961e-096d1a055b95', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='éªŒè¯', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,129 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='éªŒè¯'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='98vRfcru' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-aa298358-610c-44f2-81a2-a179be526499', choices=[Choice(delta=ChoiceDelta(content='ä»æ˜¯', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,170 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-aa298358-610c-44f2-81a2-a179be526499', choices=[Choice(delta=ChoiceDelta(content='ä»æ˜¯', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä»æ˜¯', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,172 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä»æ˜¯', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-aa298358-610c-44f2-81a2-a179be526499', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä»æ˜¯', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,172 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-aa298358-610c-44f2-81a2-a179be526499', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä»æ˜¯', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,174 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä»æ˜¯'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='4yt7RDxV' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a89ca280-a43c-4109-bb75-5a47a79f6e9f', choices=[Choice(delta=ChoiceDelta(content='å…³é”®', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,174 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a89ca280-a43c-4109-bb75-5a47a79f6e9f', choices=[Choice(delta=ChoiceDelta(content='å…³é”®', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å…³é”®', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,176 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å…³é”®', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a89ca280-a43c-4109-bb75-5a47a79f6e9f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å…³é”®', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,177 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a89ca280-a43c-4109-bb75-5a47a79f6e9f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å…³é”®', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,178 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å…³é”®'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='1vFpyhpY' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-dcb046c8-61b3-4531-b075-5608ccf3ca88', choices=[Choice(delta=ChoiceDelta(content='æŒ‘æˆ˜', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,216 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-dcb046c8-61b3-4531-b075-5608ccf3ca88', choices=[Choice(delta=ChoiceDelta(content='æŒ‘æˆ˜', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æŒ‘æˆ˜', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,218 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æŒ‘æˆ˜', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-dcb046c8-61b3-4531-b075-5608ccf3ca88', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æŒ‘æˆ˜', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,218 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-dcb046c8-61b3-4531-b075-5608ccf3ca88', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æŒ‘æˆ˜', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,219 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æŒ‘æˆ˜'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='8gWinpew' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-747ae110-40ff-431e-a86c-569a387111de', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,220 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-747ae110-40ff-431e-a86c-569a387111de', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,221 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-747ae110-40ff-431e-a86c-569a387111de', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,221 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-747ae110-40ff-431e-a86c-569a387111de', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,222 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='LluYzynu' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-94c3898b-ba79-422b-a912-f1a550220003', choices=[Choice(delta=ChoiceDelta(content='-', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,223 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-94c3898b-ba79-422b-a912-f1a550220003', choices=[Choice(delta=ChoiceDelta(content='-', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='-', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,225 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='-', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-94c3898b-ba79-422b-a912-f1a550220003', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='-', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,225 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-94c3898b-ba79-422b-a912-f1a550220003', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='-', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,225 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='-'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='HY9PrdX2' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-36115440-28cb-49be-98f0-f7916d1851ea', choices=[Choice(delta=ChoiceDelta(content=' å…³', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,264 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-36115440-28cb-49be-98f0-f7916d1851ea', choices=[Choice(delta=ChoiceDelta(content=' å…³', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' å…³', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,265 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' å…³', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-36115440-28cb-49be-98f0-f7916d1851ea', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' å…³', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,266 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-36115440-28cb-49be-98f0-f7916d1851ea', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' å…³', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,266 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' å…³'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='hFT6dTUk' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-15239023-a9ae-4908-8cad-ab42ee605df8', choices=[Choice(delta=ChoiceDelta(content='é”®', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,267 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-15239023-a9ae-4908-8cad-ab42ee605df8', choices=[Choice(delta=ChoiceDelta(content='é”®', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='é”®', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,268 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='é”®', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-15239023-a9ae-4908-8cad-ab42ee605df8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='é”®', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,269 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-15239023-a9ae-4908-8cad-ab42ee605df8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='é”®', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,269 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='é”®'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='pT2Bje8D' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-eca81b6a-508b-4a82-8206-a87ed26cee6f', choices=[Choice(delta=ChoiceDelta(content='è¯', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,311 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-eca81b6a-508b-4a82-8206-a87ed26cee6f', choices=[Choice(delta=ChoiceDelta(content='è¯', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¯', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,313 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¯', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-eca81b6a-508b-4a82-8206-a87ed26cee6f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¯', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,313 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-eca81b6a-508b-4a82-8206-a87ed26cee6f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¯', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,315 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¯'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='U53Nmz1m' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d31e7b97-9f7e-4135-a315-fe6510d5212a', choices=[Choice(delta=ChoiceDelta(content='ï¼š', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,316 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d31e7b97-9f7e-4135-a315-fe6510d5212a', choices=[Choice(delta=ChoiceDelta(content='ï¼š', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ï¼š', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,318 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ï¼š', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d31e7b97-9f7e-4135-a315-fe6510d5212a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ï¼š', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,318 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d31e7b97-9f7e-4135-a315-fe6510d5212a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ï¼š', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,318 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ï¼š'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='daHqqeU6' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-df25d88f-5a4f-4e42-9537-06c64a1ca80f', choices=[Choice(delta=ChoiceDelta(content='è¡€', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,357 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-df25d88f-5a4f-4e42-9537-06c64a1ca80f', choices=[Choice(delta=ChoiceDelta(content='è¡€', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡€', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,358 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡€', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-df25d88f-5a4f-4e42-9537-06c64a1ca80f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡€', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,359 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-df25d88f-5a4f-4e42-9537-06c64a1ca80f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡€', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,360 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¡€'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='bhZuiDdL' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1d2c57c8-bd74-4f25-af88-19396a2aba09', choices=[Choice(delta=ChoiceDelta(content='å°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,360 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1d2c57c8-bd74-4f25-af88-19396a2aba09', choices=[Choice(delta=ChoiceDelta(content='å°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,362 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1d2c57c8-bd74-4f25-af88-19396a2aba09', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,362 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1d2c57c8-bd74-4f25-af88-19396a2aba09', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,363 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å°'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='5XepRbtT' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b62ab3c8-5205-4888-9b40-1831b8d550e1', choices=[Choice(delta=ChoiceDelta(content='æ¿', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,404 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b62ab3c8-5205-4888-9b40-1831b8d550e1', choices=[Choice(delta=ChoiceDelta(content='æ¿', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,406 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b62ab3c8-5205-4888-9b40-1831b8d550e1', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,407 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b62ab3c8-5205-4888-9b40-1831b8d550e1', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è½¬åŒ–'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è½¬åŒ–
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='-'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: -
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' ä¸»'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  ä¸»
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¦'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¦
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å‘ç°'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å‘ç°
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ï¼š'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ï¼š
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¡€'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¡€
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å°'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å°
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ¿'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ¿
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç”Ÿç‰©'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç”Ÿç‰©
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¿ƒè¿›'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¿ƒè¿›
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ„ˆ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ„ˆ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='åˆ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: åˆ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ã€'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ã€
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æŠ—'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æŠ—
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç‚'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç‚
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='åŠ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: åŠ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¡€ç®¡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¡€ç®¡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç”Ÿæˆ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç”Ÿæˆ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='-'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: -
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' ç»“'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  ç»“
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è®º'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è®º
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å±•æœ›'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å±•æœ›
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ï¼š'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ï¼š
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ ‡å‡†åŒ–'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ ‡å‡†åŒ–
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='åˆ¶'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: åˆ¶
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å¤‡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å¤‡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸´åºŠ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸´åºŠ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='éªŒè¯'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: éªŒè¯
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä»æ˜¯'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä»æ˜¯
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å…³é”®'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å…³é”®
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æŒ‘æˆ˜'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æŒ‘æˆ˜
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='-'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: -
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' å…³'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  å…³
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='é”®'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: é”®
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¯'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¯
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ï¼š'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ï¼š
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¡€'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¡€
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å°'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å°
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ¿'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ¿2025-11-18 15:29:12,408 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ¿'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='TqXvoE3r' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-41316047-cff4-45fd-bcc5-f0c717e124d3', choices=[Choice(delta=ChoiceDelta(content='ï¼›', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,408 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-41316047-cff4-45fd-bcc5-f0c717e124d3', choices=[Choice(delta=ChoiceDelta(content='ï¼›', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ï¼›', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,410 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ï¼›', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-41316047-cff4-45fd-bcc5-f0c717e124d3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ï¼›', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,411 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-41316047-cff4-45fd-bcc5-f0c717e124d3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ï¼›', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,411 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ï¼›'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='vNLmG6vn' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-02a8a627-dbf3-49aa-b1b1-a234d39cd432', choices=[Choice(delta=ChoiceDelta(content='è¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,412 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-02a8a627-dbf3-49aa-b1b1-a234d39cd432', choices=[Choice(delta=ChoiceDelta(content='è¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,413 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-02a8a627-dbf3-49aa-b1b1-a234d39cd432', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,413 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-02a8a627-dbf3-49aa-b1b1-a234d39cd432', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,415 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='GuSFPBdE' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ec5daf49-f7fc-4e38-9cc7-aad0593939e6', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,449 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ec5daf49-f7fc-4e38-9cc7-aad0593939e6', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,450 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ec5daf49-f7fc-4e38-9cc7-aad0593939e6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,451 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ec5daf49-f7fc-4e38-9cc7-aad0593939e6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,452 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç”Ÿç‰©'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='CuLZDX9t' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5b98e55a-b637-4596-badf-0f95441d6390', choices=[Choice(delta=ChoiceDelta(content='ï¼›', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,452 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5b98e55a-b637-4596-badf-0f95441d6390', choices=[Choice(delta=ChoiceDelta(content='ï¼›', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ï¼›', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,454 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ï¼›', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5b98e55a-b637-4596-badf-0f95441d6390', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ï¼›', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,454 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5b98e55a-b637-4596-badf-0f95441d6390', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ï¼›', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,454 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ï¼›'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='65orfLaJ' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-19a4efbb-cc71-43ae-a637-406100707193', choices=[Choice(delta=ChoiceDelta(content='ç³–å°¿ç—…', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,496 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-19a4efbb-cc71-43ae-a637-406100707193', choices=[Choice(delta=ChoiceDelta(content='ç³–å°¿ç—…', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç³–å°¿ç—…', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,498 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç³–å°¿ç—…', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-19a4efbb-cc71-43ae-a637-406100707193', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç³–å°¿ç—…', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,498 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-19a4efbb-cc71-43ae-a637-406100707193', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç³–å°¿ç—…', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,499 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç³–å°¿ç—…'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='ynp6F880' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-369c9a37-a44a-417d-ad32-b072dc973479', choices=[Choice(delta=ChoiceDelta(content='è¶³', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,500 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-369c9a37-a44a-417d-ad32-b072dc973479', choices=[Choice(delta=ChoiceDelta(content='è¶³', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¶³', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,501 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¶³', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-369c9a37-a44a-417d-ad32-b072dc973479', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¶³', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,501 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-369c9a37-a44a-417d-ad32-b072dc973479', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¶³', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,502 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¶³'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='o6lAFc5g' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-99a96ec6-6cce-4260-b4c9-9cd6ccdfc530', choices=[Choice(delta=ChoiceDelta(content='æºƒç–¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,543 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-99a96ec6-6cce-4260-b4c9-9cd6ccdfc530', choices=[Choice(delta=ChoiceDelta(content='æºƒç–¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æºƒç–¡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,546 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æºƒç–¡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-99a96ec6-6cce-4260-b4c9-9cd6ccdfc530', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æºƒç–¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,546 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-99a96ec6-6cce-4260-b4c9-9cd6ccdfc530', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æºƒç–¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,547 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æºƒç–¡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='A9LW5Lep' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-259186f0-2e5e-4e0e-9b2b-3ab239909db7', choices=[Choice(delta=ChoiceDelta(content='ï¼›', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,548 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-259186f0-2e5e-4e0e-9b2b-3ab239909db7', choices=[Choice(delta=ChoiceDelta(content='ï¼›', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ï¼›', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,550 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ï¼›', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-259186f0-2e5e-4e0e-9b2b-3ab239909db7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ï¼›', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,550 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-259186f0-2e5e-4e0e-9b2b-3ab239909db7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ï¼›', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,551 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ï¼›'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='P170npIM' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-69071cea-5b36-4085-a097-c843d0e5a36c', choices=[Choice(delta=ChoiceDelta(content='ä½œç”¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,589 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-69071cea-5b36-4085-a097-c843d0e5a36c', choices=[Choice(delta=ChoiceDelta(content='ä½œç”¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,591 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-69071cea-5b36-4085-a097-c843d0e5a36c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,591 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-69071cea-5b36-4085-a097-c843d0e5a36c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,592 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä½œç”¨'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='jZYUIO1c' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6f65c44e-655d-4ceb-8713-bad0be47795c', choices=[Choice(delta=ChoiceDelta(content='æœºåˆ¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,592 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6f65c44e-655d-4ceb-8713-bad0be47795c', choices=[Choice(delta=ChoiceDelta(content='æœºåˆ¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æœºåˆ¶', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,594 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æœºåˆ¶', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6f65c44e-655d-4ceb-8713-bad0be47795c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æœºåˆ¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,595 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6f65c44e-655d-4ceb-8713-bad0be47795c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æœºåˆ¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,596 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æœºåˆ¶'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='Z5x87T6k' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-fb12f699-4e69-4d3f-acb2-ac7d16342c39', choices=[Choice(delta=ChoiceDelta(content='ï¼›', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,635 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-fb12f699-4e69-4d3f-acb2-ac7d16342c39', choices=[Choice(delta=ChoiceDelta(content='ï¼›', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ï¼›', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,636 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ï¼›', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-fb12f699-4e69-4d3f-acb2-ac7d16342c39', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ï¼›', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,636 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-fb12f699-4e69-4d3f-acb2-ac7d16342c39', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ï¼›', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,637 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ï¼›'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='2dABJcOj' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b2c89caa-c67a-4dfa-ac5d-34ab99645fb8', choices=[Choice(delta=ChoiceDelta(content='æ²»ç–—', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,638 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b2c89caa-c67a-4dfa-ac5d-34ab99645fb8', choices=[Choice(delta=ChoiceDelta(content='æ²»ç–—', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,640 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b2c89caa-c67a-4dfa-ac5d-34ab99645fb8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,640 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b2c89caa-c67a-4dfa-ac5d-34ab99645fb8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,641 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ²»ç–—'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='w94DZelG' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4fcb890b-dc61-4210-8c42-21043ab37c3a', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,642 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4fcb890b-dc61-4210-8c42-21043ab37c3a', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,642 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4fcb890b-dc61-4210-8c42-21043ab37c3a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,642 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4fcb890b-dc61-4210-8c42-21043ab37c3a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,643 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""

"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='l12tZDUo' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d00c1ea8-f099-4fb8-ac5e-cfbe81fb59c0', choices=[Choice(delta=ChoiceDelta(content='##', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,682 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d00c1ea8-f099-4fb8-ac5e-cfbe81fb59c0', choices=[Choice(delta=ChoiceDelta(content='##', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,683 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d00c1ea8-f099-4fb8-ac5e-cfbe81fb59c0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,683 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d00c1ea8-f099-4fb8-ac5e-cfbe81fb59c0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,684 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='##'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='DIwJ5B3D' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-aa21f121-8dd3-4350-b578-66a166b170e6', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,684 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-aa21f121-8dd3-4350-b578-66a166b170e6', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,686 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-aa21f121-8dd3-4350-b578-66a166b170e6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,687 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-aa21f121-8dd3-4350-b578-66a166b170e6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,688 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='pEWKZLqx' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a31affcf-5c6e-4d6f-becf-71776ac40cdd', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,728 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a31affcf-5c6e-4d6f-becf-71776ac40cdd', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,729 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a31affcf-5c6e-4d6f-becf-71776ac40cdd', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,729 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a31affcf-5c6e-4d6f-becf-71776ac40cdd', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,731 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='1'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='iqqcCT4T' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6af1f414-d989-4cb3-8357-853ddc39b71b', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,732 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6af1f414-d989-4cb3-8357-853ddc39b71b', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,733 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6af1f414-d989-4cb3-8357-853ddc39b71b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,733 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6af1f414-d989-4cb3-8357-853ddc39b71b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,734 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='0BQSrWRk' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4ebbbe35-b2e4-4e97-b8fc-79ec545e8c81', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,775 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4ebbbe35-b2e4-4e97-b8fc-79ec545e8c81', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,777 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4ebbbe35-b2e4-4e97-b8fc-79ec545e8c81', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,777 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4ebbbe35-b2e4-4e97-b8fc-79ec545e8c81', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0c977b8c-9072-4295-a260-903018cf9dba', choices=[Choice(delta=ChoiceDelta(content=' å¼•', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,778 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0c977b8c-9072-4295-a260-903018cf9dba', choices=[Choice(delta=ChoiceDelta(content=' å¼•', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' å¼•', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,779 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' å¼•', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0c977b8c-9072-4295-a260-903018cf9dba', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' å¼•', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,779 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0c977b8c-9072-4295-a260-903018cf9dba', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' å¼•', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,780 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' å¼•'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='suJDpmNn' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d00e72c8-24a8-4780-bbc0-c046e857a515', choices=[Choice(delta=ChoiceDelta(content='è¨€', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,824 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d00e72c8-24a8-4780-bbc0-c046e857a515', choices=[Choice(delta=ChoiceDelta(content='è¨€', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¨€', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,825 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¨€', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d00e72c8-24a8-4780-bbc0-c046e857a515', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¨€', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,825 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d00e72c8-24a8-4780-bbc0-c046e857a515', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¨€', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,826 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¨€'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='RuNEA28q' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b0c2ea4e-06d9-4680-946c-6b09b05b7a80', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,828 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b0c2ea4e-06d9-4680-946c-6b09b05b7a80', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450947, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,829 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b0c2ea4e-06d9-4680-946c-6b09b05b7a80', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,830 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b0c2ea4e-06d9-4680-946c-6b09b05b7a80', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,832 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='9bcTvAPl' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-24d33af5-4c39-42f8-8b9e-0e814bd1b919', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,833 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-24d33af5-4c39-42f8-8b9e-0e814bd1b919', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,834 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-24d33af5-4c39-42f8-8b9e-0e814bd1b919', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,834 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-24d33af5-4c39-42f8-8b9e-0e814bd1b919', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,835 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='ZXNigNl9' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f324b36f-29a6-4eb8-b2cb-1309f9507496', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,868 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f324b36f-29a6-4eb8-b2cb-1309f9507496', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,870 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f324b36f-29a6-4eb8-b2cb-1309f9507496', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,870 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f324b36f-29a6-4eb8-b2cb-1309f9507496', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,871 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='FM4XOmgd' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-de6440f8-13ca-4560-97a1-1f25eeecbab1', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,871 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-de6440f8-13ca-4560-97a1-1f25eeecbab1', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,873 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-de6440f8-13ca-4560-97a1-1f25eeecbab1', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,873 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-de6440f8-13ca-4560-97a1-1f25eeecbab1', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,874 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='1'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='XID9fD6B' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1c3f0853-6844-4d10-b39f-29ac07fb4295', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,915 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1c3f0853-6844-4d10-b39f-29ac07fb4295', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,916 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1c3f0853-6844-4d10-b39f-29ac07fb4295', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,916 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1c3f0853-6844-4d10-b39f-29ac07fb4295', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,917 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='7IzQ1gvK' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a03c9b11-3764-49e0-b7f5-cb369a340504', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,917 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a03c9b11-3764-49e0-b7f5-cb369a340504', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,918 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a03c9b11-3764-49e0-b7f5-cb369a340504', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,918 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a03c9b11-3764-49e0-b7f5-cb369a340504', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,919 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='1'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='aACa7t8w' timestamp=1763450949.457893
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-541cc0a0-2814-4201-9303-b28f60f1fd05', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,962 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-541cc0a0-2814-4201-9303-b28f60f1fd05', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,964 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-541cc0a0-2814-4201-9303-b28f60f1fd05', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,964 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-541cc0a0-2814-4201-9303-b28f60f1fd05', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9d522ebc-2966-4d39-a019-5809b82046ea', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:12,965 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9d522ebc-2966-4d39-a019-5809b82046ea', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:12,967 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:12 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9d522ebc-2966-4d39-a019-5809b82046ea', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:12,967 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9d522ebc-2966-4d39-a019-5809b82046ea', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-42889eee-775a-47eb-96b3-14498570fd9a', choices=[Choice(delta=ChoiceDelta(content=' ç³–', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,010 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-42889eee-775a-47eb-96b3-14498570fd9a', choices=[Choice(delta=ChoiceDelta(content=' ç³–', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ç³–', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,012 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ç³–', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-42889eee-775a-47eb-96b3-14498570fd9a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ç³–', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,013 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-42889eee-775a-47eb-96b3-14498570fd9a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ç³–', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,014 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' ç³–'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='W1KSvXgu' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7b19c6d2-2d4a-42b2-8a93-b68e70b7e96b', choices=[Choice(delta=ChoiceDelta(content='å°¿', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,015 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7b19c6d2-2d4a-42b2-8a93-b68e70b7e96b', choices=[Choice(delta=ChoiceDelta(content='å°¿', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å°¿', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,017 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å°¿', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7b19c6d2-2d4a-42b2-8a93-b68e70b7e96b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å°¿', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,017 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7b19c6d2-2d4a-42b2-8a93-b68e70b7e96b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å°¿', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,018 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å°¿'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='zw7cPp2P' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-35c441c5-41ee-4602-8a89-2347e5fd651a', choices=[Choice(delta=ChoiceDelta(content='ç—…', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,058 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-35c441c5-41ee-4602-8a89-2347e5fd651a', choices=[Choice(delta=ChoiceDelta(content='ç—…', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç—…', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,059 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç—…', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-35c441c5-41ee-4602-8a89-2347e5fd651a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç—…', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,059 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-35c441c5-41ee-4602-8a89-2347e5fd651a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç—…', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,061 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç—…'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='pJRE2g6f' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4dbb2d5e-f646-434f-95be-ab4a37a07a00', choices=[Choice(delta=ChoiceDelta(content='è¶³', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,062 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4dbb2d5e-f646-434f-95be-ab4a37a07a00', choices=[Choice(delta=ChoiceDelta(content='è¶³', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¶³', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,063 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¶³', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4dbb2d5e-f646-434f-95be-ab4a37a07a00', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¶³', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,063 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4dbb2d5e-f646-434f-95be-ab4a37a07a00', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¶³', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,064 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¶³'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='C7fFVN6K' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8b1fe325-6844-4f79-997f-bf20acdd4263', choices=[Choice(delta=ChoiceDelta(content='æºƒç–¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,066 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8b1fe325-6844-4f79-997f-bf20acdd4263', choices=[Choice(delta=ChoiceDelta(content='æºƒç–¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æºƒç–¡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,067 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æºƒç–¡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8b1fe325-6844-4f79-997f-bf20acdd4263', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æºƒç–¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,067 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8b1fe325-6844-4f79-997f-bf20acdd4263', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æºƒç–¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,068 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æºƒç–¡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='G7wDx0XJ' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ab4f7a6b-bd38-4517-97a2-8e2bd9af815b', choices=[Choice(delta=ChoiceDelta(content='ç°çŠ¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,107 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ab4f7a6b-bd38-4517-97a2-8e2bd9af815b', choices=[Choice(delta=ChoiceDelta(content='ç°çŠ¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç°çŠ¶', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,108 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç°çŠ¶', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ab4f7a6b-bd38-4517-97a2-8e2bd9af815b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç°çŠ¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,108 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ab4f7a6b-bd38-4517-97a2-8e2bd9af815b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç°çŠ¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,109 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç°çŠ¶'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='vwrQV2C9' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c765569b-ca1d-400e-bd1b-df18b2fb6385', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,110 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c765569b-ca1d-400e-bd1b-df18b2fb6385', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,112 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c765569b-ca1d-400e-bd1b-df18b2fb6385', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,112 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c765569b-ca1d-400e-bd1b-df18b2fb6385', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,113 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='WyZ3MTQS' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0208c667-0033-4bfb-b0fe-4a1dad6f85cf', choices=[Choice(delta=ChoiceDelta(content='æ²»ç–—', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,151 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0208c667-0033-4bfb-b0fe-4a1dad6f85cf', choices=[Choice(delta=ChoiceDelta(content='æ²»ç–—', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,153 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0208c667-0033-4bfb-b0fe-4a1dad6f85cf', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,153 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0208c667-0033-4bfb-b0fe-4a1dad6f85cf', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,154 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ²»ç–—'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='HHL5YCdr' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-51ab5663-2bef-4968-b462-c7d550acb65f', choices=[Choice(delta=ChoiceDelta(content='æŒ‘æˆ˜', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,155 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-51ab5663-2bef-4968-b462-c7d550acb65f', choices=[Choice(delta=ChoiceDelta(content='æŒ‘æˆ˜', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æŒ‘æˆ˜', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,156 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æŒ‘æˆ˜', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-51ab5663-2bef-4968-b462-c7d550acb65f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æŒ‘æˆ˜', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,156 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-51ab5663-2bef-4968-b462-c7d550acb65f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æŒ‘æˆ˜', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,157 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æŒ‘æˆ˜'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='4SbeQNIV' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-283ed411-ea3b-438d-8cd9-5f7eb8d912f2', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,198 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-283ed411-ea3b-438d-8cd9-5f7eb8d912f2', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,199 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-283ed411-ea3b-438d-8cd9-5f7eb8d912f2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,199 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-283ed411-ea3b-438d-8cd9-5f7eb8d912f2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,200 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='GTyks66p' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-294e1a0e-d675-4998-b945-4da82d81f2c5', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,201 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-294e1a0e-d675-4998-b945-4da82d81f2c5', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,202 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-294e1a0e-d675-4998-b945-4da82d81f2c5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,202 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-294e1a0e-d675-4998-b945-4da82d81f2c5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,203 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='Jrp5dA1h' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4dec817c-1fdc-4ee2-8e2f-f1ea6e268690', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,251 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4dec817c-1fdc-4ee2-8e2f-f1ea6e268690', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,253 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4dec817c-1fdc-4ee2-8e2f-f1ea6e268690', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,253 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4dec817c-1fdc-4ee2-8e2f-f1ea6e268690', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,254 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='tG2zUTjq' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-408f807a-254b-4f3b-b961-4461f6a5f74d', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,255 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-408f807a-254b-4f3b-b961-4461f6a5f74d', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,257 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-408f807a-254b-4f3b-b961-4461f6a5f74d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,257 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-408f807a-254b-4f3b-b961-4461f6a5f74d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,258 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='1'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='NRDCLpqR' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-42daa1f9-f895-461f-8e2d-611b1550c0b0', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,258 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-42daa1f9-f895-461f-8e2d-611b1550c0b0', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,260 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-42daa1f9-f895-461f-8e2d-611b1550c0b0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,260 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-42daa1f9-f895-461f-8e2d-611b1550c0b0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,262 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='YK5A0SFK' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c274ea1b-396c-4a71-8423-19f963eb857d', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,305 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c274ea1b-396c-4a71-8423-19f963eb857d', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,307 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c274ea1b-396c-4a71-8423-19f963eb857d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,307 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c274ea1b-396c-4a71-8423-19f963eb857d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,308 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='2'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='N9niSH2S' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e8f0d590-c412-4d1a-8741-37dbe9d7e01d', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,309 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e8f0d590-c412-4d1a-8741-37dbe9d7e01d', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,310 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e8f0d590-c412-4d1a-8741-37dbe9d7e01d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,310 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e8f0d590-c412-4d1a-8741-37dbe9d7e01d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-34d8b41e-1cb1-4096-8f35-a7cea2f6f2e2', choices=[Choice(delta=ChoiceDelta(content=' è¡€', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,310 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-34d8b41e-1cb1-4096-8f35-a7cea2f6f2e2', choices=[Choice(delta=ChoiceDelta(content=' è¡€', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' è¡€', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,312 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' è¡€', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-34d8b41e-1cb1-4096-8f35-a7cea2f6f2e2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' è¡€', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,312 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-34d8b41e-1cb1-4096-8f35-a7cea2f6f2e2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' è¡€', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,313 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' è¡€'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='UuRvWBw6' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-38055e86-cae4-4e37-8f6d-6467fa95008c', choices=[Choice(delta=ChoiceDelta(content='å°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,352 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-38055e86-cae4-4e37-8f6d-6467fa95008c', choices=[Choice(delta=ChoiceDelta(content='å°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,354 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-38055e86-cae4-4e37-8f6d-6467fa95008c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,354 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-38055e86-cae4-4e37-8f6d-6467fa95008c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,355 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å°'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='X5E1UqIg' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b5fc9c5a-7cdc-4b22-9688-2827f5f9e5bb', choices=[Choice(delta=ChoiceDelta(content='æ¿', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,356 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b5fc9c5a-7cdc-4b22-9688-2827f5f9e5bb', choices=[Choice(delta=ChoiceDelta(content='æ¿', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,356 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b5fc9c5a-7cdc-4b22-9688-2827f5f9e5bb', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,357 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b5fc9c5a-7cdc-4b22-9688-2827f5f9e5bb', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,357 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ¿'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='aLeB3b7I' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e19fbad1-5a53-4165-b9f9-3fb42921e24c', choices=[Choice(delta=ChoiceDelta(content='åŠå…¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,398 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e19fbad1-5a53-4165-b9f9-3fb42921e24c', choices=[Choice(delta=ChoiceDelta(content='åŠå…¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åŠå…¶', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,400 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åŠå…¶', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e19fbad1-5a53-4165-b9f9-3fb42921e24c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åŠå…¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,400 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e19fbad1-5a53-4165-b9f9-3fb42921e24c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åŠå…¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,401 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='åŠå…¶'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='WzFqpJUK' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e8ce97fa-af0e-4e25-979d-22186833140c', choices=[Choice(delta=ChoiceDelta(content='è¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,402 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e8ce97fa-af0e-4e25-979d-22186833140c', choices=[Choice(delta=ChoiceDelta(content='è¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,403 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e8ce97fa-af0e-4e25-979d-22186833140c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,403 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e8ce97fa-af0e-4e25-979d-22186833140c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,404 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='tiMuTXe1' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7c3cfad1-aaa1-4e2b-a845-44f8fa65fc57', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,446 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7c3cfad1-aaa1-4e2b-a845-44f8fa65fc57', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,447 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7c3cfad1-aaa1-4e2b-a845-44f8fa65fc57', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,448 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7c3cfad1-aaa1-4e2b-a845-44f8fa65fc57', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,449 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç”Ÿç‰©'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='RL3dIqlD' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-efcb8085-0097-4b52-b764-ebc10c94d139', choices=[Choice(delta=ChoiceDelta(content='ç ”ç©¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,449 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-efcb8085-0097-4b52-b764-ebc10c94d139', choices=[Choice(delta=ChoiceDelta(content='ç ”ç©¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,451 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-efcb8085-0097-4b52-b764-ebc10c94d139', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,451 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-efcb8085-0097-4b52-b764-ebc10c94d139', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,452 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç ”ç©¶'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='hqdEfPsQ' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8a808776-8da4-4e15-8272-9f0678f2f2c0', choices=[Choice(delta=ChoiceDelta(content='èƒŒæ™¯', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,491 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8a808776-8da4-4e15-8272-9f0678f2f2c0', choices=[Choice(delta=ChoiceDelta(content='èƒŒæ™¯', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='èƒŒæ™¯', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,493 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='èƒŒæ™¯', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8a808776-8da4-4e15-8272-9f0678f2f2c0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='èƒŒæ™¯', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,494 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8a808776-8da4-4e15-8272-9f0678f2f2c0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='èƒŒæ™¯', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,495 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='èƒŒæ™¯'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='RZVxHN40' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9d45be58-8f51-4560-8d84-2374bf7a68b7', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,496 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9d45be58-8f51-4560-8d84-2374bf7a68b7', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,497 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9d45be58-8f51-4560-8d84-2374bf7a68b7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,498 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9d45be58-8f51-4560-8d84-2374bf7a68b7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,498 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='QoUICnMh' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8f07ad7c-9ec0-464c-93c0-8ff56b2682b9', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,499 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8f07ad7c-9ec0-464c-93c0-8ff56b2682b9', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,500 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8f07ad7c-9ec0-464c-93c0-8ff56b2682b9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,500 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8f07ad7c-9ec0-464c-93c0-8ff56b2682b9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,500 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='VoFcdlNQ' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-baa9b8e2-056c-4f5f-9e53-092b82239054', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,538 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-baa9b8e2-056c-4f5f-9e53-092b82239054', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,540 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-baa9b8e2-056c-4f5f-9e53-092b82239054', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,540 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-baa9b8e2-056c-4f5f-9e53-092b82239054', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,541 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='roBN2E8Q' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e6ca333d-e1d1-45db-8b35-35274684fccd', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,542 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e6ca333d-e1d1-45db-8b35-35274684fccd', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,543 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e6ca333d-e1d1-45db-8b35-35274684fccd', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,543 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e6ca333d-e1d1-45db-8b35-35274684fccd', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,544 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='1'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='j7gDyGmY' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-603e4d3f-3bb1-4fbd-9441-6d3971931a95', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,587 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-603e4d3f-3bb1-4fbd-9441-6d3971931a95', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,588 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-603e4d3f-3bb1-4fbd-9441-6d3971931a95', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,588 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-603e4d3f-3bb1-4fbd-9441-6d3971931a95', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,589 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='027btZHL' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1410a6f6-4b5b-4f4c-8e4c-bee07df1e2ff', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,591 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1410a6f6-4b5b-4f4c-8e4c-bee07df1e2ff', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,592 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1410a6f6-4b5b-4f4c-8e4c-bee07df1e2ff', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,592 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1410a6f6-4b5b-4f4c-8e4c-bee07df1e2ff', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,593 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='3'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='zYMnsX4n' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-202fff38-6d2a-4506-9be1-f6fc25266236', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,633 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-202fff38-6d2a-4506-9be1-f6fc25266236', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,634 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-202fff38-6d2a-4506-9be1-f6fc25266236', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,634 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-202fff38-6d2a-4506-9be1-f6fc25266236', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,636 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='9AmSPnk8' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-179d05ad-5dca-417e-94aa-be1ea02f6e37', choices=[Choice(delta=ChoiceDelta(content='æœ¬', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,636 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-179d05ad-5dca-417e-94aa-be1ea02f6e37', choices=[Choice(delta=ChoiceDelta(content='æœ¬', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æœ¬', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,637 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æœ¬', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-179d05ad-5dca-417e-94aa-be1ea02f6e37', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æœ¬', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,637 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-179d05ad-5dca-417e-94aa-be1ea02f6e37', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æœ¬', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,638 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æœ¬'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='4UouqKHc' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-691340dc-463f-4341-8e60-9206847ecc4a', choices=[Choice(delta=ChoiceDelta(content='ç»¼', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,677 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-691340dc-463f-4341-8e60-9206847ecc4a', choices=[Choice(delta=ChoiceDelta(content='ç»¼', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç»¼', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,679 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç»¼', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-691340dc-463f-4341-8e60-9206847ecc4a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç»¼', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,679 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-691340dc-463f-4341-8e60-9206847ecc4a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç»¼', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,680 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç»¼'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='WK9K7osQ' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-dd3a1126-4dcf-4b72-adca-075b5d722c8d', choices=[Choice(delta=ChoiceDelta(content='è¿°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,682 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-dd3a1126-4dcf-4b72-adca-075b5d722c8d', choices=[Choice(delta=ChoiceDelta(content='è¿°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¿°', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,682 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¿°', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-dd3a1126-4dcf-4b72-adca-075b5d722c8d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¿°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,683 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-dd3a1126-4dcf-4b72-adca-075b5d722c8d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¿°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,685 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¿°'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='aLJZE3ZU' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e0ee4c53-6c94-40a7-a447-1e9d73008ed6', choices=[Choice(delta=ChoiceDelta(content='çš„ç ”ç©¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,726 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e0ee4c53-6c94-40a7-a447-1e9d73008ed6', choices=[Choice(delta=ChoiceDelta(content='çš„ç ”ç©¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='çš„ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,727 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='çš„ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e0ee4c53-6c94-40a7-a447-1e9d73008ed6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='çš„ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,728 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e0ee4c53-6c94-40a7-a447-1e9d73008ed6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='çš„ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,729 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='çš„ç ”ç©¶'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='IbLAUwJ6' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-97d56b6f-1722-4584-a5e4-37cc2fcc3ef0', choices=[Choice(delta=ChoiceDelta(content='ç›®æ ‡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,730 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-97d56b6f-1722-4584-a5e4-37cc2fcc3ef0', choices=[Choice(delta=ChoiceDelta(content='ç›®æ ‡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç›®æ ‡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,731 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç›®æ ‡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-97d56b6f-1722-4584-a5e4-37cc2fcc3ef0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç›®æ ‡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,731 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-97d56b6f-1722-4584-a5e4-37cc2fcc3ef0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç›®æ ‡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,733 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç›®æ ‡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='3kEcsZQa' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-47148152-5557-4649-9e41-292125c5caab', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,733 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-47148152-5557-4649-9e41-292125c5caab', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,734 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-47148152-5557-4649-9e41-292125c5caab', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,734 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-47148152-5557-4649-9e41-292125c5caab', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,735 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='EvxM6hEb' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3a9c8e7d-dce5-47e3-9ac2-56a13e07a774', choices=[Choice(delta=ChoiceDelta(content='æ„ä¹‰', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,772 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3a9c8e7d-dce5-47e3-9ac2-56a13e07a774', choices=[Choice(delta=ChoiceDelta(content='æ„ä¹‰', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ„ä¹‰', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,774 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ„ä¹‰', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3a9c8e7d-dce5-47e3-9ac2-56a13e07a774', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ„ä¹‰', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,774 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3a9c8e7d-dce5-47e3-9ac2-56a13e07a774', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ„ä¹‰', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,775 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ„ä¹‰'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='ls8sGM4k' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1f5038c9-07d8-4c61-909b-d71c4514625c', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,776 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1f5038c9-07d8-4c61-909b-d71c4514625c', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,777 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1f5038c9-07d8-4c61-909b-d71c4514625c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,777 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1f5038c9-07d8-4c61-909b-d71c4514625c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,778 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""

"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='up41xhlN' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8b58fbe3-2e32-4414-b2ba-fae40d53b90c', choices=[Choice(delta=ChoiceDelta(content='##', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,819 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8b58fbe3-2e32-4414-b2ba-fae40d53b90c', choices=[Choice(delta=ChoiceDelta(content='##', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,820 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8b58fbe3-2e32-4414-b2ba-fae40d53b90c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,821 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8b58fbe3-2e32-4414-b2ba-fae40d53b90c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,822 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='##'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='EIf7XNVG' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0796f587-7897-4e16-89b2-5caac6966922', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,823 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0796f587-7897-4e16-89b2-5caac6966922', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450948, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,824 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0796f587-7897-4e16-89b2-5caac6966922', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,824 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0796f587-7897-4e16-89b2-5caac6966922', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,824 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='mT8HGJVC' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-13627c96-5a8e-43d9-a621-9fa3917b1425', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,868 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-13627c96-5a8e-43d9-a621-9fa3917b1425', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,869 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-13627c96-5a8e-43d9-a621-9fa3917b1425', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,870 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-13627c96-5a8e-43d9-a621-9fa3917b1425', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,871 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='2'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='V2T91o0F' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8be11dab-fc8a-45a2-9d53-631eaa95c0fa', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,872 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8be11dab-fc8a-45a2-9d53-631eaa95c0fa', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,874 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8be11dab-fc8a-45a2-9d53-631eaa95c0fa', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,874 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8be11dab-fc8a-45a2-9d53-631eaa95c0fa', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,874 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='HxwDA9fI' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a4a05c28-8c09-48d6-9984-67bf375b5b2f', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,912 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a4a05c28-8c09-48d6-9984-67bf375b5b2f', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,914 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a4a05c28-8c09-48d6-9984-67bf375b5b2f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,914 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a4a05c28-8c09-48d6-9984-67bf375b5b2f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-bfd1c8fb-5c4e-4ed7-8847-0e6e8111fdcb', choices=[Choice(delta=ChoiceDelta(content=' è¡€', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,914 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-bfd1c8fb-5c4e-4ed7-8847-0e6e8111fdcb', choices=[Choice(delta=ChoiceDelta(content=' è¡€', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' è¡€', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,916 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' è¡€', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-bfd1c8fb-5c4e-4ed7-8847-0e6e8111fdcb', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' è¡€', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,917 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-bfd1c8fb-5c4e-4ed7-8847-0e6e8111fdcb', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' è¡€', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,917 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' è¡€'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='nzIt0noJ' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c7837b26-4fd3-427f-968d-6012b78f69a9', choices=[Choice(delta=ChoiceDelta(content='å°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,918 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c7837b26-4fd3-427f-968d-6012b78f69a9', choices=[Choice(delta=ChoiceDelta(content='å°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,919 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c7837b26-4fd3-427f-968d-6012b78f69a9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,920 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c7837b26-4fd3-427f-968d-6012b78f69a9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,920 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å°'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='5wUb2z1N' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-453a72f7-387e-4d7f-bc94-dc84b9f54775', choices=[Choice(delta=ChoiceDelta(content='æ¿', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,960 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-453a72f7-387e-4d7f-bc94-dc84b9f54775', choices=[Choice(delta=ChoiceDelta(content='æ¿', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,962 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-453a72f7-387e-4d7f-bc94-dc84b9f54775', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,962 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-453a72f7-387e-4d7f-bc94-dc84b9f54775', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,963 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ¿'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='nJPexnZG' timestamp=1763450949.457893
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a1b62086-80b2-4a00-8dc1-9aa895e58804', choices=[Choice(delta=ChoiceDelta(content='åŠå…¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:13,964 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a1b62086-80b2-4a00-8dc1-9aa895e58804', choices=[Choice(delta=ChoiceDelta(content='åŠå…¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åŠå…¶', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:13,965 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åŠå…¶', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:13 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a1b62086-80b2-4a00-8dc1-9aa895e58804', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åŠå…¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,965 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a1b62086-80b2-4a00-8dc1-9aa895e58804', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åŠå…¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:13,966 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='åŠå…¶'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='AkNGJovG' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0c345ddb-e8b6-4a7f-8bab-23e113e82591', choices=[Choice(delta=ChoiceDelta(content='è¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,008 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0c345ddb-e8b6-4a7f-8bab-23e113e82591', choices=[Choice(delta=ChoiceDelta(content='è¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,009 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0c345ddb-e8b6-4a7f-8bab-23e113e82591', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,009 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0c345ddb-e8b6-4a7f-8bab-23e113e82591', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,011 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='PazoqdFh' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-27e9a8ac-0e93-4e11-ab3b-9bbca74803d9', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,012 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-27e9a8ac-0e93-4e11-ab3b-9bbca74803d9', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,013 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-27e9a8ac-0e93-4e11-ab3b-9bbca74803d9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,013 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-27e9a8ac-0e93-4e11-ab3b-9bbca74803d9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,014 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç”Ÿç‰©'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='dBXGmKBM' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-734f1bf1-3973-4982-bb4b-bf85b98bb37c', choices=[Choice(delta=ChoiceDelta(content='çš„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,054 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-734f1bf1-3973-4982-bb4b-bf85b98bb37c', choices=[Choice(delta=ChoiceDelta(content='çš„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,055 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-734f1bf1-3973-4982-bb4b-bf85b98bb37c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,055 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-734f1bf1-3973-4982-bb4b-bf85b98bb37c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,056 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='çš„'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='iwaH9AF7' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9e83d239-458c-42b7-9a53-f69418ef6526', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©å­¦', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,057 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9e83d239-458c-42b7-9a53-f69418ef6526', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©å­¦', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©å­¦', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,059 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©å­¦', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9e83d239-458c-42b7-9a53-f69418ef6526', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©å­¦', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,059 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9e83d239-458c-42b7-9a53-f69418ef6526', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©å­¦', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,060 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç”Ÿç‰©å­¦'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='c6kjulnl' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1b0202c2-78f7-42de-9705-1bf7b926e534', choices=[Choice(delta=ChoiceDelta(content='ç‰¹æ€§', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,100 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1b0202c2-78f7-42de-9705-1bf7b926e534', choices=[Choice(delta=ChoiceDelta(content='ç‰¹æ€§', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç‰¹æ€§', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,102 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç‰¹æ€§', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1b0202c2-78f7-42de-9705-1bf7b926e534', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç‰¹æ€§', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,102 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1b0202c2-78f7-42de-9705-1bf7b926e534', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç‰¹æ€§', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,103 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç‰¹æ€§'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='qaRLpVJx' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3c8d08ce-195e-4939-9d2a-ad456be1a5b1', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,104 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3c8d08ce-195e-4939-9d2a-ad456be1a5b1', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,105 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3c8d08ce-195e-4939-9d2a-ad456be1a5b1', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,105 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3c8d08ce-195e-4939-9d2a-ad456be1a5b1', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,105 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='Lbss3acE' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d0a98efe-feaa-489a-9721-cb762d166567', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,106 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d0a98efe-feaa-489a-9721-cb762d166567', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,107 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d0a98efe-feaa-489a-9721-cb762d166567', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,107 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d0a98efe-feaa-489a-9721-cb762d166567', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,108 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='5KB8L0Ma' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-88e791b7-1379-4d02-bb2e-4d88d6bf090a', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,148 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-88e791b7-1379-4d02-bb2e-4d88d6bf090a', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,148 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-88e791b7-1379-4d02-bb2e-4d88d6bf090a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,148 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-88e791b7-1379-4d02-bb2e-4d88d6bf090a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,149 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='PuHi2QaL' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e5463ff6-b0b9-498a-bfb8-dd759a7d3a0e', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,151 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e5463ff6-b0b9-498a-bfb8-dd759a7d3a0e', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,151 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e5463ff6-b0b9-498a-bfb8-dd759a7d3a0e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,151 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e5463ff6-b0b9-498a-bfb8-dd759a7d3a0e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,153 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='2'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='HJpVgke7' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4476e048-a98e-48c9-b589-0ab4a098e710', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,195 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4476e048-a98e-48c9-b589-0ab4a098e710', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,196 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4476e048-a98e-48c9-b589-0ab4a098e710', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,196 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4476e048-a98e-48c9-b589-0ab4a098e710', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,197 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='Tf00RkVj' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-78b45f8e-0f3e-43f7-a1bc-2a15244e1140', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,198 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-78b45f8e-0f3e-43f7-a1bc-2a15244e1140', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,199 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-78b45f8e-0f3e-43f7-a1bc-2a15244e1140', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,199 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-78b45f8e-0f3e-43f7-a1bc-2a15244e1140', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,200 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='1'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='0RlZ1US3' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-235fabe5-49a1-4879-ab36-1781a84baad5', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,240 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-235fabe5-49a1-4879-ab36-1781a84baad5', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,241 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-235fabe5-49a1-4879-ab36-1781a84baad5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,242 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-235fabe5-49a1-4879-ab36-1781a84baad5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a6c7da47-85f1-4d72-ae3e-9fdf0c686c76', choices=[Choice(delta=ChoiceDelta(content=' è¡€', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,242 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a6c7da47-85f1-4d72-ae3e-9fdf0c686c76', choices=[Choice(delta=ChoiceDelta(content=' è¡€', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' è¡€', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,243 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' è¡€', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a6c7da47-85f1-4d72-ae3e-9fdf0c686c76', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' è¡€', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,244 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a6c7da47-85f1-4d72-ae3e-9fdf0c686c76', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' è¡€', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,245 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' è¡€'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='vm1bREDl' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-296a3e9e-84e4-4459-a490-3ea25f412c83', choices=[Choice(delta=ChoiceDelta(content='å°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,287 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-296a3e9e-84e4-4459-a490-3ea25f412c83', choices=[Choice(delta=ChoiceDelta(content='å°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,288 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-296a3e9e-84e4-4459-a490-3ea25f412c83', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,289 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-296a3e9e-84e4-4459-a490-3ea25f412c83', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,290 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å°'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='HrQVBCep' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6026bb56-cfbe-4691-82a9-10714d6c901d', choices=[Choice(delta=ChoiceDelta(content='æ¿', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,290 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6026bb56-cfbe-4691-82a9-10714d6c901d', choices=[Choice(delta=ChoiceDelta(content='æ¿', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,292 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6026bb56-cfbe-4691-82a9-10714d6c901d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,292 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6026bb56-cfbe-4691-82a9-10714d6c901d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,293 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ¿'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='DyPiKzKK' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8fa80a1b-7772-4c25-83ee-f6a2e7072496', choices=[Choice(delta=ChoiceDelta(content='åŠŸèƒ½', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,334 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8fa80a1b-7772-4c25-83ee-f6a2e7072496', choices=[Choice(delta=ChoiceDelta(content='åŠŸèƒ½', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åŠŸèƒ½', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,335 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åŠŸèƒ½', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8fa80a1b-7772-4c25-83ee-f6a2e7072496', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åŠŸèƒ½', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,335 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8fa80a1b-7772-4c25-83ee-f6a2e7072496', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åŠŸèƒ½', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,335 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='åŠŸèƒ½'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='O23uaRV5' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a905f41b-a9de-4a41-a5cc-83c45690368f', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,336 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a905f41b-a9de-4a41-a5cc-83c45690368f', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,337 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a905f41b-a9de-4a41-a5cc-83c45690368f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,337 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a905f41b-a9de-4a41-a5cc-83c45690368f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,338 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='kmYPCaBa' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0ffd7693-2d54-41da-9c9a-bdb06f6178e1', choices=[Choice(delta=ChoiceDelta(content='åœ¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,339 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0ffd7693-2d54-41da-9c9a-bdb06f6178e1', choices=[Choice(delta=ChoiceDelta(content='åœ¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åœ¨', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,339 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åœ¨', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0ffd7693-2d54-41da-9c9a-bdb06f6178e1', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åœ¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,340 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0ffd7693-2d54-41da-9c9a-bdb06f6178e1', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åœ¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,340 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='åœ¨'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='QSZo1V3v' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f4c4eb2b-7c68-4743-b098-1eb5ea1dbac6', choices=[Choice(delta=ChoiceDelta(content='ä¼¤å£', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,379 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f4c4eb2b-7c68-4743-b098-1eb5ea1dbac6', choices=[Choice(delta=ChoiceDelta(content='ä¼¤å£', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¼¤å£', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,381 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¼¤å£', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f4c4eb2b-7c68-4743-b098-1eb5ea1dbac6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¼¤å£', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,381 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f4c4eb2b-7c68-4743-b098-1eb5ea1dbac6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¼¤å£', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,382 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¼¤å£'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='rvZAXEIv' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-80038fc5-98ba-4aa7-bc47-ee3c34f57f63', choices=[Choice(delta=ChoiceDelta(content='ä¿®å¤', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,383 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-80038fc5-98ba-4aa7-bc47-ee3c34f57f63', choices=[Choice(delta=ChoiceDelta(content='ä¿®å¤', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¿®å¤', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,384 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¿®å¤', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-80038fc5-98ba-4aa7-bc47-ee3c34f57f63', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¿®å¤', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,384 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-80038fc5-98ba-4aa7-bc47-ee3c34f57f63', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¿®å¤', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,386 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¿®å¤'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='HMRKLsMA' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-baf428b8-29f9-4a4a-af7f-a8c0e361b8ca', choices=[Choice(delta=ChoiceDelta(content='ä¸­çš„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,427 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-baf428b8-29f9-4a4a-af7f-a8c0e361b8ca', choices=[Choice(delta=ChoiceDelta(content='ä¸­çš„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸­çš„', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,428 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸­çš„', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-baf428b8-29f9-4a4a-af7f-a8c0e361b8ca', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸­çš„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,429 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-baf428b8-29f9-4a4a-af7f-a8c0e361b8ca', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸­çš„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,430 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸­çš„'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='H9yQwz09' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-70420e50-de6d-4c57-9c71-f1812c480e2f', choices=[Choice(delta=ChoiceDelta(content='ä½œç”¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,430 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-70420e50-de6d-4c57-9c71-f1812c480e2f', choices=[Choice(delta=ChoiceDelta(content='ä½œç”¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,431 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-70420e50-de6d-4c57-9c71-f1812c480e2f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,432 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-70420e50-de6d-4c57-9c71-f1812c480e2f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ï¼›'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ï¼›
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç”Ÿç‰©'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç”Ÿç‰©
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ï¼›'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ï¼›
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç³–å°¿ç—…'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç³–å°¿ç—…
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¶³'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¶³
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æºƒç–¡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æºƒç–¡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ï¼›'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ï¼›
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä½œç”¨'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä½œç”¨
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æœºåˆ¶'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æœºåˆ¶
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ï¼›'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ï¼›
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ²»ç–—'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ²»ç–—
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""

"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 


è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='##'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ##
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='1'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 1
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' å¼•'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  å¼•
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¨€'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¨€
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='1'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 1
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='1'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 1
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' ç³–'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  ç³–
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å°¿'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å°¿
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç—…'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç—…
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¶³'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¶³
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æºƒç–¡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æºƒç–¡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç°çŠ¶'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç°çŠ¶
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ²»ç–—'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ²»ç–—
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æŒ‘æˆ˜'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æŒ‘æˆ˜
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='1'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 1
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='2'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 2
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' è¡€'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  è¡€
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å°'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å°
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ¿'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ¿
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='åŠå…¶'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: åŠå…¶
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç”Ÿç‰©'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç”Ÿç‰©
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç ”ç©¶'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç ”ç©¶
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='èƒŒæ™¯'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: èƒŒæ™¯
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='1'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 1
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='3'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 3
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æœ¬'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æœ¬
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç»¼'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç»¼
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¿°'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¿°
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='çš„ç ”ç©¶'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: çš„ç ”ç©¶
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç›®æ ‡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç›®æ ‡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ„ä¹‰'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ„ä¹‰
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""

"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 


è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='##'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ##
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='2'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 2
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' è¡€'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  è¡€
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å°'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å°
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ¿'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ¿
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='åŠå…¶'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: åŠå…¶
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç”Ÿç‰©'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç”Ÿç‰©
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='çš„'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: çš„
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç”Ÿç‰©å­¦'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç”Ÿç‰©å­¦
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç‰¹æ€§'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç‰¹æ€§
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='2'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 2
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='1'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 1
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' è¡€'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  è¡€
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å°'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å°
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ¿'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ¿
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='åŠŸèƒ½'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: åŠŸèƒ½
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='åœ¨'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: åœ¨
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¼¤å£'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¼¤å£
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¿®å¤'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¿®å¤
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸­çš„'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸­çš„
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä½œç”¨'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä½œç”¨2025-11-18 15:29:14,433 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä½œç”¨'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='mQJR5P0I' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e68be80a-50e2-4cd0-af4b-b784189d7ff7', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,474 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e68be80a-50e2-4cd0-af4b-b784189d7ff7', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,476 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e68be80a-50e2-4cd0-af4b-b784189d7ff7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,476 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e68be80a-50e2-4cd0-af4b-b784189d7ff7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,478 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='UZ3Rycha' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c1fcbca9-3de0-425c-88bf-30ef33d24482', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,478 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c1fcbca9-3de0-425c-88bf-30ef33d24482', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,479 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c1fcbca9-3de0-425c-88bf-30ef33d24482', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,479 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c1fcbca9-3de0-425c-88bf-30ef33d24482', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,480 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='QG0ywnfA' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-76b7f50d-4a6e-47a1-96d2-1b2f3085dfb2', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,520 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-76b7f50d-4a6e-47a1-96d2-1b2f3085dfb2', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,521 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-76b7f50d-4a6e-47a1-96d2-1b2f3085dfb2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,521 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-76b7f50d-4a6e-47a1-96d2-1b2f3085dfb2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,522 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='gXxdbyqy' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-581f2dec-a409-436c-8348-29afbbd5db49', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,523 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-581f2dec-a409-436c-8348-29afbbd5db49', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,525 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-581f2dec-a409-436c-8348-29afbbd5db49', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,525 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-581f2dec-a409-436c-8348-29afbbd5db49', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,525 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='2'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='WZ8V6DRD' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e8876fdc-35c0-49ab-9904-b5c8313fb6ae', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,526 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e8876fdc-35c0-49ab-9904-b5c8313fb6ae', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,527 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e8876fdc-35c0-49ab-9904-b5c8313fb6ae', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,527 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e8876fdc-35c0-49ab-9904-b5c8313fb6ae', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,528 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='0SWnKlm1' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-962b5d95-8cf1-4837-a205-db997112e1da', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,566 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-962b5d95-8cf1-4837-a205-db997112e1da', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,568 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-962b5d95-8cf1-4837-a205-db997112e1da', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,568 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-962b5d95-8cf1-4837-a205-db997112e1da', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,569 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='2'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='28j6Edt6' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ce5ac26c-d274-492f-9d43-1a4e7408f02e', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,570 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ce5ac26c-d274-492f-9d43-1a4e7408f02e', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,571 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ce5ac26c-d274-492f-9d43-1a4e7408f02e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,571 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ce5ac26c-d274-492f-9d43-1a4e7408f02e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-96e33ade-3a73-46ce-87e2-d101700e9e44', choices=[Choice(delta=ChoiceDelta(content=' è¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,614 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-96e33ade-3a73-46ce-87e2-d101700e9e44', choices=[Choice(delta=ChoiceDelta(content=' è¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' è¡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,616 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' è¡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-96e33ade-3a73-46ce-87e2-d101700e9e44', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' è¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,617 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-96e33ade-3a73-46ce-87e2-d101700e9e44', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' è¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,617 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' è¡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='y71GxM0O' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-70b2c9ef-ec29-4a9d-861f-3e1e82d9f405', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,619 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-70b2c9ef-ec29-4a9d-861f-3e1e82d9f405', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,620 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-70b2c9ef-ec29-4a9d-861f-3e1e82d9f405', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,620 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-70b2c9ef-ec29-4a9d-861f-3e1e82d9f405', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,621 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç”Ÿç‰©'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='2BEnWi3C' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a811fa55-e1e8-4134-aad0-53ae8f8fe4d9', choices=[Choice(delta=ChoiceDelta(content='ç±»å‹', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,662 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a811fa55-e1e8-4134-aad0-53ae8f8fe4d9', choices=[Choice(delta=ChoiceDelta(content='ç±»å‹', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç±»å‹', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,664 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç±»å‹', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a811fa55-e1e8-4134-aad0-53ae8f8fe4d9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç±»å‹', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,664 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a811fa55-e1e8-4134-aad0-53ae8f8fe4d9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç±»å‹', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,665 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç±»å‹'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='CDg9H8ab' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d0b4b7b8-e75f-4bf7-9a32-6506bcdf1c48', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,665 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d0b4b7b8-e75f-4bf7-9a32-6506bcdf1c48', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,666 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d0b4b7b8-e75f-4bf7-9a32-6506bcdf1c48', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,666 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d0b4b7b8-e75f-4bf7-9a32-6506bcdf1c48', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,667 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='wcjpUtbN' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-752ed387-e2df-40bc-b606-550c18121b09', choices=[Choice(delta=ChoiceDelta(content='åˆ¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,708 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-752ed387-e2df-40bc-b606-550c18121b09', choices=[Choice(delta=ChoiceDelta(content='åˆ¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åˆ¶', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,710 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åˆ¶', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-752ed387-e2df-40bc-b606-550c18121b09', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åˆ¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,711 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-752ed387-e2df-40bc-b606-550c18121b09', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åˆ¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,712 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='åˆ¶'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='l5l2wUkL' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-28862a18-c013-4047-982a-3764e1ee13bf', choices=[Choice(delta=ChoiceDelta(content='å¤‡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,713 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-28862a18-c013-4047-982a-3764e1ee13bf', choices=[Choice(delta=ChoiceDelta(content='å¤‡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å¤‡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,714 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å¤‡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-28862a18-c013-4047-982a-3764e1ee13bf', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å¤‡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,715 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-28862a18-c013-4047-982a-3764e1ee13bf', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å¤‡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,716 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å¤‡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='giPtlB01' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-60abe752-2a1d-4c02-9b5f-45bdd2feece5', choices=[Choice(delta=ChoiceDelta(content='æ–¹æ³•', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,756 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-60abe752-2a1d-4c02-9b5f-45bdd2feece5', choices=[Choice(delta=ChoiceDelta(content='æ–¹æ³•', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ–¹æ³•', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,757 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ–¹æ³•', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-60abe752-2a1d-4c02-9b5f-45bdd2feece5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ–¹æ³•', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,757 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-60abe752-2a1d-4c02-9b5f-45bdd2feece5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ–¹æ³•', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,758 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ–¹æ³•'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='XkY9O2EF' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f57b82d6-13aa-419b-aef7-5cabe68325ea', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,759 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f57b82d6-13aa-419b-aef7-5cabe68325ea', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,761 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f57b82d6-13aa-419b-aef7-5cabe68325ea', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,761 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f57b82d6-13aa-419b-aef7-5cabe68325ea', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,762 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='dfvryWuE' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d8d114a1-d511-4852-821f-4ee7a7b6a264', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,762 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d8d114a1-d511-4852-821f-4ee7a7b6a264', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,765 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d8d114a1-d511-4852-821f-4ee7a7b6a264', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,765 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d8d114a1-d511-4852-821f-4ee7a7b6a264', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,767 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='MxkiUJzL' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-02944f65-239e-46f5-b346-91af9745fbca', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,802 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-02944f65-239e-46f5-b346-91af9745fbca', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,804 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-02944f65-239e-46f5-b346-91af9745fbca', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,804 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-02944f65-239e-46f5-b346-91af9745fbca', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,805 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='RrFbNSmo' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1ed6b17f-63ca-4dbd-96dd-d367f4891cc2', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,805 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1ed6b17f-63ca-4dbd-96dd-d367f4891cc2', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,807 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1ed6b17f-63ca-4dbd-96dd-d367f4891cc2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,807 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1ed6b17f-63ca-4dbd-96dd-d367f4891cc2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,808 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='2'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='Uk7pIK22' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e60f1414-c710-4566-be86-c449af23a0ab', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,850 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e60f1414-c710-4566-be86-c449af23a0ab', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450949, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,851 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e60f1414-c710-4566-be86-c449af23a0ab', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,851 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e60f1414-c710-4566-be86-c449af23a0ab', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,852 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='3KZZwcmC' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-60576ead-9ec2-471f-8659-7c69a8459f0a', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,852 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-60576ead-9ec2-471f-8659-7c69a8459f0a', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,855 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-60576ead-9ec2-471f-8659-7c69a8459f0a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,855 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-60576ead-9ec2-471f-8659-7c69a8459f0a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,855 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='3'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='RJ0IN3Rh' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8005847b-2efe-4f16-9d12-9028cbc1b838', choices=[Choice(delta=ChoiceDelta(content=' ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,897 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8005847b-2efe-4f16-9d12-9028cbc1b838', choices=[Choice(delta=ChoiceDelta(content=' ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,899 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8005847b-2efe-4f16-9d12-9028cbc1b838', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,899 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8005847b-2efe-4f16-9d12-9028cbc1b838', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,900 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='ALs1O94f' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-32facaa9-9a67-4ce9-af3e-2a219a7a04c9', choices=[Choice(delta=ChoiceDelta(content='åŒ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,901 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-32facaa9-9a67-4ce9-af3e-2a219a7a04c9', choices=[Choice(delta=ChoiceDelta(content='åŒ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åŒ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,903 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åŒ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-32facaa9-9a67-4ce9-af3e-2a219a7a04c9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åŒ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,904 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-32facaa9-9a67-4ce9-af3e-2a219a7a04c9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åŒ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,908 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='åŒ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='D2reAvxk' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6bbb8563-80bd-47c1-b7ba-104d1e428c98', choices=[Choice(delta=ChoiceDelta(content='è¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,909 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6bbb8563-80bd-47c1-b7ba-104d1e428c98', choices=[Choice(delta=ChoiceDelta(content='è¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,910 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6bbb8563-80bd-47c1-b7ba-104d1e428c98', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,910 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6bbb8563-80bd-47c1-b7ba-104d1e428c98', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,911 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='B8eneOjx' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-01be83e2-534c-4021-8ef9-2baa8fc69d14', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,943 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-01be83e2-534c-4021-8ef9-2baa8fc69d14', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,945 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-01be83e2-534c-4021-8ef9-2baa8fc69d14', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,945 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-01be83e2-534c-4021-8ef9-2baa8fc69d14', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,946 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç”Ÿç‰©'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='3haRqQDc' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4294f2b0-610d-4d0f-8b20-f389cb2fa19c', choices=[Choice(delta=ChoiceDelta(content='çš„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,946 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4294f2b0-610d-4d0f-8b20-f389cb2fa19c', choices=[Choice(delta=ChoiceDelta(content='çš„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,948 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4294f2b0-610d-4d0f-8b20-f389cb2fa19c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,948 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4294f2b0-610d-4d0f-8b20-f389cb2fa19c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,949 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='çš„'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='OB4sro22' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-91fc9fff-8caf-403a-a0ad-f8bacf45d626', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,989 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-91fc9fff-8caf-403a-a0ad-f8bacf45d626', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,991 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-91fc9fff-8caf-403a-a0ad-f8bacf45d626', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,991 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-91fc9fff-8caf-403a-a0ad-f8bacf45d626', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,992 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç”Ÿç‰©'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='YxExRYAK' timestamp=1763450949.457893
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-2025bf2b-5b30-4f73-9d22-6df85950d400', choices=[Choice(delta=ChoiceDelta(content='æ´»æ€§', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:14,993 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-2025bf2b-5b30-4f73-9d22-6df85950d400', choices=[Choice(delta=ChoiceDelta(content='æ´»æ€§', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ´»æ€§', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:14,994 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ´»æ€§', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:14 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-2025bf2b-5b30-4f73-9d22-6df85950d400', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ´»æ€§', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,994 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-2025bf2b-5b30-4f73-9d22-6df85950d400', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ´»æ€§', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:14,996 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ´»æ€§'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='SPfYdGI5' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-04bc38fe-70e9-4aa7-9d38-87984dd93f1a', choices=[Choice(delta=ChoiceDelta(content='æ¯”è¾ƒ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,034 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-04bc38fe-70e9-4aa7-9d38-87984dd93f1a', choices=[Choice(delta=ChoiceDelta(content='æ¯”è¾ƒ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ¯”è¾ƒ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,037 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ¯”è¾ƒ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-04bc38fe-70e9-4aa7-9d38-87984dd93f1a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ¯”è¾ƒ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,037 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-04bc38fe-70e9-4aa7-9d38-87984dd93f1a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ¯”è¾ƒ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,038 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ¯”è¾ƒ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='6PRIHeEt' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d174f0d1-1981-4706-a049-69daea168f68', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,038 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d174f0d1-1981-4706-a049-69daea168f68', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,040 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d174f0d1-1981-4706-a049-69daea168f68', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,040 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d174f0d1-1981-4706-a049-69daea168f68', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,041 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""

"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='slZVDr6Y' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7e691f4b-c981-4b77-bd95-05213dd716e8', choices=[Choice(delta=ChoiceDelta(content='##', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,082 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7e691f4b-c981-4b77-bd95-05213dd716e8', choices=[Choice(delta=ChoiceDelta(content='##', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,084 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7e691f4b-c981-4b77-bd95-05213dd716e8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,084 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7e691f4b-c981-4b77-bd95-05213dd716e8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,084 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='##'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='UXQxDdHw' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0348f9b0-6fb2-493f-b2f4-7816795d28e3', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,086 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0348f9b0-6fb2-493f-b2f4-7816795d28e3', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,087 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0348f9b0-6fb2-493f-b2f4-7816795d28e3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,087 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0348f9b0-6fb2-493f-b2f4-7816795d28e3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,088 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='vecjhIoU' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-af462c2e-1f7b-4061-837e-301cba6289c4', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,130 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-af462c2e-1f7b-4061-837e-301cba6289c4', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,132 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-af462c2e-1f7b-4061-837e-301cba6289c4', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,133 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-af462c2e-1f7b-4061-837e-301cba6289c4', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,134 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='3'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='wbQ2IB8N' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c83d614f-6181-4195-b829-d37680393fcc', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,134 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c83d614f-6181-4195-b829-d37680393fcc', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,136 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c83d614f-6181-4195-b829-d37680393fcc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,136 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c83d614f-6181-4195-b829-d37680393fcc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,136 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='cEvGkyVg' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-47737f2c-f1af-4941-8306-9f07790216b9', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,138 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-47737f2c-f1af-4941-8306-9f07790216b9', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,140 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-47737f2c-f1af-4941-8306-9f07790216b9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,140 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-47737f2c-f1af-4941-8306-9f07790216b9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,141 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='fy7MsUzA' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-2b1162dd-f384-43f1-a3d5-9600e9696037', choices=[Choice(delta=ChoiceDelta(content='ä½œç”¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,175 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-2b1162dd-f384-43f1-a3d5-9600e9696037', choices=[Choice(delta=ChoiceDelta(content='ä½œç”¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,177 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-2b1162dd-f384-43f1-a3d5-9600e9696037', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,178 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-2b1162dd-f384-43f1-a3d5-9600e9696037', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,179 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä½œç”¨'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='j4iI0qVd' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0043aee8-f29c-438a-bb0f-9bea2afb09c1', choices=[Choice(delta=ChoiceDelta(content='æœºåˆ¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,179 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0043aee8-f29c-438a-bb0f-9bea2afb09c1', choices=[Choice(delta=ChoiceDelta(content='æœºåˆ¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æœºåˆ¶', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,180 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æœºåˆ¶', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0043aee8-f29c-438a-bb0f-9bea2afb09c1', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æœºåˆ¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,181 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0043aee8-f29c-438a-bb0f-9bea2afb09c1', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æœºåˆ¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,181 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æœºåˆ¶'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='G4K9Oyb5' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c44116d1-758e-4390-97b6-cf1036231b94', choices=[Choice(delta=ChoiceDelta(content='ç ”ç©¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,222 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c44116d1-758e-4390-97b6-cf1036231b94', choices=[Choice(delta=ChoiceDelta(content='ç ”ç©¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,224 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c44116d1-758e-4390-97b6-cf1036231b94', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,224 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c44116d1-758e-4390-97b6-cf1036231b94', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,226 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç ”ç©¶'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='jzyEOHRY' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-fb0fcb55-b1cf-4f51-8759-2d689eb62680', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,227 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-fb0fcb55-b1cf-4f51-8759-2d689eb62680', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,229 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-fb0fcb55-b1cf-4f51-8759-2d689eb62680', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,229 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-fb0fcb55-b1cf-4f51-8759-2d689eb62680', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,230 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='CAX5VL42' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1a194930-a121-4189-906d-d7ac29b0ff50', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,268 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1a194930-a121-4189-906d-d7ac29b0ff50', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,271 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1a194930-a121-4189-906d-d7ac29b0ff50', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,271 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1a194930-a121-4189-906d-d7ac29b0ff50', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,272 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='v4H7by1O' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-073a0148-9f51-4fc6-9748-3affc27f9833', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,273 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-073a0148-9f51-4fc6-9748-3affc27f9833', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,274 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-073a0148-9f51-4fc6-9748-3affc27f9833', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,274 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-073a0148-9f51-4fc6-9748-3affc27f9833', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,275 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='ohfiSIga' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-32188b22-c6e4-4abe-b3e3-2e480649d53a', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,318 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-32188b22-c6e4-4abe-b3e3-2e480649d53a', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,319 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-32188b22-c6e4-4abe-b3e3-2e480649d53a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,320 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-32188b22-c6e4-4abe-b3e3-2e480649d53a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,321 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='3'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='QPBrMJbs' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ce24f457-ed12-40b1-85d5-720b7a2c0e9b', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,321 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ce24f457-ed12-40b1-85d5-720b7a2c0e9b', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,322 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ce24f457-ed12-40b1-85d5-720b7a2c0e9b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,323 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ce24f457-ed12-40b1-85d5-720b7a2c0e9b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,324 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='NESGwON1' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-68b19c1a-97e5-4895-89eb-7bdd5ed67831', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,324 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-68b19c1a-97e5-4895-89eb-7bdd5ed67831', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,325 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-68b19c1a-97e5-4895-89eb-7bdd5ed67831', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,325 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-68b19c1a-97e5-4895-89eb-7bdd5ed67831', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,326 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='1'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='ntCa6fgq' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4e30060b-7198-427b-bf23-7022b765e44d', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,364 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4e30060b-7198-427b-bf23-7022b765e44d', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,366 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4e30060b-7198-427b-bf23-7022b765e44d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,366 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4e30060b-7198-427b-bf23-7022b765e44d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,367 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='yztqg4Iv' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4a859c50-3a5c-49c4-b0c2-4c4e0549af61', choices=[Choice(delta=ChoiceDelta(content='ä¿ƒè¿›', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,368 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4a859c50-3a5c-49c4-b0c2-4c4e0549af61', choices=[Choice(delta=ChoiceDelta(content='ä¿ƒè¿›', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¿ƒè¿›', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,369 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¿ƒè¿›', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4a859c50-3a5c-49c4-b0c2-4c4e0549af61', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¿ƒè¿›', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,369 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4a859c50-3a5c-49c4-b0c2-4c4e0549af61', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¿ƒè¿›', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,370 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¿ƒè¿›'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='4WMnNvkc' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-74faae80-a97e-4750-a580-acd2c728e9f4', choices=[Choice(delta=ChoiceDelta(content='ç»†èƒ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,408 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-74faae80-a97e-4750-a580-acd2c728e9f4', choices=[Choice(delta=ChoiceDelta(content='ç»†èƒ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç»†èƒ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,409 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç»†èƒ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-74faae80-a97e-4750-a580-acd2c728e9f4', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç»†èƒ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,409 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-74faae80-a97e-4750-a580-acd2c728e9f4', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç»†èƒ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,410 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç»†èƒ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='2wkThJ9i' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6232d26f-1844-4685-9605-363377eda35f', choices=[Choice(delta=ChoiceDelta(content='å¢', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,411 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6232d26f-1844-4685-9605-363377eda35f', choices=[Choice(delta=ChoiceDelta(content='å¢', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å¢', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,412 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å¢', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6232d26f-1844-4685-9605-363377eda35f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å¢', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,412 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6232d26f-1844-4685-9605-363377eda35f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å¢', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,413 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å¢'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='xjudwMla' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3bd1fc66-85f0-483c-95be-3576459562e6', choices=[Choice(delta=ChoiceDelta(content='æ®–', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,454 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3bd1fc66-85f0-483c-95be-3576459562e6', choices=[Choice(delta=ChoiceDelta(content='æ®–', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ®–', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,457 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ®–', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3bd1fc66-85f0-483c-95be-3576459562e6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ®–', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,457 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3bd1fc66-85f0-483c-95be-3576459562e6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ®–', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='2'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 2
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='2'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 2
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' è¡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  è¡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç”Ÿç‰©'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç”Ÿç‰©
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç±»å‹'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç±»å‹
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='åˆ¶'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: åˆ¶
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å¤‡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å¤‡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ–¹æ³•'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ–¹æ³•
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='2'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 2
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='3'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 3
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='åŒ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: åŒ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç”Ÿç‰©'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç”Ÿç‰©
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='çš„'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: çš„
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç”Ÿç‰©'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç”Ÿç‰©
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ´»æ€§'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ´»æ€§
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ¯”è¾ƒ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ¯”è¾ƒ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""

"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 


è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='##'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ##
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='3'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 3
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä½œç”¨'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä½œç”¨
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æœºåˆ¶'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æœºåˆ¶
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç ”ç©¶'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç ”ç©¶
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='3'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 3
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='1'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 1
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¿ƒè¿›'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¿ƒè¿›
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç»†èƒ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç»†èƒ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å¢'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å¢
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ®–'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ®–2025-11-18 15:29:15,458 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ®–'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='pQx0fzt9' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a64dd580-c60d-4a61-b122-e0aaeae275ef', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,459 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a64dd580-c60d-4a61-b122-e0aaeae275ef', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,460 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a64dd580-c60d-4a61-b122-e0aaeae275ef', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,460 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a64dd580-c60d-4a61-b122-e0aaeae275ef', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,461 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='E5RktsJh' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3c0500f6-566d-40b4-9fd3-f6d5191f6858', choices=[Choice(delta=ChoiceDelta(content='è¿ç§»', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,499 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3c0500f6-566d-40b4-9fd3-f6d5191f6858', choices=[Choice(delta=ChoiceDelta(content='è¿ç§»', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¿ç§»', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,500 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¿ç§»', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3c0500f6-566d-40b4-9fd3-f6d5191f6858', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¿ç§»', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,500 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3c0500f6-566d-40b4-9fd3-f6d5191f6858', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¿ç§»', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,501 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¿ç§»'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='WSqKgtCA' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ec91fbf3-0bf7-4a1a-a18c-4f8c130a2f3e', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,502 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ec91fbf3-0bf7-4a1a-a18c-4f8c130a2f3e', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,503 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ec91fbf3-0bf7-4a1a-a18c-4f8c130a2f3e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,503 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ec91fbf3-0bf7-4a1a-a18c-4f8c130a2f3e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,504 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='149GwPlM' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-69e867d3-07dc-4306-a981-f6171da827f6', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,547 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-69e867d3-07dc-4306-a981-f6171da827f6', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,548 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-69e867d3-07dc-4306-a981-f6171da827f6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,549 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-69e867d3-07dc-4306-a981-f6171da827f6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,550 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='rg7DWaU3' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-33812ade-64d8-4f56-aed5-4c50f185818a', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,550 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-33812ade-64d8-4f56-aed5-4c50f185818a', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,552 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-33812ade-64d8-4f56-aed5-4c50f185818a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,552 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-33812ade-64d8-4f56-aed5-4c50f185818a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,553 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='wVTHWjqO' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-00f04b31-ed74-42cb-bedd-36d019efe744', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,553 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-00f04b31-ed74-42cb-bedd-36d019efe744', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,554 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-00f04b31-ed74-42cb-bedd-36d019efe744', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,554 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-00f04b31-ed74-42cb-bedd-36d019efe744', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,555 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='3'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='ZA9DLaul' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f2e1db77-ce8c-4cbf-bb54-b045150b856a', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,592 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f2e1db77-ce8c-4cbf-bb54-b045150b856a', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,594 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f2e1db77-ce8c-4cbf-bb54-b045150b856a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,594 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f2e1db77-ce8c-4cbf-bb54-b045150b856a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,596 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='ZpTPx76E' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-41c29d20-8d30-427e-ab8e-4b7061e3ad34', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,596 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-41c29d20-8d30-427e-ab8e-4b7061e3ad34', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,598 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-41c29d20-8d30-427e-ab8e-4b7061e3ad34', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,598 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-41c29d20-8d30-427e-ab8e-4b7061e3ad34', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,599 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='2'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='k5DsBQiA' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8362233b-e75d-4046-87ea-30f4317652af', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,638 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8362233b-e75d-4046-87ea-30f4317652af', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,640 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8362233b-e75d-4046-87ea-30f4317652af', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,640 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8362233b-e75d-4046-87ea-30f4317652af', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a596cf79-e74d-4a09-9f60-0dddd1dc9957', choices=[Choice(delta=ChoiceDelta(content=' æŠ—', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,641 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a596cf79-e74d-4a09-9f60-0dddd1dc9957', choices=[Choice(delta=ChoiceDelta(content=' æŠ—', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' æŠ—', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,642 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' æŠ—', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a596cf79-e74d-4a09-9f60-0dddd1dc9957', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' æŠ—', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,642 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a596cf79-e74d-4a09-9f60-0dddd1dc9957', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' æŠ—', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,643 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' æŠ—'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='136vkuUH' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7ed381e3-1bd2-4812-950c-ab6a6cc4c9a1', choices=[Choice(delta=ChoiceDelta(content='ç‚', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,685 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7ed381e3-1bd2-4812-950c-ab6a6cc4c9a1', choices=[Choice(delta=ChoiceDelta(content='ç‚', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç‚', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,686 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç‚', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7ed381e3-1bd2-4812-950c-ab6a6cc4c9a1', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç‚', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,686 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7ed381e3-1bd2-4812-950c-ab6a6cc4c9a1', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç‚', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,687 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç‚'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='pstGsMCV' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4dd66f66-2859-4589-96c8-1438c3a22326', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,688 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4dd66f66-2859-4589-96c8-1438c3a22326', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,688 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4dd66f66-2859-4589-96c8-1438c3a22326', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,689 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4dd66f66-2859-4589-96c8-1438c3a22326', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,689 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='SiXjtEHq' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-27e2e290-9bed-4426-aca9-a1f0539b218e', choices=[Choice(delta=ChoiceDelta(content='å…ç–«', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,730 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-27e2e290-9bed-4426-aca9-a1f0539b218e', choices=[Choice(delta=ChoiceDelta(content='å…ç–«', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å…ç–«', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,731 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å…ç–«', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-27e2e290-9bed-4426-aca9-a1f0539b218e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å…ç–«', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,732 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-27e2e290-9bed-4426-aca9-a1f0539b218e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å…ç–«', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,733 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å…ç–«'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='LnACaQnP' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ce197546-6962-480b-8c25-a5d7a0aceb34', choices=[Choice(delta=ChoiceDelta(content='è°ƒèŠ‚', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,733 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ce197546-6962-480b-8c25-a5d7a0aceb34', choices=[Choice(delta=ChoiceDelta(content='è°ƒèŠ‚', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è°ƒèŠ‚', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,734 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è°ƒèŠ‚', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ce197546-6962-480b-8c25-a5d7a0aceb34', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è°ƒèŠ‚', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,735 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ce197546-6962-480b-8c25-a5d7a0aceb34', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è°ƒèŠ‚', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,735 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è°ƒèŠ‚'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='hIrWhAkf' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-95b6a384-b94d-4533-bced-a43cfe470a30', choices=[Choice(delta=ChoiceDelta(content='ä½œç”¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,776 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-95b6a384-b94d-4533-bced-a43cfe470a30', choices=[Choice(delta=ChoiceDelta(content='ä½œç”¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,777 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-95b6a384-b94d-4533-bced-a43cfe470a30', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,777 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-95b6a384-b94d-4533-bced-a43cfe470a30', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,778 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä½œç”¨'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='30Vw71kF' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-527935f3-3423-4afc-9449-757fdd7ff5c8', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,779 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-527935f3-3423-4afc-9449-757fdd7ff5c8', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,780 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-527935f3-3423-4afc-9449-757fdd7ff5c8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,780 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-527935f3-3423-4afc-9449-757fdd7ff5c8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,781 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='py1j1qfS' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-2b193f32-b30c-46e9-a1d3-a3743a359e4e', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,782 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-2b193f32-b30c-46e9-a1d3-a3743a359e4e', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,783 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-2b193f32-b30c-46e9-a1d3-a3743a359e4e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,783 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-2b193f32-b30c-46e9-a1d3-a3743a359e4e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,784 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='iSMkfNaX' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7e1e44ac-77fd-45f3-8f2d-1019c4367be9', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,822 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7e1e44ac-77fd-45f3-8f2d-1019c4367be9', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450950, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,824 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7e1e44ac-77fd-45f3-8f2d-1019c4367be9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,824 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7e1e44ac-77fd-45f3-8f2d-1019c4367be9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,826 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='wqOunG1r' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-cd88df5d-4aa0-4c54-9b0a-ba47dff06566', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,826 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-cd88df5d-4aa0-4c54-9b0a-ba47dff06566', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,827 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-cd88df5d-4aa0-4c54-9b0a-ba47dff06566', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,828 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-cd88df5d-4aa0-4c54-9b0a-ba47dff06566', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,829 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='3'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='0svfPvS5' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ba0f62ab-d80f-4e1b-8b7c-6037f2a349db', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,870 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ba0f62ab-d80f-4e1b-8b7c-6037f2a349db', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,871 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ba0f62ab-d80f-4e1b-8b7c-6037f2a349db', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,872 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ba0f62ab-d80f-4e1b-8b7c-6037f2a349db', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,873 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='YY2RVToI' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-54341142-4d83-4a74-9f7d-0dc8e2fb8a8d', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,874 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-54341142-4d83-4a74-9f7d-0dc8e2fb8a8d', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,875 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-54341142-4d83-4a74-9f7d-0dc8e2fb8a8d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,875 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-54341142-4d83-4a74-9f7d-0dc8e2fb8a8d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,876 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='3'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='nV9AEvYA' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-2578a955-4e0e-420f-9313-7d52f0ad8bbf', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,917 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-2578a955-4e0e-420f-9313-7d52f0ad8bbf', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,919 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-2578a955-4e0e-420f-9313-7d52f0ad8bbf', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,919 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-2578a955-4e0e-420f-9313-7d52f0ad8bbf', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,920 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='Tr9hWPNl' timestamp=1763450949.457893
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-cfed7a58-6a78-46cc-afd7-6edf73626ace', choices=[Choice(delta=ChoiceDelta(content='ä¿ƒè¿›', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:15,920 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-cfed7a58-6a78-46cc-afd7-6edf73626ace', choices=[Choice(delta=ChoiceDelta(content='ä¿ƒè¿›', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¿ƒè¿›', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:15,921 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¿ƒè¿›', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:15 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-cfed7a58-6a78-46cc-afd7-6edf73626ace', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¿ƒè¿›', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,922 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-cfed7a58-6a78-46cc-afd7-6edf73626ace', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¿ƒè¿›', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:15,923 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¿ƒè¿›'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='j1qX5Ef7' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c8fbba2e-91e1-47eb-8462-c1f1939e830b', choices=[Choice(delta=ChoiceDelta(content='è¡€ç®¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,032 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c8fbba2e-91e1-47eb-8462-c1f1939e830b', choices=[Choice(delta=ChoiceDelta(content='è¡€ç®¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡€ç®¡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,033 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡€ç®¡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c8fbba2e-91e1-47eb-8462-c1f1939e830b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡€ç®¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,033 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c8fbba2e-91e1-47eb-8462-c1f1939e830b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡€ç®¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,034 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¡€ç®¡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='wbZlA3B9' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1d54d85f-223b-48b6-bd60-6c07275562c3', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿæˆ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,035 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1d54d85f-223b-48b6-bd60-6c07275562c3', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿæˆ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿæˆ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,036 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿæˆ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1d54d85f-223b-48b6-bd60-6c07275562c3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿæˆ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,036 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1d54d85f-223b-48b6-bd60-6c07275562c3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿæˆ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,038 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç”Ÿæˆ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='5r0oNFTS' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-af99fd58-d6e1-42fb-8a04-a50203ac0bae', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,038 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-af99fd58-d6e1-42fb-8a04-a50203ac0bae', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,039 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-af99fd58-d6e1-42fb-8a04-a50203ac0bae', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,039 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-af99fd58-d6e1-42fb-8a04-a50203ac0bae', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,041 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='eBazrS79' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d2c14ff7-3f02-4057-b095-480731e4ae8a', choices=[Choice(delta=ChoiceDelta(content='ç»„ç»‡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,070 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d2c14ff7-3f02-4057-b095-480731e4ae8a', choices=[Choice(delta=ChoiceDelta(content='ç»„ç»‡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç»„ç»‡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,071 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç»„ç»‡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d2c14ff7-3f02-4057-b095-480731e4ae8a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç»„ç»‡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,071 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d2c14ff7-3f02-4057-b095-480731e4ae8a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç»„ç»‡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,073 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç»„ç»‡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='5SjIoBte' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-81b54657-a58f-4ebc-a7d8-148be62eaa01', choices=[Choice(delta=ChoiceDelta(content='ä¿®å¤', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,073 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-81b54657-a58f-4ebc-a7d8-148be62eaa01', choices=[Choice(delta=ChoiceDelta(content='ä¿®å¤', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¿®å¤', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,074 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¿®å¤', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-81b54657-a58f-4ebc-a7d8-148be62eaa01', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¿®å¤', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,075 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-81b54657-a58f-4ebc-a7d8-148be62eaa01', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¿®å¤', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,075 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¿®å¤'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='wkWfCYag' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7a8aa52b-c78d-484c-ad0d-0d7d4565ad60', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,076 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7a8aa52b-c78d-484c-ad0d-0d7d4565ad60', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,077 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7a8aa52b-c78d-484c-ad0d-0d7d4565ad60', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,077 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7a8aa52b-c78d-484c-ad0d-0d7d4565ad60', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,078 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""

"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='9plxC4kN' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f5294641-e323-47be-8457-9f9fc283bc98', choices=[Choice(delta=ChoiceDelta(content='##', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,079 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f5294641-e323-47be-8457-9f9fc283bc98', choices=[Choice(delta=ChoiceDelta(content='##', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,079 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f5294641-e323-47be-8457-9f9fc283bc98', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,080 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f5294641-e323-47be-8457-9f9fc283bc98', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,080 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='##'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='ODlqgUMs' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8645aa3e-d51f-4f59-808a-8d13c0d10bee', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,081 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8645aa3e-d51f-4f59-808a-8d13c0d10bee', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,082 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8645aa3e-d51f-4f59-808a-8d13c0d10bee', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,082 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8645aa3e-d51f-4f59-808a-8d13c0d10bee', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,083 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='wNAwbPdB' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6487c7db-79c2-440e-a7e7-1393457327f8', choices=[Choice(delta=ChoiceDelta(content='4', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,087 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6487c7db-79c2-440e-a7e7-1393457327f8', choices=[Choice(delta=ChoiceDelta(content='4', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='4', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,088 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='4', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6487c7db-79c2-440e-a7e7-1393457327f8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='4', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,088 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6487c7db-79c2-440e-a7e7-1393457327f8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='4', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,090 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='4'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='Ymfo4WW6' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b699afef-e6d9-404f-aace-9ed603dd8c18', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,133 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b699afef-e6d9-404f-aace-9ed603dd8c18', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,135 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b699afef-e6d9-404f-aace-9ed603dd8c18', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,135 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b699afef-e6d9-404f-aace-9ed603dd8c18', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,136 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='L5XnUzBO' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-89db19af-8b93-40a8-9888-2d154b8c3d7f', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,136 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-89db19af-8b93-40a8-9888-2d154b8c3d7f', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,138 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-89db19af-8b93-40a8-9888-2d154b8c3d7f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,138 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-89db19af-8b93-40a8-9888-2d154b8c3d7f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,139 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='TYXwQML4' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-df65331a-ea1e-4ec6-aba7-f655d96507b0', choices=[Choice(delta=ChoiceDelta(content='ä¸´åºŠ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,180 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-df65331a-ea1e-4ec6-aba7-f655d96507b0', choices=[Choice(delta=ChoiceDelta(content='ä¸´åºŠ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,182 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-df65331a-ea1e-4ec6-aba7-f655d96507b0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,182 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-df65331a-ea1e-4ec6-aba7-f655d96507b0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,183 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸´åºŠ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='m0htv1Sw' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0fe0d881-c510-4898-8029-452e77a0f6f1', choices=[Choice(delta=ChoiceDelta(content='åº”ç”¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,183 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0fe0d881-c510-4898-8029-452e77a0f6f1', choices=[Choice(delta=ChoiceDelta(content='åº”ç”¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åº”ç”¨', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,184 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åº”ç”¨', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0fe0d881-c510-4898-8029-452e77a0f6f1', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åº”ç”¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,184 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0fe0d881-c510-4898-8029-452e77a0f6f1', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åº”ç”¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,186 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='åº”ç”¨'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='u1IAPwrZ' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-112c33c5-a9f1-463f-82b5-5d78f2229e37', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,228 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-112c33c5-a9f1-463f-82b5-5d78f2229e37', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,229 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-112c33c5-a9f1-463f-82b5-5d78f2229e37', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,229 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-112c33c5-a9f1-463f-82b5-5d78f2229e37', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,230 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='cin86gZz' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8bedccef-c785-48b0-9fde-585686cbef0b', choices=[Choice(delta=ChoiceDelta(content='ç–—æ•ˆ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,231 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8bedccef-c785-48b0-9fde-585686cbef0b', choices=[Choice(delta=ChoiceDelta(content='ç–—æ•ˆ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç–—æ•ˆ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,233 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç–—æ•ˆ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8bedccef-c785-48b0-9fde-585686cbef0b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç–—æ•ˆ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,233 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8bedccef-c785-48b0-9fde-585686cbef0b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç–—æ•ˆ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,234 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç–—æ•ˆ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='GKAxonJh' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-57d3c9ff-1a49-49d1-9e31-d4171a23b1bd', choices=[Choice(delta=ChoiceDelta(content='è¯„ä¼°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,272 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-57d3c9ff-1a49-49d1-9e31-d4171a23b1bd', choices=[Choice(delta=ChoiceDelta(content='è¯„ä¼°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¯„ä¼°', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,274 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¯„ä¼°', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-57d3c9ff-1a49-49d1-9e31-d4171a23b1bd', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¯„ä¼°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,274 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-57d3c9ff-1a49-49d1-9e31-d4171a23b1bd', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¯„ä¼°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,275 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¯„ä¼°'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='bHfzVPHc' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-779391d0-aef2-4f7a-9368-30d30e21c527', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,276 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-779391d0-aef2-4f7a-9368-30d30e21c527', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,278 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-779391d0-aef2-4f7a-9368-30d30e21c527', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,278 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-779391d0-aef2-4f7a-9368-30d30e21c527', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,279 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='t7moMCcP' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3a51ef60-eae0-4318-83f9-7bf359b03963', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,318 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3a51ef60-eae0-4318-83f9-7bf359b03963', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,319 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3a51ef60-eae0-4318-83f9-7bf359b03963', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,319 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3a51ef60-eae0-4318-83f9-7bf359b03963', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,320 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='vMFCIwW9' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-540ba102-cd6a-4a9a-9095-4e8670a0bdd3', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,321 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-540ba102-cd6a-4a9a-9095-4e8670a0bdd3', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,323 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-540ba102-cd6a-4a9a-9095-4e8670a0bdd3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,323 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-540ba102-cd6a-4a9a-9095-4e8670a0bdd3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,324 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='2YrpP43B' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-cd644adc-3327-4ff8-8bbb-0f282c1f3545', choices=[Choice(delta=ChoiceDelta(content='4', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,324 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-cd644adc-3327-4ff8-8bbb-0f282c1f3545', choices=[Choice(delta=ChoiceDelta(content='4', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='4', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,325 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='4', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-cd644adc-3327-4ff8-8bbb-0f282c1f3545', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='4', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,326 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-cd644adc-3327-4ff8-8bbb-0f282c1f3545', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='4', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,327 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='4'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='FevMtVId' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9e4a5302-da56-44b0-9c4f-6f67abc0b347', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,365 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9e4a5302-da56-44b0-9c4f-6f67abc0b347', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,367 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9e4a5302-da56-44b0-9c4f-6f67abc0b347', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,367 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9e4a5302-da56-44b0-9c4f-6f67abc0b347', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,368 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='hXpubKcQ' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5b0fab53-dfed-4356-b480-0767ead29f8e', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,369 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5b0fab53-dfed-4356-b480-0767ead29f8e', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,370 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5b0fab53-dfed-4356-b480-0767ead29f8e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,370 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5b0fab53-dfed-4356-b480-0767ead29f8e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,371 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='1'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='e2JH8qYx' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a8bad506-40bb-408e-b30f-6c3798e67b92', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,412 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a8bad506-40bb-408e-b30f-6c3798e67b92', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,414 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a8bad506-40bb-408e-b30f-6c3798e67b92', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,414 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a8bad506-40bb-408e-b30f-6c3798e67b92', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,415 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='Oyiy3EgT' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f1eea811-4a3e-49cf-a3b9-7e57b04e5905', choices=[Choice(delta=ChoiceDelta(content='ä¸´åºŠ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,416 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f1eea811-4a3e-49cf-a3b9-7e57b04e5905', choices=[Choice(delta=ChoiceDelta(content='ä¸´åºŠ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,417 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f1eea811-4a3e-49cf-a3b9-7e57b04e5905', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,417 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f1eea811-4a3e-49cf-a3b9-7e57b04e5905', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,418 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸´åºŠ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='xhzleeoh' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3b16f3d2-ef50-4447-a922-bc701e71c2dc', choices=[Choice(delta=ChoiceDelta(content='è¯•éªŒ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,459 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3b16f3d2-ef50-4447-a922-bc701e71c2dc', choices=[Choice(delta=ChoiceDelta(content='è¯•éªŒ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¯•éªŒ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,460 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¯•éªŒ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3b16f3d2-ef50-4447-a922-bc701e71c2dc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¯•éªŒ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,461 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3b16f3d2-ef50-4447-a922-bc701e71c2dc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¯•éªŒ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¿ç§»'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¿ç§»
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='3'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 3
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='2'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 2
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' æŠ—'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  æŠ—
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç‚'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç‚
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å…ç–«'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å…ç–«
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è°ƒèŠ‚'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è°ƒèŠ‚
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä½œç”¨'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä½œç”¨
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='3'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 3
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='3'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 3
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¿ƒè¿›'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¿ƒè¿›
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¡€ç®¡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¡€ç®¡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç”Ÿæˆ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç”Ÿæˆ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç»„ç»‡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç»„ç»‡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¿®å¤'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¿®å¤
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""

"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 


è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='##'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ##
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='4'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 4
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸´åºŠ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸´åºŠ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='åº”ç”¨'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: åº”ç”¨
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç–—æ•ˆ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç–—æ•ˆ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¯„ä¼°'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¯„ä¼°
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='4'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 4
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='1'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 1
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸´åºŠ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸´åºŠ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¯•éªŒ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¯•éªŒ2025-11-18 15:29:16,462 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¯•éªŒ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='LocwOR40' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-aacb594a-fd0a-4e44-8ed5-bbba23f059a6', choices=[Choice(delta=ChoiceDelta(content='ç»“æœ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,463 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-aacb594a-fd0a-4e44-8ed5-bbba23f059a6', choices=[Choice(delta=ChoiceDelta(content='ç»“æœ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç»“æœ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,463 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç»“æœ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-aacb594a-fd0a-4e44-8ed5-bbba23f059a6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç»“æœ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,464 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-aacb594a-fd0a-4e44-8ed5-bbba23f059a6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç»“æœ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,465 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç»“æœ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='ppOXMJOr' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c0f9df07-983d-492d-afe7-1459d4388798', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,505 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c0f9df07-983d-492d-afe7-1459d4388798', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,508 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c0f9df07-983d-492d-afe7-1459d4388798', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,508 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c0f9df07-983d-492d-afe7-1459d4388798', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,509 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='JSZUfQcB' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-fe02f8ca-ffe6-49cb-b6e1-9f95174d7fc7', choices=[Choice(delta=ChoiceDelta(content='ç–—æ•ˆ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,509 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-fe02f8ca-ffe6-49cb-b6e1-9f95174d7fc7', choices=[Choice(delta=ChoiceDelta(content='ç–—æ•ˆ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç–—æ•ˆ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,511 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç–—æ•ˆ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-fe02f8ca-ffe6-49cb-b6e1-9f95174d7fc7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç–—æ•ˆ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,512 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-fe02f8ca-ffe6-49cb-b6e1-9f95174d7fc7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç–—æ•ˆ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,513 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç–—æ•ˆ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='0tIy2qU5' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b930b1c7-ab6a-4374-944e-d4d3bff29b5d', choices=[Choice(delta=ChoiceDelta(content='æ•°æ®', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,553 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b930b1c7-ab6a-4374-944e-d4d3bff29b5d', choices=[Choice(delta=ChoiceDelta(content='æ•°æ®', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ•°æ®', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,554 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ•°æ®', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b930b1c7-ab6a-4374-944e-d4d3bff29b5d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ•°æ®', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,554 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b930b1c7-ab6a-4374-944e-d4d3bff29b5d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ•°æ®', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,555 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ•°æ®'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='TBD5WATf' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f7a89501-1ffe-4801-a0c1-cd4d4f7fbece', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,556 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f7a89501-1ffe-4801-a0c1-cd4d4f7fbece', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,557 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f7a89501-1ffe-4801-a0c1-cd4d4f7fbece', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,557 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f7a89501-1ffe-4801-a0c1-cd4d4f7fbece', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,558 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='asjKIQsV' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-eda36f03-31fb-4726-bc25-e3acf8a3fe20', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,559 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-eda36f03-31fb-4726-bc25-e3acf8a3fe20', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,561 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-eda36f03-31fb-4726-bc25-e3acf8a3fe20', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,561 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-eda36f03-31fb-4726-bc25-e3acf8a3fe20', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,562 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='Rfyxmaso' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-bdd24370-4409-453b-bc2b-c1e2381c352a', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,599 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-bdd24370-4409-453b-bc2b-c1e2381c352a', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,602 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-bdd24370-4409-453b-bc2b-c1e2381c352a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,602 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-bdd24370-4409-453b-bc2b-c1e2381c352a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,603 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='BBBsS9ND' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7b3316d3-36ff-444d-898d-66cfe8f4d66e', choices=[Choice(delta=ChoiceDelta(content='4', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,603 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7b3316d3-36ff-444d-898d-66cfe8f4d66e', choices=[Choice(delta=ChoiceDelta(content='4', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='4', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,604 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='4', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7b3316d3-36ff-444d-898d-66cfe8f4d66e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='4', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,604 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7b3316d3-36ff-444d-898d-66cfe8f4d66e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='4', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,605 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='4'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='wgDcX3JA' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-180750c2-54d6-40ab-9764-304e8083ddc3', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,646 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-180750c2-54d6-40ab-9764-304e8083ddc3', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,648 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-180750c2-54d6-40ab-9764-304e8083ddc3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,648 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-180750c2-54d6-40ab-9764-304e8083ddc3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,649 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='tHIzmWnA' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f5fb6f8c-1823-47e2-8538-3d1cc3bc3cea', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,649 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f5fb6f8c-1823-47e2-8538-3d1cc3bc3cea', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,650 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f5fb6f8c-1823-47e2-8538-3d1cc3bc3cea', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,651 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f5fb6f8c-1823-47e2-8538-3d1cc3bc3cea', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,652 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='2'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='DSYmkrRy' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-37d65e83-9812-465b-90e1-67bd627cd7b2', choices=[Choice(delta=ChoiceDelta(content=' ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,691 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-37d65e83-9812-465b-90e1-67bd627cd7b2', choices=[Choice(delta=ChoiceDelta(content=' ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,693 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-37d65e83-9812-465b-90e1-67bd627cd7b2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,693 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-37d65e83-9812-465b-90e1-67bd627cd7b2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,694 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='UDGpnYKx' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-92ee08b2-b590-411b-9e2e-18b4350d7c74', choices=[Choice(delta=ChoiceDelta(content='åŒ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,695 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-92ee08b2-b590-411b-9e2e-18b4350d7c74', choices=[Choice(delta=ChoiceDelta(content='åŒ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åŒ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,696 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åŒ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-92ee08b2-b590-411b-9e2e-18b4350d7c74', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åŒ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,696 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-92ee08b2-b590-411b-9e2e-18b4350d7c74', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åŒ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,697 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='åŒ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='0Ev2MryI' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-cbc4dddb-fdfd-4dd7-973b-92b8bfb1fc43', choices=[Choice(delta=ChoiceDelta(content='äººç¾¤', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,739 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-cbc4dddb-fdfd-4dd7-973b-92b8bfb1fc43', choices=[Choice(delta=ChoiceDelta(content='äººç¾¤', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='äººç¾¤', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,741 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='äººç¾¤', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-cbc4dddb-fdfd-4dd7-973b-92b8bfb1fc43', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='äººç¾¤', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,741 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-cbc4dddb-fdfd-4dd7-973b-92b8bfb1fc43', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='äººç¾¤', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,742 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='äººç¾¤'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='vEtpN0gK' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-56724e27-f6c7-4623-89ae-9d3078979252', choices=[Choice(delta=ChoiceDelta(content='ä¸­çš„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,743 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-56724e27-f6c7-4623-89ae-9d3078979252', choices=[Choice(delta=ChoiceDelta(content='ä¸­çš„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸­çš„', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,745 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸­çš„', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-56724e27-f6c7-4623-89ae-9d3078979252', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸­çš„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,745 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-56724e27-f6c7-4623-89ae-9d3078979252', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸­çš„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,746 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸­çš„'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='ZY9lhOCk' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1097e152-fa79-40b7-ad81-fe18a872b010', choices=[Choice(delta=ChoiceDelta(content='æ²»ç–—', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,746 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1097e152-fa79-40b7-ad81-fe18a872b010', choices=[Choice(delta=ChoiceDelta(content='æ²»ç–—', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,747 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1097e152-fa79-40b7-ad81-fe18a872b010', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,747 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1097e152-fa79-40b7-ad81-fe18a872b010', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,748 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ²»ç–—'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='gv9djldD' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-948c3663-8cd3-49fd-a930-d5a201efd70f', choices=[Choice(delta=ChoiceDelta(content='æ•ˆæœ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,785 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-948c3663-8cd3-49fd-a930-d5a201efd70f', choices=[Choice(delta=ChoiceDelta(content='æ•ˆæœ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ•ˆæœ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,786 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ•ˆæœ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-948c3663-8cd3-49fd-a930-d5a201efd70f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ•ˆæœ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,786 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-948c3663-8cd3-49fd-a930-d5a201efd70f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ•ˆæœ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,787 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ•ˆæœ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='WuydHmbT' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-41b4e681-cc33-4ed8-b546-4d83cd5c33b4', choices=[Choice(delta=ChoiceDelta(content='å·®å¼‚', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,787 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-41b4e681-cc33-4ed8-b546-4d83cd5c33b4', choices=[Choice(delta=ChoiceDelta(content='å·®å¼‚', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å·®å¼‚', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,789 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å·®å¼‚', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-41b4e681-cc33-4ed8-b546-4d83cd5c33b4', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å·®å¼‚', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,789 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-41b4e681-cc33-4ed8-b546-4d83cd5c33b4', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å·®å¼‚', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,790 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å·®å¼‚'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='gfkVS0qn' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3d3ee919-c672-4f3c-9c37-49339609724d', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,831 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3d3ee919-c672-4f3c-9c37-49339609724d', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450951, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,832 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3d3ee919-c672-4f3c-9c37-49339609724d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,832 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3d3ee919-c672-4f3c-9c37-49339609724d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,833 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='gyAVtlX2' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-45277989-cec9-4b11-93b3-f3ad51b1fddf', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,834 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-45277989-cec9-4b11-93b3-f3ad51b1fddf', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,834 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-45277989-cec9-4b11-93b3-f3ad51b1fddf', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,836 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-45277989-cec9-4b11-93b3-f3ad51b1fddf', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,837 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='MpglceSm' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8dcc974a-c3b2-44d4-8d8a-d6e2e6d7748f', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,877 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8dcc974a-c3b2-44d4-8d8a-d6e2e6d7748f', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,879 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8dcc974a-c3b2-44d4-8d8a-d6e2e6d7748f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,879 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8dcc974a-c3b2-44d4-8d8a-d6e2e6d7748f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,880 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='XlUVKrlP' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-07489d08-3ce5-4747-ac40-ab2e94b0ff6d', choices=[Choice(delta=ChoiceDelta(content='4', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,881 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-07489d08-3ce5-4747-ac40-ab2e94b0ff6d', choices=[Choice(delta=ChoiceDelta(content='4', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='4', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,882 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='4', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-07489d08-3ce5-4747-ac40-ab2e94b0ff6d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='4', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,882 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-07489d08-3ce5-4747-ac40-ab2e94b0ff6d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='4', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,883 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='4'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='e7RofbpM' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-edc76525-519f-466b-8984-3a514748bee9', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,924 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-edc76525-519f-466b-8984-3a514748bee9', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,927 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-edc76525-519f-466b-8984-3a514748bee9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,928 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-edc76525-519f-466b-8984-3a514748bee9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,928 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='KuWt2wLO' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f24d8f1c-6a2f-4277-9473-909bc6902f7a', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,929 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f24d8f1c-6a2f-4277-9473-909bc6902f7a', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,930 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f24d8f1c-6a2f-4277-9473-909bc6902f7a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,931 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f24d8f1c-6a2f-4277-9473-909bc6902f7a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,932 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='3'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='eLmADqko' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-37c2ea50-cf83-4fac-8131-707326f73006', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,933 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-37c2ea50-cf83-4fac-8131-707326f73006', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,934 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-37c2ea50-cf83-4fac-8131-707326f73006', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,934 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-37c2ea50-cf83-4fac-8131-707326f73006', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,935 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='hcmSBBth' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ffc3093e-88a9-4bbb-a036-dc2f0f021b9e', choices=[Choice(delta=ChoiceDelta(content='ä¸å…¶ä»–', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,972 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ffc3093e-88a9-4bbb-a036-dc2f0f021b9e', choices=[Choice(delta=ChoiceDelta(content='ä¸å…¶ä»–', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸å…¶ä»–', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,974 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸å…¶ä»–', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ffc3093e-88a9-4bbb-a036-dc2f0f021b9e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸å…¶ä»–', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,974 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ffc3093e-88a9-4bbb-a036-dc2f0f021b9e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸å…¶ä»–', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,975 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸å…¶ä»–'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='9AdcSN4L' timestamp=1763450949.457893
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-475d05ce-b59b-4dbf-869e-0b0d3298e7a2', choices=[Choice(delta=ChoiceDelta(content='æ²»ç–—', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:16,975 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-475d05ce-b59b-4dbf-869e-0b0d3298e7a2', choices=[Choice(delta=ChoiceDelta(content='æ²»ç–—', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:16,977 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:16 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-475d05ce-b59b-4dbf-869e-0b0d3298e7a2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,977 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-475d05ce-b59b-4dbf-869e-0b0d3298e7a2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:16,978 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ²»ç–—'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='SPLzNqKe' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4f6157e4-5b47-4f7c-b726-5a8492b4504e', choices=[Choice(delta=ChoiceDelta(content='æ‰‹æ®µ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,020 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4f6157e4-5b47-4f7c-b726-5a8492b4504e', choices=[Choice(delta=ChoiceDelta(content='æ‰‹æ®µ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ‰‹æ®µ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,021 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ‰‹æ®µ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4f6157e4-5b47-4f7c-b726-5a8492b4504e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ‰‹æ®µ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,021 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4f6157e4-5b47-4f7c-b726-5a8492b4504e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ‰‹æ®µ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,023 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ‰‹æ®µ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='gLx7aYuE' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-be1d0b93-d545-4759-8932-8ab0f0fe63b8', choices=[Choice(delta=ChoiceDelta(content='çš„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,023 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-be1d0b93-d545-4759-8932-8ab0f0fe63b8', choices=[Choice(delta=ChoiceDelta(content='çš„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,024 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-be1d0b93-d545-4759-8932-8ab0f0fe63b8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,024 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-be1d0b93-d545-4759-8932-8ab0f0fe63b8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,026 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='çš„'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='1KIHoLjn' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f2d3d384-d75d-4556-b927-5316a9fe4f3e', choices=[Choice(delta=ChoiceDelta(content='ååŒ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,066 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f2d3d384-d75d-4556-b927-5316a9fe4f3e', choices=[Choice(delta=ChoiceDelta(content='ååŒ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ååŒ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,067 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ååŒ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f2d3d384-d75d-4556-b927-5316a9fe4f3e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ååŒ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,067 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f2d3d384-d75d-4556-b927-5316a9fe4f3e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ååŒ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,068 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ååŒ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='vgzkeSh9' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3025ad1a-6484-4973-bce3-dc39f925a14b', choices=[Choice(delta=ChoiceDelta(content='æ•ˆåº”', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,069 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3025ad1a-6484-4973-bce3-dc39f925a14b', choices=[Choice(delta=ChoiceDelta(content='æ•ˆåº”', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ•ˆåº”', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,070 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ•ˆåº”', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3025ad1a-6484-4973-bce3-dc39f925a14b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ•ˆåº”', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,070 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3025ad1a-6484-4973-bce3-dc39f925a14b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ•ˆåº”', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,071 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ•ˆåº”'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='zdKISQ10' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7bc83e9b-d7c3-4502-84ed-69958105d6f2', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,113 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7bc83e9b-d7c3-4502-84ed-69958105d6f2', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,115 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7bc83e9b-d7c3-4502-84ed-69958105d6f2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,115 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7bc83e9b-d7c3-4502-84ed-69958105d6f2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,116 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""

"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='kWpFQp0O' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3a0c8347-654c-4df8-b564-c43877835a24', choices=[Choice(delta=ChoiceDelta(content='##', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,117 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3a0c8347-654c-4df8-b564-c43877835a24', choices=[Choice(delta=ChoiceDelta(content='##', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,118 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3a0c8347-654c-4df8-b564-c43877835a24', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,118 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3a0c8347-654c-4df8-b564-c43877835a24', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,119 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='##'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='mMGEP5lm' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5296658b-5b94-477b-b183-0a389a890e78', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,120 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5296658b-5b94-477b-b183-0a389a890e78', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,120 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5296658b-5b94-477b-b183-0a389a890e78', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,121 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5296658b-5b94-477b-b183-0a389a890e78', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,121 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='YkCGYSYa' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-be9f3bd8-eade-4f96-97d4-7d296eaa417a', choices=[Choice(delta=ChoiceDelta(content='5', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,159 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-be9f3bd8-eade-4f96-97d4-7d296eaa417a', choices=[Choice(delta=ChoiceDelta(content='5', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='5', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,161 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='5', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-be9f3bd8-eade-4f96-97d4-7d296eaa417a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='5', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,161 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-be9f3bd8-eade-4f96-97d4-7d296eaa417a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='5', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,162 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='5'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='NJ8MbIqv' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b2604d48-3c9c-4120-9d70-ed37073b9b96', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,162 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b2604d48-3c9c-4120-9d70-ed37073b9b96', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,164 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b2604d48-3c9c-4120-9d70-ed37073b9b96', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,165 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b2604d48-3c9c-4120-9d70-ed37073b9b96', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,166 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='YrrqePjX' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-33e02060-30e1-403c-97e9-f02477267975', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,207 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-33e02060-30e1-403c-97e9-f02477267975', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,208 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-33e02060-30e1-403c-97e9-f02477267975', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,208 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-33e02060-30e1-403c-97e9-f02477267975', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5eae8188-8f86-49a5-b287-4ac89b066a7c', choices=[Choice(delta=ChoiceDelta(content=' å®‰', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,209 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5eae8188-8f86-49a5-b287-4ac89b066a7c', choices=[Choice(delta=ChoiceDelta(content=' å®‰', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' å®‰', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,210 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' å®‰', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5eae8188-8f86-49a5-b287-4ac89b066a7c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' å®‰', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,210 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5eae8188-8f86-49a5-b287-4ac89b066a7c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' å®‰', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,211 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' å®‰'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='yz28EBLY' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-47310416-3caa-40f7-b3ed-27b473cd6016', choices=[Choice(delta=ChoiceDelta(content='å…¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,254 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-47310416-3caa-40f7-b3ed-27b473cd6016', choices=[Choice(delta=ChoiceDelta(content='å…¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å…¨', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,256 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å…¨', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-47310416-3caa-40f7-b3ed-27b473cd6016', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å…¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,256 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-47310416-3caa-40f7-b3ed-27b473cd6016', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å…¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,257 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å…¨'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='zQJC5Ng3' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-237b7543-f994-452b-863b-9bf5c8d6117d', choices=[Choice(delta=ChoiceDelta(content='æ€§', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,257 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-237b7543-f994-452b-863b-9bf5c8d6117d', choices=[Choice(delta=ChoiceDelta(content='æ€§', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ€§', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,259 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ€§', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-237b7543-f994-452b-863b-9bf5c8d6117d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ€§', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,259 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-237b7543-f994-452b-863b-9bf5c8d6117d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ€§', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,260 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ€§'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='NigWSV5h' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-53940bf1-0e9e-4853-9957-e9957d5bf070', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,299 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-53940bf1-0e9e-4853-9957-e9957d5bf070', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,301 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-53940bf1-0e9e-4853-9957-e9957d5bf070', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,301 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-53940bf1-0e9e-4853-9957-e9957d5bf070', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,302 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='9aKPKNPc' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-fb2cb7a8-b2a5-4bf8-b50a-a351b373fbb9', choices=[Choice(delta=ChoiceDelta(content='å‰¯ä½œç”¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,303 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-fb2cb7a8-b2a5-4bf8-b50a-a351b373fbb9', choices=[Choice(delta=ChoiceDelta(content='å‰¯ä½œç”¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å‰¯ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,304 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å‰¯ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-fb2cb7a8-b2a5-4bf8-b50a-a351b373fbb9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å‰¯ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,304 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-fb2cb7a8-b2a5-4bf8-b50a-a351b373fbb9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å‰¯ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,305 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å‰¯ä½œç”¨'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='05ojefrZ' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ff282787-e6e5-4ae3-995b-5fde7284a78f', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,344 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ff282787-e6e5-4ae3-995b-5fde7284a78f', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,346 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ff282787-e6e5-4ae3-995b-5fde7284a78f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,346 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ff282787-e6e5-4ae3-995b-5fde7284a78f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,347 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='vTD9sepX' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1e36a977-1764-4f0b-9029-670b934d7dd5', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,348 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1e36a977-1764-4f0b-9029-670b934d7dd5', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,349 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1e36a977-1764-4f0b-9029-670b934d7dd5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,349 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1e36a977-1764-4f0b-9029-670b934d7dd5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,350 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='jVRC1K74' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-2e7ddbec-ab41-48bf-8dfc-e9fce3c8b1f6', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,350 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-2e7ddbec-ab41-48bf-8dfc-e9fce3c8b1f6', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,351 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-2e7ddbec-ab41-48bf-8dfc-e9fce3c8b1f6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,351 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-2e7ddbec-ab41-48bf-8dfc-e9fce3c8b1f6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,353 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='61KTz1Z5' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d76d858f-cfc9-4633-ba3d-4e9a3e114b76', choices=[Choice(delta=ChoiceDelta(content='5', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,390 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d76d858f-cfc9-4633-ba3d-4e9a3e114b76', choices=[Choice(delta=ChoiceDelta(content='5', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='5', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,392 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='5', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d76d858f-cfc9-4633-ba3d-4e9a3e114b76', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='5', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,392 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d76d858f-cfc9-4633-ba3d-4e9a3e114b76', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='5', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,393 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='5'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='wl3Lxi1W' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4c507d23-6a07-4ed4-a556-18d47b092d61', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,394 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4c507d23-6a07-4ed4-a556-18d47b092d61', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,395 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4c507d23-6a07-4ed4-a556-18d47b092d61', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,395 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4c507d23-6a07-4ed4-a556-18d47b092d61', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,397 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='6wtwoZJr' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b8d20c03-f99c-4cb1-aad9-b917a966b09e', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,436 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b8d20c03-f99c-4cb1-aad9-b917a966b09e', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,437 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b8d20c03-f99c-4cb1-aad9-b917a966b09e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,438 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b8d20c03-f99c-4cb1-aad9-b917a966b09e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,439 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='1'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='PSZNNoNG' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ec79e576-6af7-4e31-b108-5fabe4f5fefe', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,440 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ec79e576-6af7-4e31-b108-5fabe4f5fefe', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,441 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ec79e576-6af7-4e31-b108-5fabe4f5fefe', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,441 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ec79e576-6af7-4e31-b108-5fabe4f5fefe', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-702a5b62-ea58-4ba6-a856-fb5d74dc6e53', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,483 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-702a5b62-ea58-4ba6-a856-fb5d74dc6e53', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,484 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-702a5b62-ea58-4ba6-a856-fb5d74dc6e53', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,484 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-702a5b62-ea58-4ba6-a856-fb5d74dc6e53', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-20b737d5-bb87-4fd6-abbd-18651dd07f7a', choices=[Choice(delta=ChoiceDelta(content=' çŸ­', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,485 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-20b737d5-bb87-4fd6-abbd-18651dd07f7a', choices=[Choice(delta=ChoiceDelta(content=' çŸ­', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' çŸ­', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,486 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' çŸ­', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-20b737d5-bb87-4fd6-abbd-18651dd07f7a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' çŸ­', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,486 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-20b737d5-bb87-4fd6-abbd-18651dd07f7a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' çŸ­', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç»“æœ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç»“æœ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç–—æ•ˆ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç–—æ•ˆ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ•°æ®'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ•°æ®
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='4'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 4
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='2'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 2
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='åŒ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: åŒ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='äººç¾¤'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: äººç¾¤
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸­çš„'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸­çš„
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ²»ç–—'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ²»ç–—
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ•ˆæœ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ•ˆæœ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å·®å¼‚'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å·®å¼‚
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='4'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 4
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='3'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 3
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸å…¶ä»–'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸å…¶ä»–
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ²»ç–—'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ²»ç–—
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ‰‹æ®µ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ‰‹æ®µ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='çš„'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: çš„
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ååŒ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ååŒ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ•ˆåº”'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ•ˆåº”
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""

"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 


è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='##'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ##
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='5'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 5
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' å®‰'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  å®‰
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å…¨'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å…¨
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ€§'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ€§
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å‰¯ä½œç”¨'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å‰¯ä½œç”¨
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='5'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 5
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='1'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 1
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' çŸ­'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  çŸ­2025-11-18 15:29:17,487 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' çŸ­'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='V4AVmqRy' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-eee04759-461d-4dae-abc0-03ea5fdb8156', choices=[Choice(delta=ChoiceDelta(content='æœŸ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,529 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-eee04759-461d-4dae-abc0-03ea5fdb8156', choices=[Choice(delta=ChoiceDelta(content='æœŸ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æœŸ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,531 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æœŸ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-eee04759-461d-4dae-abc0-03ea5fdb8156', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æœŸ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,531 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-eee04759-461d-4dae-abc0-03ea5fdb8156', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æœŸ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,532 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æœŸ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='baBCMil9' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6ccfcb05-1b2d-4d7b-9c89-2a8654feeb00', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,533 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6ccfcb05-1b2d-4d7b-9c89-2a8654feeb00', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,534 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6ccfcb05-1b2d-4d7b-9c89-2a8654feeb00', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,534 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6ccfcb05-1b2d-4d7b-9c89-2a8654feeb00', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,535 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='NdO2Z41O' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4aefb571-5c51-4391-a789-c7612b869a67', choices=[Choice(delta=ChoiceDelta(content='é•¿æœŸ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,575 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4aefb571-5c51-4391-a789-c7612b869a67', choices=[Choice(delta=ChoiceDelta(content='é•¿æœŸ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='é•¿æœŸ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,576 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='é•¿æœŸ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4aefb571-5c51-4391-a789-c7612b869a67', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='é•¿æœŸ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,576 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4aefb571-5c51-4391-a789-c7612b869a67', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='é•¿æœŸ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,577 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='é•¿æœŸ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='9yP1LfzB' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-477433a5-8c94-44f5-be58-22ce69c1f88e', choices=[Choice(delta=ChoiceDelta(content='å‰¯ä½œç”¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,578 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-477433a5-8c94-44f5-be58-22ce69c1f88e', choices=[Choice(delta=ChoiceDelta(content='å‰¯ä½œç”¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å‰¯ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,579 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å‰¯ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-477433a5-8c94-44f5-be58-22ce69c1f88e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å‰¯ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,579 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-477433a5-8c94-44f5-be58-22ce69c1f88e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å‰¯ä½œç”¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,580 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å‰¯ä½œç”¨'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='237Zw58m' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d765fc9b-dcea-4a87-8435-949a62c90184', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,580 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d765fc9b-dcea-4a87-8435-949a62c90184', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,581 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d765fc9b-dcea-4a87-8435-949a62c90184', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,582 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d765fc9b-dcea-4a87-8435-949a62c90184', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,582 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='pWw9OAez' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-215c3bca-1507-421d-8d2b-8c583a41c755', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,621 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-215c3bca-1507-421d-8d2b-8c583a41c755', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,623 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-215c3bca-1507-421d-8d2b-8c583a41c755', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,623 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-215c3bca-1507-421d-8d2b-8c583a41c755', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,624 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='drs80Wxb' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f26eda5e-eba5-4cc4-b156-90d131de93ca', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,625 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f26eda5e-eba5-4cc4-b156-90d131de93ca', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,626 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f26eda5e-eba5-4cc4-b156-90d131de93ca', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,626 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f26eda5e-eba5-4cc4-b156-90d131de93ca', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,626 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='gjyRz3Yc' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3ecc3b84-9b97-432b-9fef-66f3c884f072', choices=[Choice(delta=ChoiceDelta(content='5', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,667 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3ecc3b84-9b97-432b-9fef-66f3c884f072', choices=[Choice(delta=ChoiceDelta(content='5', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='5', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,669 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='5', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3ecc3b84-9b97-432b-9fef-66f3c884f072', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='5', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,669 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3ecc3b84-9b97-432b-9fef-66f3c884f072', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='5', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,671 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='5'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='2YLBm5NL' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f7225eaa-04c6-494d-ad3f-a285f773cf49', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,671 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f7225eaa-04c6-494d-ad3f-a285f773cf49', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,672 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f7225eaa-04c6-494d-ad3f-a285f773cf49', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,673 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f7225eaa-04c6-494d-ad3f-a285f773cf49', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,674 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='LAvHZFxf' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5aa39474-a1ad-4303-848f-65f773f4e263', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,715 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5aa39474-a1ad-4303-848f-65f773f4e263', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,716 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5aa39474-a1ad-4303-848f-65f773f4e263', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,716 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5aa39474-a1ad-4303-848f-65f773f4e263', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,717 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='2'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='H0fM7TsK' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0a5b41b2-71a5-4261-ae3d-053e4a27cc1b', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,718 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0a5b41b2-71a5-4261-ae3d-053e4a27cc1b', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,719 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0a5b41b2-71a5-4261-ae3d-053e4a27cc1b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,719 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0a5b41b2-71a5-4261-ae3d-053e4a27cc1b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-88ce775a-3e3c-4b37-b50f-448cf2470ed8', choices=[Choice(delta=ChoiceDelta(content=' ç‰¹', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,761 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-88ce775a-3e3c-4b37-b50f-448cf2470ed8', choices=[Choice(delta=ChoiceDelta(content=' ç‰¹', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ç‰¹', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,763 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ç‰¹', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-88ce775a-3e3c-4b37-b50f-448cf2470ed8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ç‰¹', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,763 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-88ce775a-3e3c-4b37-b50f-448cf2470ed8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ç‰¹', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,764 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' ç‰¹'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='V7zOL1R8' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5ad67cd6-5420-42ec-8ef7-96a89dbaa6d9', choices=[Choice(delta=ChoiceDelta(content='æ®Š', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,765 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5ad67cd6-5420-42ec-8ef7-96a89dbaa6d9', choices=[Choice(delta=ChoiceDelta(content='æ®Š', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ®Š', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,766 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ®Š', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5ad67cd6-5420-42ec-8ef7-96a89dbaa6d9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ®Š', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,766 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5ad67cd6-5420-42ec-8ef7-96a89dbaa6d9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ®Š', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,767 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ®Š'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='GSueWnFD' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-496b5ae9-d2c5-4f15-b339-59f010a6bf89', choices=[Choice(delta=ChoiceDelta(content='äººç¾¤', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,810 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-496b5ae9-d2c5-4f15-b339-59f010a6bf89', choices=[Choice(delta=ChoiceDelta(content='äººç¾¤', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='äººç¾¤', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,812 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='äººç¾¤', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-496b5ae9-d2c5-4f15-b339-59f010a6bf89', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='äººç¾¤', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,812 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-496b5ae9-d2c5-4f15-b339-59f010a6bf89', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='äººç¾¤', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,813 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='äººç¾¤'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='O9KE7m79' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-916aa47f-1614-4f2f-831f-79097035ae47', choices=[Choice(delta=ChoiceDelta(content='çš„é£é™©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,814 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-916aa47f-1614-4f2f-831f-79097035ae47', choices=[Choice(delta=ChoiceDelta(content='çš„é£é™©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='çš„é£é™©', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,816 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='çš„é£é™©', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-916aa47f-1614-4f2f-831f-79097035ae47', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='çš„é£é™©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,816 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-916aa47f-1614-4f2f-831f-79097035ae47', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='çš„é£é™©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,817 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='çš„é£é™©'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='Zc74hoX5' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c70c431a-62e7-4de5-864d-e053c8b857c4', choices=[Choice(delta=ChoiceDelta(content='è¯„ä¼°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,817 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c70c431a-62e7-4de5-864d-e053c8b857c4', choices=[Choice(delta=ChoiceDelta(content='è¯„ä¼°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450952, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¯„ä¼°', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,819 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¯„ä¼°', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c70c431a-62e7-4de5-864d-e053c8b857c4', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¯„ä¼°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,819 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c70c431a-62e7-4de5-864d-e053c8b857c4', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¯„ä¼°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,820 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¯„ä¼°'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='YA8NtIOV' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c626bf0c-7e9b-49f5-a8af-c47594181be7', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,858 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c626bf0c-7e9b-49f5-a8af-c47594181be7', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,859 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c626bf0c-7e9b-49f5-a8af-c47594181be7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,859 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c626bf0c-7e9b-49f5-a8af-c47594181be7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,860 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='f7qdOYMU' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-81ef8c16-3908-4376-b1d3-6a42143b66a9', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,861 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-81ef8c16-3908-4376-b1d3-6a42143b66a9', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,862 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-81ef8c16-3908-4376-b1d3-6a42143b66a9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,862 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-81ef8c16-3908-4376-b1d3-6a42143b66a9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,863 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='NNkm7808' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b30afca1-f9a4-4b85-88f3-3ac0f36a6fed', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,902 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b30afca1-f9a4-4b85-88f3-3ac0f36a6fed', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,903 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b30afca1-f9a4-4b85-88f3-3ac0f36a6fed', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,903 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b30afca1-f9a4-4b85-88f3-3ac0f36a6fed', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,904 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='nQcCrGTo' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e1283601-d733-4700-92b0-51befcf179af', choices=[Choice(delta=ChoiceDelta(content='5', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,904 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e1283601-d733-4700-92b0-51befcf179af', choices=[Choice(delta=ChoiceDelta(content='5', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='5', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,906 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='5', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e1283601-d733-4700-92b0-51befcf179af', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='5', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,906 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e1283601-d733-4700-92b0-51befcf179af', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='5', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,907 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='5'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='vGob1yMF' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a55e378d-c27a-40af-ae60-134ba3a07acc', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,948 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a55e378d-c27a-40af-ae60-134ba3a07acc', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,950 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a55e378d-c27a-40af-ae60-134ba3a07acc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,950 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a55e378d-c27a-40af-ae60-134ba3a07acc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,951 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='vOZWcrSK' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c5f81291-139c-439f-9ce8-2e4c1ef659db', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,952 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c5f81291-139c-439f-9ce8-2e4c1ef659db', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:17,953 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c5f81291-139c-439f-9ce8-2e4c1ef659db', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,953 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c5f81291-139c-439f-9ce8-2e4c1ef659db', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:17,954 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='3'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='2QULzy5m' timestamp=1763450949.457893
[92m15:29:17 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-197076ec-845c-415d-986b-3569ba16bf57', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:17,999 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-197076ec-845c-415d-986b-3569ba16bf57', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,000 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-197076ec-845c-415d-986b-3569ba16bf57', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,000 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-197076ec-845c-415d-986b-3569ba16bf57', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d80589e4-69ac-4a4d-8b23-50e2b940a51c', choices=[Choice(delta=ChoiceDelta(content=' å®‰', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,001 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d80589e4-69ac-4a4d-8b23-50e2b940a51c', choices=[Choice(delta=ChoiceDelta(content=' å®‰', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' å®‰', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,002 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' å®‰', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d80589e4-69ac-4a4d-8b23-50e2b940a51c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' å®‰', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,002 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d80589e4-69ac-4a4d-8b23-50e2b940a51c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' å®‰', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,003 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' å®‰'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='YljoTk65' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-08718e5c-1616-4741-9846-35936338daf5', choices=[Choice(delta=ChoiceDelta(content='å…¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,003 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-08718e5c-1616-4741-9846-35936338daf5', choices=[Choice(delta=ChoiceDelta(content='å…¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å…¨', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,004 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å…¨', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-08718e5c-1616-4741-9846-35936338daf5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å…¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,004 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-08718e5c-1616-4741-9846-35936338daf5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å…¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,006 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å…¨'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='iFdn9r6B' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-da0d148a-8e3a-4b2c-ae72-554743e4ff72', choices=[Choice(delta=ChoiceDelta(content='æ€§', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,044 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-da0d148a-8e3a-4b2c-ae72-554743e4ff72', choices=[Choice(delta=ChoiceDelta(content='æ€§', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ€§', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,045 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ€§', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-da0d148a-8e3a-4b2c-ae72-554743e4ff72', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ€§', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,045 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-da0d148a-8e3a-4b2c-ae72-554743e4ff72', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ€§', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,045 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ€§'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='9In0GtB4' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-47ded2d7-08b0-4ad0-937e-f4f771131a25', choices=[Choice(delta=ChoiceDelta(content='æ•°æ®', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,046 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-47ded2d7-08b0-4ad0-937e-f4f771131a25', choices=[Choice(delta=ChoiceDelta(content='æ•°æ®', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ•°æ®', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,048 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ•°æ®', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-47ded2d7-08b0-4ad0-937e-f4f771131a25', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ•°æ®', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,048 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-47ded2d7-08b0-4ad0-937e-f4f771131a25', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ•°æ®', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,049 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ•°æ®'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='6UpnBAu4' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5511ad8c-ba49-4ff0-bc26-8c92dbacef14', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,090 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5511ad8c-ba49-4ff0-bc26-8c92dbacef14', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,091 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5511ad8c-ba49-4ff0-bc26-8c92dbacef14', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,091 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5511ad8c-ba49-4ff0-bc26-8c92dbacef14', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,092 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='1Ag8VUeB' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c6bde4fc-e754-42ea-82e2-8ee178455358', choices=[Choice(delta=ChoiceDelta(content='ä¸´åºŠ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,093 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c6bde4fc-e754-42ea-82e2-8ee178455358', choices=[Choice(delta=ChoiceDelta(content='ä¸´åºŠ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,095 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c6bde4fc-e754-42ea-82e2-8ee178455358', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,095 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c6bde4fc-e754-42ea-82e2-8ee178455358', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,096 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸´åºŠ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='gAOpmTup' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8b5d7b97-e6ae-411b-b5fd-744834c54ba2', choices=[Choice(delta=ChoiceDelta(content='ç›‘æµ‹', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,139 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8b5d7b97-e6ae-411b-b5fd-744834c54ba2', choices=[Choice(delta=ChoiceDelta(content='ç›‘æµ‹', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç›‘æµ‹', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,141 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç›‘æµ‹', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8b5d7b97-e6ae-411b-b5fd-744834c54ba2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç›‘æµ‹', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,141 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8b5d7b97-e6ae-411b-b5fd-744834c54ba2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç›‘æµ‹', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,142 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç›‘æµ‹'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='YomyY5P6' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-688b9ba8-35dc-4b77-b8ce-eb161a778d01', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,143 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-688b9ba8-35dc-4b77-b8ce-eb161a778d01', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,144 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-688b9ba8-35dc-4b77-b8ce-eb161a778d01', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,145 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-688b9ba8-35dc-4b77-b8ce-eb161a778d01', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,145 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""

"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='y1HFfmXW' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4be02f22-be01-4e2a-957e-7ba5eb0fd522', choices=[Choice(delta=ChoiceDelta(content='##', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,146 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4be02f22-be01-4e2a-957e-7ba5eb0fd522', choices=[Choice(delta=ChoiceDelta(content='##', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,148 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4be02f22-be01-4e2a-957e-7ba5eb0fd522', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,148 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4be02f22-be01-4e2a-957e-7ba5eb0fd522', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,149 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='##'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='V73VCS6j' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d38b460c-87f5-4003-b7a8-2512dc26f15f', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,185 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d38b460c-87f5-4003-b7a8-2512dc26f15f', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,187 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d38b460c-87f5-4003-b7a8-2512dc26f15f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,187 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d38b460c-87f5-4003-b7a8-2512dc26f15f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,188 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='SdC4c3BX' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-572d6555-149a-4428-ab04-ccf2ce3bf189', choices=[Choice(delta=ChoiceDelta(content='6', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,189 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-572d6555-149a-4428-ab04-ccf2ce3bf189', choices=[Choice(delta=ChoiceDelta(content='6', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='6', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,190 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='6', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-572d6555-149a-4428-ab04-ccf2ce3bf189', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='6', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,190 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-572d6555-149a-4428-ab04-ccf2ce3bf189', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='6', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,191 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='6'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='VBqOT70d' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f4190225-ab6d-41f3-958f-8ddb89c11d83', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,233 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f4190225-ab6d-41f3-958f-8ddb89c11d83', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,233 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f4190225-ab6d-41f3-958f-8ddb89c11d83', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,233 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f4190225-ab6d-41f3-958f-8ddb89c11d83', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,235 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='rWhD2MTo' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d0998fdb-15d1-4dab-9790-4958e0809e0f', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,235 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d0998fdb-15d1-4dab-9790-4958e0809e0f', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,237 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d0998fdb-15d1-4dab-9790-4958e0809e0f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,237 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d0998fdb-15d1-4dab-9790-4958e0809e0f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a5d77e68-c36d-471e-9c84-f6dc5c323c8c', choices=[Choice(delta=ChoiceDelta(content=' åˆ¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,276 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a5d77e68-c36d-471e-9c84-f6dc5c323c8c', choices=[Choice(delta=ChoiceDelta(content=' åˆ¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' åˆ¶', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,278 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' åˆ¶', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a5d77e68-c36d-471e-9c84-f6dc5c323c8c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' åˆ¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,278 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a5d77e68-c36d-471e-9c84-f6dc5c323c8c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' åˆ¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,279 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' åˆ¶'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='SleYvm7u' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8a57c9ee-7fbc-46f2-b615-c69be405b9ed', choices=[Choice(delta=ChoiceDelta(content='å¤‡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,280 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8a57c9ee-7fbc-46f2-b615-c69be405b9ed', choices=[Choice(delta=ChoiceDelta(content='å¤‡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å¤‡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,281 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å¤‡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8a57c9ee-7fbc-46f2-b615-c69be405b9ed', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å¤‡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,281 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8a57c9ee-7fbc-46f2-b615-c69be405b9ed', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å¤‡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,282 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å¤‡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='T2f8VNyM' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-70da7e5a-801c-4987-a1e6-9415c02b3a5c', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,323 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-70da7e5a-801c-4987-a1e6-9415c02b3a5c', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,325 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-70da7e5a-801c-4987-a1e6-9415c02b3a5c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,325 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-70da7e5a-801c-4987-a1e6-9415c02b3a5c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,326 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='kmwzqWCy' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-30246581-9da0-43e0-b877-19ddcf52508b', choices=[Choice(delta=ChoiceDelta(content='æ ‡å‡†åŒ–', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,327 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-30246581-9da0-43e0-b877-19ddcf52508b', choices=[Choice(delta=ChoiceDelta(content='æ ‡å‡†åŒ–', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ ‡å‡†åŒ–', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,328 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ ‡å‡†åŒ–', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-30246581-9da0-43e0-b877-19ddcf52508b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ ‡å‡†åŒ–', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,328 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-30246581-9da0-43e0-b877-19ddcf52508b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ ‡å‡†åŒ–', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,329 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ ‡å‡†åŒ–'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='CLHIPa8s' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d87b6e3e-32cf-454d-93b2-aef3471adf57', choices=[Choice(delta=ChoiceDelta(content='æŒ‘æˆ˜', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,370 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d87b6e3e-32cf-454d-93b2-aef3471adf57', choices=[Choice(delta=ChoiceDelta(content='æŒ‘æˆ˜', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æŒ‘æˆ˜', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,372 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æŒ‘æˆ˜', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d87b6e3e-32cf-454d-93b2-aef3471adf57', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æŒ‘æˆ˜', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,372 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d87b6e3e-32cf-454d-93b2-aef3471adf57', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æŒ‘æˆ˜', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,373 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æŒ‘æˆ˜'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='jvIWMamo' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-670d00e0-d1f2-4360-aab4-a7c1559c64de', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,374 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-670d00e0-d1f2-4360-aab4-a7c1559c64de', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,376 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-670d00e0-d1f2-4360-aab4-a7c1559c64de', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,376 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-670d00e0-d1f2-4360-aab4-a7c1559c64de', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,377 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='XMF8lUUZ' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b27d2728-b85a-4842-bc1f-23e906138466', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,377 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b27d2728-b85a-4842-bc1f-23e906138466', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,378 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b27d2728-b85a-4842-bc1f-23e906138466', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,379 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b27d2728-b85a-4842-bc1f-23e906138466', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,379 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='zCnJxEAd' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9f9327c4-3506-409e-aabe-09668738e87e', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,419 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9f9327c4-3506-409e-aabe-09668738e87e', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,420 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9f9327c4-3506-409e-aabe-09668738e87e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,420 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9f9327c4-3506-409e-aabe-09668738e87e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,421 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='Rl1Mdeug' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1eace175-489e-49b7-99e9-5c8e07c68113', choices=[Choice(delta=ChoiceDelta(content='6', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,423 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1eace175-489e-49b7-99e9-5c8e07c68113', choices=[Choice(delta=ChoiceDelta(content='6', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='6', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,424 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='6', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1eace175-489e-49b7-99e9-5c8e07c68113', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='6', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,424 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1eace175-489e-49b7-99e9-5c8e07c68113', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='6', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,425 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='6'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='z39rHETw' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ae13da41-3ab3-4015-adf5-ffb94534d415', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,464 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ae13da41-3ab3-4015-adf5-ffb94534d415', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,466 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ae13da41-3ab3-4015-adf5-ffb94534d415', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,466 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ae13da41-3ab3-4015-adf5-ffb94534d415', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,467 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='XGZG4F3e' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d5a3b13c-177c-440e-90e0-012f12106dd1', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,468 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d5a3b13c-177c-440e-90e0-012f12106dd1', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,469 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d5a3b13c-177c-440e-90e0-012f12106dd1', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,469 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d5a3b13c-177c-440e-90e0-012f12106dd1', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,470 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='1'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='7ZMsW4Wp' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1e8db50f-25ee-48eb-a905-caa41af6ea5a', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,511 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1e8db50f-25ee-48eb-a905-caa41af6ea5a', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,512 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1e8db50f-25ee-48eb-a905-caa41af6ea5a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,513 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1e8db50f-25ee-48eb-a905-caa41af6ea5a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-26adc471-d792-402d-9421-d8116a3c99b9', choices=[Choice(delta=ChoiceDelta(content=' åˆ¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,514 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-26adc471-d792-402d-9421-d8116a3c99b9', choices=[Choice(delta=ChoiceDelta(content=' åˆ¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' åˆ¶', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,514 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' åˆ¶', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-26adc471-d792-402d-9421-d8116a3c99b9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' åˆ¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,514 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-26adc471-d792-402d-9421-d8116a3c99b9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' åˆ¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,516 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' åˆ¶'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='bu8VUpkM' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c315cc7d-2312-4c06-88aa-03c615370f6d', choices=[Choice(delta=ChoiceDelta(content='å¤‡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,559 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c315cc7d-2312-4c06-88aa-03c615370f6d', choices=[Choice(delta=ChoiceDelta(content='å¤‡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å¤‡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,561 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å¤‡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c315cc7d-2312-4c06-88aa-03c615370f6d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å¤‡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,561 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c315cc7d-2312-4c06-88aa-03c615370f6d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å¤‡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,562 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å¤‡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='VeT5Iwzf' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c42acabb-84f2-4bdf-85e8-b18e06516c4e', choices=[Choice(delta=ChoiceDelta(content='å·¥è‰º', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,562 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c42acabb-84f2-4bdf-85e8-b18e06516c4e', choices=[Choice(delta=ChoiceDelta(content='å·¥è‰º', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å·¥è‰º', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,564 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å·¥è‰º', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c42acabb-84f2-4bdf-85e8-b18e06516c4e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å·¥è‰º', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,564 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c42acabb-84f2-4bdf-85e8-b18e06516c4e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å·¥è‰º', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æœŸ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æœŸ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='é•¿æœŸ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: é•¿æœŸ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å‰¯ä½œç”¨'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å‰¯ä½œç”¨
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='5'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 5
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='2'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 2
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' ç‰¹'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  ç‰¹
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ®Š'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ®Š
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='äººç¾¤'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: äººç¾¤
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='çš„é£é™©'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: çš„é£é™©
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¯„ä¼°'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¯„ä¼°
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='5'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 5
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='3'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 3
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' å®‰'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  å®‰
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å…¨'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å…¨
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ€§'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ€§
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ•°æ®'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ•°æ®
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸´åºŠ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸´åºŠ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç›‘æµ‹'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç›‘æµ‹
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""

"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 


è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='##'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ##
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='6'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 6
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' åˆ¶'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  åˆ¶
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å¤‡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å¤‡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ ‡å‡†åŒ–'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ ‡å‡†åŒ–
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æŒ‘æˆ˜'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æŒ‘æˆ˜
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='6'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 6
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='1'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 1
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' åˆ¶'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  åˆ¶
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å¤‡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å¤‡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å·¥è‰º'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å·¥è‰º2025-11-18 15:29:18,564 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å·¥è‰º'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='s7m8c1F6' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5a06d07c-6e6e-4b27-9b1d-8a9bae1d41c2', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,566 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5a06d07c-6e6e-4b27-9b1d-8a9bae1d41c2', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,567 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5a06d07c-6e6e-4b27-9b1d-8a9bae1d41c2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,567 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5a06d07c-6e6e-4b27-9b1d-8a9bae1d41c2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,567 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='Bh10JF1u' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d33e6eae-e7cb-4ae2-a4c5-cf3da0b007a7', choices=[Choice(delta=ChoiceDelta(content='è´¨é‡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,604 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d33e6eae-e7cb-4ae2-a4c5-cf3da0b007a7', choices=[Choice(delta=ChoiceDelta(content='è´¨é‡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è´¨é‡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,606 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è´¨é‡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d33e6eae-e7cb-4ae2-a4c5-cf3da0b007a7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è´¨é‡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,606 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d33e6eae-e7cb-4ae2-a4c5-cf3da0b007a7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è´¨é‡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,607 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è´¨é‡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='ByQAGLct' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-40a7b877-c35d-40bc-8f4b-c78c56dc79f0', choices=[Choice(delta=ChoiceDelta(content='æ§åˆ¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,608 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-40a7b877-c35d-40bc-8f4b-c78c56dc79f0', choices=[Choice(delta=ChoiceDelta(content='æ§åˆ¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ§åˆ¶', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,609 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ§åˆ¶', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-40a7b877-c35d-40bc-8f4b-c78c56dc79f0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ§åˆ¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,609 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-40a7b877-c35d-40bc-8f4b-c78c56dc79f0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ§åˆ¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,610 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ§åˆ¶'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='sVlOGFu6' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-36bd6926-276d-4135-be2a-c958764b6c57', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,650 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-36bd6926-276d-4135-be2a-c958764b6c57', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,651 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-36bd6926-276d-4135-be2a-c958764b6c57', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,652 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-36bd6926-276d-4135-be2a-c958764b6c57', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,653 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='EEKF92T2' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-afe531db-638a-4608-bcaf-5b7672d85c42', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,653 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-afe531db-638a-4608-bcaf-5b7672d85c42', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,654 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-afe531db-638a-4608-bcaf-5b7672d85c42', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,654 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-afe531db-638a-4608-bcaf-5b7672d85c42', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,655 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='GG14GKNm' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d016fe2e-f0bc-4a01-a4b5-4eba2fe1ae1c', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,697 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d016fe2e-f0bc-4a01-a4b5-4eba2fe1ae1c', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,698 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d016fe2e-f0bc-4a01-a4b5-4eba2fe1ae1c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,699 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d016fe2e-f0bc-4a01-a4b5-4eba2fe1ae1c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,699 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='89MPyoVd' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6e4fa179-840f-47fc-8640-1890fc968cf2', choices=[Choice(delta=ChoiceDelta(content='6', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,700 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6e4fa179-840f-47fc-8640-1890fc968cf2', choices=[Choice(delta=ChoiceDelta(content='6', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='6', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,701 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='6', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6e4fa179-840f-47fc-8640-1890fc968cf2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='6', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,701 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6e4fa179-840f-47fc-8640-1890fc968cf2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='6', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,702 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='6'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='4vCezez5' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7d186f1a-0293-4117-8c91-2864cdedcfde', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,744 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7d186f1a-0293-4117-8c91-2864cdedcfde', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,745 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7d186f1a-0293-4117-8c91-2864cdedcfde', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,745 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7d186f1a-0293-4117-8c91-2864cdedcfde', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,745 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='gAPmF3uK' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c10c214e-2478-4cb6-82a4-62e628a164fd', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,746 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c10c214e-2478-4cb6-82a4-62e628a164fd', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,747 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c10c214e-2478-4cb6-82a4-62e628a164fd', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,747 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c10c214e-2478-4cb6-82a4-62e628a164fd', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,748 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='2'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='uG0vz1Lg' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-23cf89db-9cb2-4d3e-9e6b-576e08b052d8', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,789 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-23cf89db-9cb2-4d3e-9e6b-576e08b052d8', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,791 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-23cf89db-9cb2-4d3e-9e6b-576e08b052d8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,791 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-23cf89db-9cb2-4d3e-9e6b-576e08b052d8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-2b8b5471-d80b-4f00-b690-9f2c2c5a47d4', choices=[Choice(delta=ChoiceDelta(content=' å®‰', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,792 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-2b8b5471-d80b-4f00-b690-9f2c2c5a47d4', choices=[Choice(delta=ChoiceDelta(content=' å®‰', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' å®‰', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,793 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' å®‰', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-2b8b5471-d80b-4f00-b690-9f2c2c5a47d4', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' å®‰', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,794 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-2b8b5471-d80b-4f00-b690-9f2c2c5a47d4', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' å®‰', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,794 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' å®‰'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='69cfAv27' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7b7894b8-2f58-418e-8853-581230ff0819', choices=[Choice(delta=ChoiceDelta(content='å…¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,796 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7b7894b8-2f58-418e-8853-581230ff0819', choices=[Choice(delta=ChoiceDelta(content='å…¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å…¨', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,797 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å…¨', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7b7894b8-2f58-418e-8853-581230ff0819', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å…¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,797 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7b7894b8-2f58-418e-8853-581230ff0819', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å…¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,798 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å…¨'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='i3LDOEdY' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c3ca7680-7145-424d-b427-189d7ff7c65e', choices=[Choice(delta=ChoiceDelta(content='æ ‡å‡†', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,836 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c3ca7680-7145-424d-b427-189d7ff7c65e', choices=[Choice(delta=ChoiceDelta(content='æ ‡å‡†', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450953, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ ‡å‡†', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,838 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ ‡å‡†', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c3ca7680-7145-424d-b427-189d7ff7c65e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ ‡å‡†', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,838 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c3ca7680-7145-424d-b427-189d7ff7c65e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ ‡å‡†', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,839 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ ‡å‡†'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='Fynq98iZ' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8a23fead-b89b-4ca1-a2aa-328628183925', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,839 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8a23fead-b89b-4ca1-a2aa-328628183925', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,841 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8a23fead-b89b-4ca1-a2aa-328628183925', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,841 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8a23fead-b89b-4ca1-a2aa-328628183925', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,842 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='BuYMz6EM' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-97ee9a1e-c2b0-4a8a-8b1e-5841601380a6', choices=[Choice(delta=ChoiceDelta(content='ç›‘ç®¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,885 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-97ee9a1e-c2b0-4a8a-8b1e-5841601380a6', choices=[Choice(delta=ChoiceDelta(content='ç›‘ç®¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç›‘ç®¡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,886 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç›‘ç®¡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-97ee9a1e-c2b0-4a8a-8b1e-5841601380a6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç›‘ç®¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,886 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-97ee9a1e-c2b0-4a8a-8b1e-5841601380a6', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç›‘ç®¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,887 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç›‘ç®¡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='UZkNmAjk' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-26857826-7dac-4781-8c17-7433c47c6942', choices=[Choice(delta=ChoiceDelta(content='è¦æ±‚', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,888 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-26857826-7dac-4781-8c17-7433c47c6942', choices=[Choice(delta=ChoiceDelta(content='è¦æ±‚', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¦æ±‚', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,889 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¦æ±‚', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-26857826-7dac-4781-8c17-7433c47c6942', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¦æ±‚', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,890 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-26857826-7dac-4781-8c17-7433c47c6942', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¦æ±‚', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,890 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¦æ±‚'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='UiQpwIrq' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-78a36a30-0279-46f6-8fd3-396926ee212d', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,931 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-78a36a30-0279-46f6-8fd3-396926ee212d', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,933 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-78a36a30-0279-46f6-8fd3-396926ee212d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,933 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-78a36a30-0279-46f6-8fd3-396926ee212d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,934 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='y7M7vpI1' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-98d2cd04-7e25-4471-85c2-875cf0973753', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,934 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-98d2cd04-7e25-4471-85c2-875cf0973753', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,935 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-98d2cd04-7e25-4471-85c2-875cf0973753', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,935 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-98d2cd04-7e25-4471-85c2-875cf0973753', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,936 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='M41DMUHo' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-aa7d17ad-ba82-47a5-860c-105a2364749d', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,979 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-aa7d17ad-ba82-47a5-860c-105a2364749d', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,980 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-aa7d17ad-ba82-47a5-860c-105a2364749d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,981 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-aa7d17ad-ba82-47a5-860c-105a2364749d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,982 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='ZRPyzgIN' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0a5ef992-71f9-4499-bc6d-357d203dec8a', choices=[Choice(delta=ChoiceDelta(content='6', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,983 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0a5ef992-71f9-4499-bc6d-357d203dec8a', choices=[Choice(delta=ChoiceDelta(content='6', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='6', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,984 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='6', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0a5ef992-71f9-4499-bc6d-357d203dec8a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='6', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,984 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0a5ef992-71f9-4499-bc6d-357d203dec8a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='6', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,986 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='6'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='KxCZ38cE' timestamp=1763450949.457893
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3df98373-4bf7-4eee-abd4-9f6fa85086b5', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:18,986 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3df98373-4bf7-4eee-abd4-9f6fa85086b5', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:18,987 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:18 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3df98373-4bf7-4eee-abd4-9f6fa85086b5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,987 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3df98373-4bf7-4eee-abd4-9f6fa85086b5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:18,988 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='ngNcFTtG' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a581764e-35ab-42f4-a924-cae3cba9bbad', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,026 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a581764e-35ab-42f4-a924-cae3cba9bbad', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,028 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a581764e-35ab-42f4-a924-cae3cba9bbad', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,028 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a581764e-35ab-42f4-a924-cae3cba9bbad', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,029 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='3'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='XSxAO3AM' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ddc1bd02-2d34-4cef-9b1f-e79a0b43a347', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,030 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ddc1bd02-2d34-4cef-9b1f-e79a0b43a347', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,031 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ddc1bd02-2d34-4cef-9b1f-e79a0b43a347', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,032 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ddc1bd02-2d34-4cef-9b1f-e79a0b43a347', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-62af0f48-3f2d-463e-af6b-e3fd851343c3', choices=[Choice(delta=ChoiceDelta(content=' è¡Œ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,072 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-62af0f48-3f2d-463e-af6b-e3fd851343c3', choices=[Choice(delta=ChoiceDelta(content=' è¡Œ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' è¡Œ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,073 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' è¡Œ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-62af0f48-3f2d-463e-af6b-e3fd851343c3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' è¡Œ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,074 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-62af0f48-3f2d-463e-af6b-e3fd851343c3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' è¡Œ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,075 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' è¡Œ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='8QyzhzDK' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-06193eaa-fb18-49ec-9ee8-8f2e1c1e1a56', choices=[Choice(delta=ChoiceDelta(content='ä¸š', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,076 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-06193eaa-fb18-49ec-9ee8-8f2e1c1e1a56', choices=[Choice(delta=ChoiceDelta(content='ä¸š', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸š', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,078 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸š', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-06193eaa-fb18-49ec-9ee8-8f2e1c1e1a56', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸š', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,078 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-06193eaa-fb18-49ec-9ee8-8f2e1c1e1a56', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸š', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,079 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸š'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='GZepvgoh' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b368ab6a-d1d5-41fd-8410-a8508cca1b1d', choices=[Choice(delta=ChoiceDelta(content='æ ‡å‡†åŒ–', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,119 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b368ab6a-d1d5-41fd-8410-a8508cca1b1d', choices=[Choice(delta=ChoiceDelta(content='æ ‡å‡†åŒ–', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ ‡å‡†åŒ–', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,120 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ ‡å‡†åŒ–', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b368ab6a-d1d5-41fd-8410-a8508cca1b1d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ ‡å‡†åŒ–', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,120 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b368ab6a-d1d5-41fd-8410-a8508cca1b1d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ ‡å‡†åŒ–', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,121 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ ‡å‡†åŒ–'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='RYmwO80i' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e84f1c5f-8d79-421f-949d-b1b262e9bd46', choices=[Choice(delta=ChoiceDelta(content='è¿›å±•', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,122 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e84f1c5f-8d79-421f-949d-b1b262e9bd46', choices=[Choice(delta=ChoiceDelta(content='è¿›å±•', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¿›å±•', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,124 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¿›å±•', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e84f1c5f-8d79-421f-949d-b1b262e9bd46', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¿›å±•', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,124 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e84f1c5f-8d79-421f-949d-b1b262e9bd46', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¿›å±•', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,125 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¿›å±•'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='a09hQPOH' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6a4977b7-befe-4c3d-a826-125961911844', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,164 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6a4977b7-befe-4c3d-a826-125961911844', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,165 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6a4977b7-befe-4c3d-a826-125961911844', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,165 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6a4977b7-befe-4c3d-a826-125961911844', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,166 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='1XWN9v5m' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a85eb1a4-00d9-41a3-a340-6d3120ad69d9', choices=[Choice(delta=ChoiceDelta(content='éšœç¢', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,167 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a85eb1a4-00d9-41a3-a340-6d3120ad69d9', choices=[Choice(delta=ChoiceDelta(content='éšœç¢', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='éšœç¢', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,168 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='éšœç¢', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a85eb1a4-00d9-41a3-a340-6d3120ad69d9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='éšœç¢', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,168 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a85eb1a4-00d9-41a3-a340-6d3120ad69d9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='éšœç¢', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,169 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='éšœç¢'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='P6uI5Eec' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-2c0b1faf-bf8e-4c8d-92c4-eec1b6816a3b', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,209 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-2c0b1faf-bf8e-4c8d-92c4-eec1b6816a3b', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,210 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-2c0b1faf-bf8e-4c8d-92c4-eec1b6816a3b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,210 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-2c0b1faf-bf8e-4c8d-92c4-eec1b6816a3b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,211 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""

"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='EQaoBrt8' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ee1b31f7-bf4b-4a28-a6e2-3274ee32275a', choices=[Choice(delta=ChoiceDelta(content='##', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,212 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ee1b31f7-bf4b-4a28-a6e2-3274ee32275a', choices=[Choice(delta=ChoiceDelta(content='##', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,213 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ee1b31f7-bf4b-4a28-a6e2-3274ee32275a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,213 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ee1b31f7-bf4b-4a28-a6e2-3274ee32275a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,214 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='##'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='nQw1ZLDB' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9f2991ad-29c7-44ad-ac4e-1dd9dfb7efed', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,214 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9f2991ad-29c7-44ad-ac4e-1dd9dfb7efed', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,216 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9f2991ad-29c7-44ad-ac4e-1dd9dfb7efed', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,217 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9f2991ad-29c7-44ad-ac4e-1dd9dfb7efed', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,217 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='UmkYm8GO' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-12fa1ae8-3d76-4424-9d2a-cdcafde58d1a', choices=[Choice(delta=ChoiceDelta(content='7', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,256 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-12fa1ae8-3d76-4424-9d2a-cdcafde58d1a', choices=[Choice(delta=ChoiceDelta(content='7', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='7', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,257 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='7', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-12fa1ae8-3d76-4424-9d2a-cdcafde58d1a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='7', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,257 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-12fa1ae8-3d76-4424-9d2a-cdcafde58d1a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='7', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,258 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='7'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='KoOpdXwR' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5456d70e-7977-4143-81ea-b21c1b124fe7', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,258 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5456d70e-7977-4143-81ea-b21c1b124fe7', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,259 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5456d70e-7977-4143-81ea-b21c1b124fe7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,260 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5456d70e-7977-4143-81ea-b21c1b124fe7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,260 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='zvMtjat1' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5c1210d2-f1cb-4f6a-ab23-b333ff39e01b', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,301 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5c1210d2-f1cb-4f6a-ab23-b333ff39e01b', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,302 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5c1210d2-f1cb-4f6a-ab23-b333ff39e01b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,302 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5c1210d2-f1cb-4f6a-ab23-b333ff39e01b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d5a187cd-2869-4c4d-a60b-d1519b463d5a', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,303 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d5a187cd-2869-4c4d-a60b-d1519b463d5a', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,304 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d5a187cd-2869-4c4d-a60b-d1519b463d5a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,304 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d5a187cd-2869-4c4d-a60b-d1519b463d5a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3b74efcc-199c-491f-bd09-646d17f16d65', choices=[Choice(delta=ChoiceDelta(content=' çœŸ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,346 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3b74efcc-199c-491f-bd09-646d17f16d65', choices=[Choice(delta=ChoiceDelta(content=' çœŸ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' çœŸ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,351 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' çœŸ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3b74efcc-199c-491f-bd09-646d17f16d65', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' çœŸ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,351 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3b74efcc-199c-491f-bd09-646d17f16d65', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' çœŸ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,352 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' çœŸ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='Pkl3MMtc' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-eeef5fd0-eb98-4e72-96eb-cbf45c3267bc', choices=[Choice(delta=ChoiceDelta(content='å®', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,353 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-eeef5fd0-eb98-4e72-96eb-cbf45c3267bc', choices=[Choice(delta=ChoiceDelta(content='å®', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å®', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,354 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å®', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-eeef5fd0-eb98-4e72-96eb-cbf45c3267bc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å®', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,354 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-eeef5fd0-eb98-4e72-96eb-cbf45c3267bc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å®', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,355 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å®'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='2HX6qImt' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d83a39e5-96f5-4cd9-a650-81f46cbdc84f', choices=[Choice(delta=ChoiceDelta(content='ä¸–ç•Œ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,392 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d83a39e5-96f5-4cd9-a650-81f46cbdc84f', choices=[Choice(delta=ChoiceDelta(content='ä¸–ç•Œ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸–ç•Œ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,394 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸–ç•Œ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d83a39e5-96f5-4cd9-a650-81f46cbdc84f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸–ç•Œ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,394 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d83a39e5-96f5-4cd9-a650-81f46cbdc84f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸–ç•Œ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,397 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸–ç•Œ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='XOwchZhA' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-946dc5c1-a29c-4327-89cc-8188dca8fb95', choices=[Choice(delta=ChoiceDelta(content='è¯æ®', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,399 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-946dc5c1-a29c-4327-89cc-8188dca8fb95', choices=[Choice(delta=ChoiceDelta(content='è¯æ®', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¯æ®', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,403 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¯æ®', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-946dc5c1-a29c-4327-89cc-8188dca8fb95', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¯æ®', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,403 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-946dc5c1-a29c-4327-89cc-8188dca8fb95', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¯æ®', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,406 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¯æ®'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='QPnDHo8f' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-79b29ee6-3a90-4d83-b7ed-a3809a907bed', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,439 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-79b29ee6-3a90-4d83-b7ed-a3809a907bed', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,440 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-79b29ee6-3a90-4d83-b7ed-a3809a907bed', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,441 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-79b29ee6-3a90-4d83-b7ed-a3809a907bed', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,442 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='eeecYxJn' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-fb7bc0de-1f9e-4610-996f-3d77965537c3', choices=[Choice(delta=ChoiceDelta(content='ç°åœº', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,443 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-fb7bc0de-1f9e-4610-996f-3d77965537c3', choices=[Choice(delta=ChoiceDelta(content='ç°åœº', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç°åœº', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,444 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç°åœº', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-fb7bc0de-1f9e-4610-996f-3d77965537c3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç°åœº', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,444 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-fb7bc0de-1f9e-4610-996f-3d77965537c3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç°åœº', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,445 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç°åœº'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='GbHhsiVb' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a4536976-e817-4eba-b95a-4c3ba40fa7d3', choices=[Choice(delta=ChoiceDelta(content='å®è·µ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,446 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a4536976-e817-4eba-b95a-4c3ba40fa7d3', choices=[Choice(delta=ChoiceDelta(content='å®è·µ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å®è·µ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,447 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å®è·µ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a4536976-e817-4eba-b95a-4c3ba40fa7d3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å®è·µ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,448 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a4536976-e817-4eba-b95a-4c3ba40fa7d3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å®è·µ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,448 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å®è·µ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='NvHPwLMZ' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1a12b95c-5c29-429b-8177-2e7433d77fdc', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,486 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1a12b95c-5c29-429b-8177-2e7433d77fdc', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,486 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1a12b95c-5c29-429b-8177-2e7433d77fdc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,487 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1a12b95c-5c29-429b-8177-2e7433d77fdc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,487 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='pgD5b6iP' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6fb869db-3cfb-4647-b56f-39e14162674c', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,488 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6fb869db-3cfb-4647-b56f-39e14162674c', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,490 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6fb869db-3cfb-4647-b56f-39e14162674c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,490 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6fb869db-3cfb-4647-b56f-39e14162674c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,491 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='sQstVN2n' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f5b128ae-69da-4353-99f0-4ef1cd2b9c14', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,532 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f5b128ae-69da-4353-99f0-4ef1cd2b9c14', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,534 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f5b128ae-69da-4353-99f0-4ef1cd2b9c14', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,534 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f5b128ae-69da-4353-99f0-4ef1cd2b9c14', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,535 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='4eoonM28' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c63896b7-46f1-4d3f-a29d-6c9fe48a10fc', choices=[Choice(delta=ChoiceDelta(content='7', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,536 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c63896b7-46f1-4d3f-a29d-6c9fe48a10fc', choices=[Choice(delta=ChoiceDelta(content='7', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='7', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,537 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='7', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c63896b7-46f1-4d3f-a29d-6c9fe48a10fc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='7', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,537 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c63896b7-46f1-4d3f-a29d-6c9fe48a10fc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='7', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,538 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='7'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='ofSNIdWk' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-50b8edfd-58ba-4eea-9aaa-d11ec3a2f078', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,579 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-50b8edfd-58ba-4eea-9aaa-d11ec3a2f078', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,580 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-50b8edfd-58ba-4eea-9aaa-d11ec3a2f078', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,581 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-50b8edfd-58ba-4eea-9aaa-d11ec3a2f078', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,582 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='YwHv63zy' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-28cccb95-32f8-43cf-8dea-b7ecd877424a', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,582 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-28cccb95-32f8-43cf-8dea-b7ecd877424a', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,584 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-28cccb95-32f8-43cf-8dea-b7ecd877424a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,584 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-28cccb95-32f8-43cf-8dea-b7ecd877424a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,585 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='1'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='eJVStpbj' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ab0b82d3-b98b-4fb3-b610-6a37087f3958', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,624 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ab0b82d3-b98b-4fb3-b610-6a37087f3958', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,627 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ab0b82d3-b98b-4fb3-b610-6a37087f3958', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,627 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ab0b82d3-b98b-4fb3-b610-6a37087f3958', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c225f030-87cb-40fa-867e-5a407395fdea', choices=[Choice(delta=ChoiceDelta(content=' åŒ»', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,628 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c225f030-87cb-40fa-867e-5a407395fdea', choices=[Choice(delta=ChoiceDelta(content=' åŒ»', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' åŒ»', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,629 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' åŒ»', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c225f030-87cb-40fa-867e-5a407395fdea', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' åŒ»', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,629 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c225f030-87cb-40fa-867e-5a407395fdea', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' åŒ»', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,631 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' åŒ»'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='YNYno6MC' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-cdded09d-efc2-40df-95b2-797050fa712c', choices=[Choice(delta=ChoiceDelta(content='é™¢', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,632 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-cdded09d-efc2-40df-95b2-797050fa712c', choices=[Choice(delta=ChoiceDelta(content='é™¢', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='é™¢', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,633 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='é™¢', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-cdded09d-efc2-40df-95b2-797050fa712c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='é™¢', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,633 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-cdded09d-efc2-40df-95b2-797050fa712c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='é™¢', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è´¨é‡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è´¨é‡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ§åˆ¶'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ§åˆ¶
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='6'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 6
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='2'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 2
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' å®‰'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  å®‰
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å…¨'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å…¨
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ ‡å‡†'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ ‡å‡†
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç›‘ç®¡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç›‘ç®¡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¦æ±‚'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¦æ±‚
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='6'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 6
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='3'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 3
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' è¡Œ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  è¡Œ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸š'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸š
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ ‡å‡†åŒ–'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ ‡å‡†åŒ–
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¿›å±•'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¿›å±•
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='éšœç¢'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: éšœç¢
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""

"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 


è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='##'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ##
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='7'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 7
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' çœŸ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  çœŸ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å®'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å®
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸–ç•Œ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸–ç•Œ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¯æ®'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¯æ®
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç°åœº'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç°åœº
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å®è·µ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å®è·µ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='7'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 7
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='1'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 1
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' åŒ»'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  åŒ»
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='é™¢'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: é™¢2025-11-18 15:29:19,634 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='é™¢'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='09J5i3K4' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3d786a7b-802d-4789-b33c-ac5e72d23981', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,674 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3d786a7b-802d-4789-b33c-ac5e72d23981', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,676 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3d786a7b-802d-4789-b33c-ac5e72d23981', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,676 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3d786a7b-802d-4789-b33c-ac5e72d23981', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,677 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='vAX0j166' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-990aea61-2b2b-4f4d-ab58-910cc1afe9e3', choices=[Choice(delta=ChoiceDelta(content='ç¤¾åŒº', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,678 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-990aea61-2b2b-4f4d-ab58-910cc1afe9e3', choices=[Choice(delta=ChoiceDelta(content='ç¤¾åŒº', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç¤¾åŒº', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,679 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç¤¾åŒº', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-990aea61-2b2b-4f4d-ab58-910cc1afe9e3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç¤¾åŒº', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,679 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-990aea61-2b2b-4f4d-ab58-910cc1afe9e3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç¤¾åŒº', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,680 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç¤¾åŒº'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='Yg22ecp3' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ab843d5a-cdc1-410e-a56a-0ba6d5b05f80', choices=[Choice(delta=ChoiceDelta(content='åº”ç”¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,718 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ab843d5a-cdc1-410e-a56a-0ba6d5b05f80', choices=[Choice(delta=ChoiceDelta(content='åº”ç”¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åº”ç”¨', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,719 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åº”ç”¨', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ab843d5a-cdc1-410e-a56a-0ba6d5b05f80', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åº”ç”¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,720 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ab843d5a-cdc1-410e-a56a-0ba6d5b05f80', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åº”ç”¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,721 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='åº”ç”¨'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='MgM0h8Ti' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-28a2b37a-3373-493c-9b6c-9f40ec68b039', choices=[Choice(delta=ChoiceDelta(content='æ¡ˆä¾‹', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,722 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-28a2b37a-3373-493c-9b6c-9f40ec68b039', choices=[Choice(delta=ChoiceDelta(content='æ¡ˆä¾‹', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ¡ˆä¾‹', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,723 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ¡ˆä¾‹', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-28a2b37a-3373-493c-9b6c-9f40ec68b039', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ¡ˆä¾‹', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,723 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-28a2b37a-3373-493c-9b6c-9f40ec68b039', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ¡ˆä¾‹', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,724 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ¡ˆä¾‹'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='I0iZojmP' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-639954d9-9c62-4e3a-9503-f8adc00f6007', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,765 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-639954d9-9c62-4e3a-9503-f8adc00f6007', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,767 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-639954d9-9c62-4e3a-9503-f8adc00f6007', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,767 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-639954d9-9c62-4e3a-9503-f8adc00f6007', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,768 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='bLNDgeRT' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6cd4155d-b482-4c06-8960-d4c9f368e486', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,768 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6cd4155d-b482-4c06-8960-d4c9f368e486', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,770 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6cd4155d-b482-4c06-8960-d4c9f368e486', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,770 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6cd4155d-b482-4c06-8960-d4c9f368e486', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,771 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='7BZVWzNE' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-63aa4f7c-869f-44e5-b90b-2d458fa13b6a', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,811 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-63aa4f7c-869f-44e5-b90b-2d458fa13b6a', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,812 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-63aa4f7c-869f-44e5-b90b-2d458fa13b6a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,813 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-63aa4f7c-869f-44e5-b90b-2d458fa13b6a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,814 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='bKP2Ktt5' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-09a9dcc8-0285-486e-8adc-74f50d5db99b', choices=[Choice(delta=ChoiceDelta(content='7', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,815 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-09a9dcc8-0285-486e-8adc-74f50d5db99b', choices=[Choice(delta=ChoiceDelta(content='7', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450954, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='7', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,817 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='7', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-09a9dcc8-0285-486e-8adc-74f50d5db99b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='7', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,817 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-09a9dcc8-0285-486e-8adc-74f50d5db99b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='7', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,817 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='7'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='rdxwRjiv' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d58ab53e-fee5-44b4-b07b-12b66e8a4cd5', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,858 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d58ab53e-fee5-44b4-b07b-12b66e8a4cd5', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,859 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d58ab53e-fee5-44b4-b07b-12b66e8a4cd5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,859 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d58ab53e-fee5-44b4-b07b-12b66e8a4cd5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,861 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='Fjv9bIAZ' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7861cc7a-3107-4a6c-8df8-6e904a176352', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,861 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7861cc7a-3107-4a6c-8df8-6e904a176352', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,862 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7861cc7a-3107-4a6c-8df8-6e904a176352', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,863 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7861cc7a-3107-4a6c-8df8-6e904a176352', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,864 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='2'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='b6BRoZK2' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4789ec5a-4eec-48fa-a01b-447a0cacc4b4', choices=[Choice(delta=ChoiceDelta(content=' æˆ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,864 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4789ec5a-4eec-48fa-a01b-447a0cacc4b4', choices=[Choice(delta=ChoiceDelta(content=' æˆ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' æˆ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,866 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' æˆ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4789ec5a-4eec-48fa-a01b-447a0cacc4b4', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' æˆ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,866 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4789ec5a-4eec-48fa-a01b-447a0cacc4b4', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' æˆ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,867 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' æˆ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='eA6XQXbr' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-93b9089b-abc5-4eab-8296-3de64c1f953b', choices=[Choice(delta=ChoiceDelta(content='æœ¬', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,903 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-93b9089b-abc5-4eab-8296-3de64c1f953b', choices=[Choice(delta=ChoiceDelta(content='æœ¬', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æœ¬', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,904 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æœ¬', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-93b9089b-abc5-4eab-8296-3de64c1f953b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æœ¬', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,904 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-93b9089b-abc5-4eab-8296-3de64c1f953b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æœ¬', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,905 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æœ¬'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='bIfPKhT5' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f7ceae8c-e2b2-4348-948d-6570809c96be', choices=[Choice(delta=ChoiceDelta(content='æ•ˆç›Š', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,905 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f7ceae8c-e2b2-4348-948d-6570809c96be', choices=[Choice(delta=ChoiceDelta(content='æ•ˆç›Š', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ•ˆç›Š', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,908 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ•ˆç›Š', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f7ceae8c-e2b2-4348-948d-6570809c96be', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ•ˆç›Š', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,908 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f7ceae8c-e2b2-4348-948d-6570809c96be', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ•ˆç›Š', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,909 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ•ˆç›Š'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='O4JgWzz3' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b5cd0eb0-408a-43dc-85d8-350770e84b04', choices=[Choice(delta=ChoiceDelta(content='åˆ†æ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,949 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b5cd0eb0-408a-43dc-85d8-350770e84b04', choices=[Choice(delta=ChoiceDelta(content='åˆ†æ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åˆ†æ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,950 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åˆ†æ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b5cd0eb0-408a-43dc-85d8-350770e84b04', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åˆ†æ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,950 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b5cd0eb0-408a-43dc-85d8-350770e84b04', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åˆ†æ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,951 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='åˆ†æ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='r10QzmM4' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9e632d8a-7267-4049-a022-02bc10980c6f', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,952 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9e632d8a-7267-4049-a022-02bc10980c6f', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,953 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9e632d8a-7267-4049-a022-02bc10980c6f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,953 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9e632d8a-7267-4049-a022-02bc10980c6f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,954 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='J5gMTVwy' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-77a54e89-9c18-48dd-97b3-b787467668dc', choices=[Choice(delta=ChoiceDelta(content='ç»æµ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,994 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-77a54e89-9c18-48dd-97b3-b787467668dc', choices=[Choice(delta=ChoiceDelta(content='ç»æµ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç»æµ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:19,997 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç»æµ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-77a54e89-9c18-48dd-97b3-b787467668dc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç»æµ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,997 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-77a54e89-9c18-48dd-97b3-b787467668dc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç»æµ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:19,998 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç»æµ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='yKvqwh6o' timestamp=1763450949.457893
[92m15:29:19 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b4b51e26-1872-4014-9c24-6b9e17fa7fa1', choices=[Choice(delta=ChoiceDelta(content='å½±å“', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:19,999 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b4b51e26-1872-4014-9c24-6b9e17fa7fa1', choices=[Choice(delta=ChoiceDelta(content='å½±å“', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å½±å“', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,000 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å½±å“', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b4b51e26-1872-4014-9c24-6b9e17fa7fa1', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å½±å“', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,000 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b4b51e26-1872-4014-9c24-6b9e17fa7fa1', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å½±å“', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,001 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å½±å“'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='FJSY7UNC' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-311d84bb-d0c0-4128-9aec-4383f6c2ccf5', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,054 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-311d84bb-d0c0-4128-9aec-4383f6c2ccf5', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,056 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-311d84bb-d0c0-4128-9aec-4383f6c2ccf5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,056 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-311d84bb-d0c0-4128-9aec-4383f6c2ccf5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,057 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='VbwPcDvc' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-45aa64fb-b900-4bcc-b630-224d55c93c51', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,058 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-45aa64fb-b900-4bcc-b630-224d55c93c51', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,059 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-45aa64fb-b900-4bcc-b630-224d55c93c51', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,059 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-45aa64fb-b900-4bcc-b630-224d55c93c51', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,060 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='lT7fshCE' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ada65a1e-1429-43d1-8f50-c0557d6ec3bc', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,104 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ada65a1e-1429-43d1-8f50-c0557d6ec3bc', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,106 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ada65a1e-1429-43d1-8f50-c0557d6ec3bc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,107 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ada65a1e-1429-43d1-8f50-c0557d6ec3bc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,108 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='b4cTpNmn' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7b530b46-186b-4a60-bd84-fce70e5efc31', choices=[Choice(delta=ChoiceDelta(content='7', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,108 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7b530b46-186b-4a60-bd84-fce70e5efc31', choices=[Choice(delta=ChoiceDelta(content='7', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='7', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,109 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='7', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7b530b46-186b-4a60-bd84-fce70e5efc31', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='7', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,110 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7b530b46-186b-4a60-bd84-fce70e5efc31', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='7', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,111 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='7'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='NwbfOQ47' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-21344c6f-6cbd-4085-9322-1d9870cd3deb', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,111 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-21344c6f-6cbd-4085-9322-1d9870cd3deb', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,112 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-21344c6f-6cbd-4085-9322-1d9870cd3deb', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,112 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-21344c6f-6cbd-4085-9322-1d9870cd3deb', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,113 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='CcXEe2Y4' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-275c3fd7-f986-4ba5-bc9a-2c44768a2876', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,151 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-275c3fd7-f986-4ba5-bc9a-2c44768a2876', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,153 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-275c3fd7-f986-4ba5-bc9a-2c44768a2876', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,153 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-275c3fd7-f986-4ba5-bc9a-2c44768a2876', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,154 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='3'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='F7gKl9iC' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1b10d04c-51b3-4174-a13c-cfe68f6b3b13', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,155 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1b10d04c-51b3-4174-a13c-cfe68f6b3b13', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,156 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1b10d04c-51b3-4174-a13c-cfe68f6b3b13', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,156 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1b10d04c-51b3-4174-a13c-cfe68f6b3b13', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,157 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='0f5WsU8O' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3207c4d6-9e79-4e60-ac53-b21e370a616e', choices=[Choice(delta=ChoiceDelta(content='ä¸´åºŠ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,158 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3207c4d6-9e79-4e60-ac53-b21e370a616e', choices=[Choice(delta=ChoiceDelta(content='ä¸´åºŠ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,159 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3207c4d6-9e79-4e60-ac53-b21e370a616e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,159 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3207c4d6-9e79-4e60-ac53-b21e370a616e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,160 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸´åºŠ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='WmOMW9yY' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6760cfe1-3049-4004-b7f9-c88c59341466', choices=[Choice(delta=ChoiceDelta(content='å®è·µ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,197 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6760cfe1-3049-4004-b7f9-c88c59341466', choices=[Choice(delta=ChoiceDelta(content='å®è·µ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å®è·µ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,199 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å®è·µ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6760cfe1-3049-4004-b7f9-c88c59341466', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å®è·µ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,199 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6760cfe1-3049-4004-b7f9-c88c59341466', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å®è·µ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,200 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å®è·µ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='gqc3vaXY' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e0a192cf-6219-4708-aa9a-a5013876f1aa', choices=[Choice(delta=ChoiceDelta(content='ä¸­çš„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,201 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e0a192cf-6219-4708-aa9a-a5013876f1aa', choices=[Choice(delta=ChoiceDelta(content='ä¸­çš„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸­çš„', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,202 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸­çš„', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e0a192cf-6219-4708-aa9a-a5013876f1aa', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸­çš„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,203 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e0a192cf-6219-4708-aa9a-a5013876f1aa', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸­çš„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,204 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸­çš„'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='UZrXgeMj' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-614ec9b9-2722-403b-a7ad-e3352e301dd2', choices=[Choice(delta=ChoiceDelta(content='åº”ç”¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,245 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-614ec9b9-2722-403b-a7ad-e3352e301dd2', choices=[Choice(delta=ChoiceDelta(content='åº”ç”¨', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åº”ç”¨', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,247 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åº”ç”¨', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-614ec9b9-2722-403b-a7ad-e3352e301dd2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åº”ç”¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,247 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-614ec9b9-2722-403b-a7ad-e3352e301dd2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åº”ç”¨', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,248 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='åº”ç”¨'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='mmePIWsb' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7059bdc0-3398-42bd-87b8-a62890eed4db', choices=[Choice(delta=ChoiceDelta(content='å±€é™', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,249 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7059bdc0-3398-42bd-87b8-a62890eed4db', choices=[Choice(delta=ChoiceDelta(content='å±€é™', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å±€é™', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,250 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å±€é™', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7059bdc0-3398-42bd-87b8-a62890eed4db', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å±€é™', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,250 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7059bdc0-3398-42bd-87b8-a62890eed4db', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å±€é™', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,251 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å±€é™'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='51KU1mOa' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-126036d1-7836-4438-86c1-ec3d9c0b73db', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,291 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-126036d1-7836-4438-86c1-ec3d9c0b73db', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,292 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-126036d1-7836-4438-86c1-ec3d9c0b73db', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,293 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-126036d1-7836-4438-86c1-ec3d9c0b73db', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,294 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""

"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='o71HIdz8' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-081b0f28-0d09-42d0-9730-190c25a66374', choices=[Choice(delta=ChoiceDelta(content='##', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,294 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-081b0f28-0d09-42d0-9730-190c25a66374', choices=[Choice(delta=ChoiceDelta(content='##', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,296 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-081b0f28-0d09-42d0-9730-190c25a66374', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,297 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-081b0f28-0d09-42d0-9730-190c25a66374', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,298 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='##'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='woFeQmXK' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-94a090ee-3c49-4b7c-80bd-9447e7ea3a6e', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,337 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-94a090ee-3c49-4b7c-80bd-9447e7ea3a6e', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,339 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-94a090ee-3c49-4b7c-80bd-9447e7ea3a6e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,339 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-94a090ee-3c49-4b7c-80bd-9447e7ea3a6e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,340 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='Tdnzvaha' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f38ff05d-5898-4100-81d8-817419532e67', choices=[Choice(delta=ChoiceDelta(content='8', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,341 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f38ff05d-5898-4100-81d8-817419532e67', choices=[Choice(delta=ChoiceDelta(content='8', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='8', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,342 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='8', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f38ff05d-5898-4100-81d8-817419532e67', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='8', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,342 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f38ff05d-5898-4100-81d8-817419532e67', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='8', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,343 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='8'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='tVSB8KBj' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7edd658e-9747-45d6-94a9-e3c1668346e8', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,343 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7edd658e-9747-45d6-94a9-e3c1668346e8', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,345 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7edd658e-9747-45d6-94a9-e3c1668346e8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,345 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7edd658e-9747-45d6-94a9-e3c1668346e8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,345 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='NG5TbGVP' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1f879f49-4827-4036-be68-b5af542ba46f', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,385 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1f879f49-4827-4036-be68-b5af542ba46f', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,386 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1f879f49-4827-4036-be68-b5af542ba46f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,386 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1f879f49-4827-4036-be68-b5af542ba46f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,387 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='37k43qQX' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-dc3809f9-4f79-452f-b720-e83f5d35f467', choices=[Choice(delta=ChoiceDelta(content='æœªæ¥', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,388 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-dc3809f9-4f79-452f-b720-e83f5d35f467', choices=[Choice(delta=ChoiceDelta(content='æœªæ¥', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æœªæ¥', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,389 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æœªæ¥', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-dc3809f9-4f79-452f-b720-e83f5d35f467', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æœªæ¥', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,389 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-dc3809f9-4f79-452f-b720-e83f5d35f467', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æœªæ¥', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,390 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æœªæ¥'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='pbpp0zLn' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8719a51e-e81a-4e1e-b8ac-40d571dfcc0a', choices=[Choice(delta=ChoiceDelta(content='å‘å±•æ–¹å‘', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,432 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8719a51e-e81a-4e1e-b8ac-40d571dfcc0a', choices=[Choice(delta=ChoiceDelta(content='å‘å±•æ–¹å‘', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å‘å±•æ–¹å‘', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,434 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å‘å±•æ–¹å‘', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8719a51e-e81a-4e1e-b8ac-40d571dfcc0a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å‘å±•æ–¹å‘', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,434 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8719a51e-e81a-4e1e-b8ac-40d571dfcc0a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å‘å±•æ–¹å‘', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,435 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å‘å±•æ–¹å‘'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='GWFkEQ5V' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-fa2225af-8a05-458e-a880-ace94e318ac8', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,436 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-fa2225af-8a05-458e-a880-ace94e318ac8', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,437 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-fa2225af-8a05-458e-a880-ace94e318ac8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,437 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-fa2225af-8a05-458e-a880-ace94e318ac8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,438 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='GXHel7Is' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-501c46d8-1119-4274-bce6-6b4f9e372caf', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,491 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-501c46d8-1119-4274-bce6-6b4f9e372caf', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,493 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-501c46d8-1119-4274-bce6-6b4f9e372caf', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,493 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-501c46d8-1119-4274-bce6-6b4f9e372caf', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,494 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='1tEdWGjN' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c56a98e3-9dc9-4c70-8173-a3b92c9de9fa', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,494 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c56a98e3-9dc9-4c70-8173-a3b92c9de9fa', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,496 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c56a98e3-9dc9-4c70-8173-a3b92c9de9fa', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,497 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c56a98e3-9dc9-4c70-8173-a3b92c9de9fa', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,498 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='anJtKHUE' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a978c56b-5ef4-43fd-8e35-fada3adbece1', choices=[Choice(delta=ChoiceDelta(content='8', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,498 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a978c56b-5ef4-43fd-8e35-fada3adbece1', choices=[Choice(delta=ChoiceDelta(content='8', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='8', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,499 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='8', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a978c56b-5ef4-43fd-8e35-fada3adbece1', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='8', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,499 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a978c56b-5ef4-43fd-8e35-fada3adbece1', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='8', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,500 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='8'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='51A3RaqM' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-fe6c39df-2d1b-4958-8a5d-c6808381606d', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,543 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-fe6c39df-2d1b-4958-8a5d-c6808381606d', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,544 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-fe6c39df-2d1b-4958-8a5d-c6808381606d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,545 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-fe6c39df-2d1b-4958-8a5d-c6808381606d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,546 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='hwIJyAmM' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-211de363-c8bc-4aea-9e2d-c6ad05526452', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,546 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-211de363-c8bc-4aea-9e2d-c6ad05526452', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,548 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-211de363-c8bc-4aea-9e2d-c6ad05526452', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,548 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-211de363-c8bc-4aea-9e2d-c6ad05526452', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,549 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='1'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='RuIkhMAd' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6197e344-fcd0-4442-b751-56cb3f7551f3', choices=[Choice(delta=ChoiceDelta(content=' æ–°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,586 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6197e344-fcd0-4442-b751-56cb3f7551f3', choices=[Choice(delta=ChoiceDelta(content=' æ–°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' æ–°', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,589 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' æ–°', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6197e344-fcd0-4442-b751-56cb3f7551f3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' æ–°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,589 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6197e344-fcd0-4442-b751-56cb3f7551f3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' æ–°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,590 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' æ–°'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='0lcBQj41' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-43acc96f-999b-44d1-b1db-5fa05c8eea46', choices=[Choice(delta=ChoiceDelta(content='å‹', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,590 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-43acc96f-999b-44d1-b1db-5fa05c8eea46', choices=[Choice(delta=ChoiceDelta(content='å‹', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å‹', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,592 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å‹', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-43acc96f-999b-44d1-b1db-5fa05c8eea46', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å‹', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,592 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-43acc96f-999b-44d1-b1db-5fa05c8eea46', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å‹', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,593 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å‹'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='IsZ1SJYA' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f82661c3-9746-4f57-b729-6e5fb8bf24b1', choices=[Choice(delta=ChoiceDelta(content='è¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,634 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f82661c3-9746-4f57-b729-6e5fb8bf24b1', choices=[Choice(delta=ChoiceDelta(content='è¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,636 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f82661c3-9746-4f57-b729-6e5fb8bf24b1', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,636 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f82661c3-9746-4f57-b729-6e5fb8bf24b1', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,637 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='WihL5AXn' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ce5d105e-4e84-4d2f-ab47-22069e6679c9', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,638 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ce5d105e-4e84-4d2f-ab47-22069e6679c9', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,639 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ce5d105e-4e84-4d2f-ab47-22069e6679c9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,640 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ce5d105e-4e84-4d2f-ab47-22069e6679c9', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç¤¾åŒº'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç¤¾åŒº
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='åº”ç”¨'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: åº”ç”¨
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ¡ˆä¾‹'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ¡ˆä¾‹
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='7'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 7
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='2'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 2
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' æˆ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  æˆ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æœ¬'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æœ¬
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ•ˆç›Š'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ•ˆç›Š
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='åˆ†æ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: åˆ†æ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç»æµ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç»æµ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å½±å“'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å½±å“
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='7'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 7
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='3'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 3
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸´åºŠ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸´åºŠ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å®è·µ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å®è·µ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸­çš„'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸­çš„
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='åº”ç”¨'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: åº”ç”¨
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å±€é™'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å±€é™
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""

"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 


è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='##'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ##
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='8'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 8
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æœªæ¥'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æœªæ¥
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å‘å±•æ–¹å‘'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å‘å±•æ–¹å‘
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='8'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 8
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='1'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 1
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' æ–°'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  æ–°
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å‹'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å‹
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç”Ÿç‰©'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç”Ÿç‰©2025-11-18 15:29:20,641 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç”Ÿç‰©'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='PNMptnmg' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4b7d41f1-a3b3-4bbf-8b73-1dbe063843f8', choices=[Choice(delta=ChoiceDelta(content='ç ”å‘', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,641 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4b7d41f1-a3b3-4bbf-8b73-1dbe063843f8', choices=[Choice(delta=ChoiceDelta(content='ç ”å‘', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç ”å‘', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,642 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç ”å‘', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4b7d41f1-a3b3-4bbf-8b73-1dbe063843f8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç ”å‘', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,642 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4b7d41f1-a3b3-4bbf-8b73-1dbe063843f8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç ”å‘', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,643 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç ”å‘'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='GH6kxBN3' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-18b7d92a-8d17-4389-979a-3d83cee7e8f5', choices=[Choice(delta=ChoiceDelta(content='è¶‹åŠ¿', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,683 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-18b7d92a-8d17-4389-979a-3d83cee7e8f5', choices=[Choice(delta=ChoiceDelta(content='è¶‹åŠ¿', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¶‹åŠ¿', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,684 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¶‹åŠ¿', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-18b7d92a-8d17-4389-979a-3d83cee7e8f5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¶‹åŠ¿', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,684 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-18b7d92a-8d17-4389-979a-3d83cee7e8f5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¶‹åŠ¿', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,687 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¶‹åŠ¿'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='6K9jXAFe' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ac34625a-68b2-4523-9c96-8b7ed4f1ee45', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,687 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ac34625a-68b2-4523-9c96-8b7ed4f1ee45', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,688 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ac34625a-68b2-4523-9c96-8b7ed4f1ee45', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,689 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ac34625a-68b2-4523-9c96-8b7ed4f1ee45', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,690 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='iRONpNnI' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-05b687d3-b148-44b0-987b-96ab140c8a3a', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,730 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-05b687d3-b148-44b0-987b-96ab140c8a3a', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,732 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-05b687d3-b148-44b0-987b-96ab140c8a3a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,732 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-05b687d3-b148-44b0-987b-96ab140c8a3a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,733 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='5simIxMU' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d2640532-57dc-41f7-9f7b-9b81dd0cfcc0', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,733 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d2640532-57dc-41f7-9f7b-9b81dd0cfcc0', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,734 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d2640532-57dc-41f7-9f7b-9b81dd0cfcc0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,734 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d2640532-57dc-41f7-9f7b-9b81dd0cfcc0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,736 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='ljcGKgFB' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-184e3fb1-aa01-4415-a78a-e18d51578b71', choices=[Choice(delta=ChoiceDelta(content='8', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,777 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-184e3fb1-aa01-4415-a78a-e18d51578b71', choices=[Choice(delta=ChoiceDelta(content='8', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='8', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,778 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='8', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-184e3fb1-aa01-4415-a78a-e18d51578b71', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='8', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,778 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-184e3fb1-aa01-4415-a78a-e18d51578b71', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='8', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,779 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='8'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='6DuJWTiT' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-48204f2a-a4d6-4726-add3-086e9f7c066c', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,780 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-48204f2a-a4d6-4726-add3-086e9f7c066c', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,781 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-48204f2a-a4d6-4726-add3-086e9f7c066c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,781 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-48204f2a-a4d6-4726-add3-086e9f7c066c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,782 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='o2IDjsJK' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b75a3976-9ed6-4373-b91c-3c01a8a2cf9e', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,783 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b75a3976-9ed6-4373-b91c-3c01a8a2cf9e', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,784 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b75a3976-9ed6-4373-b91c-3c01a8a2cf9e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,784 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b75a3976-9ed6-4373-b91c-3c01a8a2cf9e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,785 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='2'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='bD2BSDY1' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-30a4d223-e267-44ef-a85e-ac6f1c551380', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,825 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-30a4d223-e267-44ef-a85e-ac6f1c551380', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450955, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,826 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-30a4d223-e267-44ef-a85e-ac6f1c551380', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,826 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-30a4d223-e267-44ef-a85e-ac6f1c551380', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,827 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='sEDMH7h4' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-160ad756-9af8-4b9c-bd2c-479af1ad75f0', choices=[Choice(delta=ChoiceDelta(content='ä¸ªæ€§åŒ–', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,828 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-160ad756-9af8-4b9c-bd2c-479af1ad75f0', choices=[Choice(delta=ChoiceDelta(content='ä¸ªæ€§åŒ–', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸ªæ€§åŒ–', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,830 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸ªæ€§åŒ–', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-160ad756-9af8-4b9c-bd2c-479af1ad75f0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸ªæ€§åŒ–', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,830 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-160ad756-9af8-4b9c-bd2c-479af1ad75f0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸ªæ€§åŒ–', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,832 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸ªæ€§åŒ–'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='XqmdM5D3' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f0477840-037f-4b57-a702-2ebec2232c61', choices=[Choice(delta=ChoiceDelta(content='æ²»ç–—', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,869 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f0477840-037f-4b57-a702-2ebec2232c61', choices=[Choice(delta=ChoiceDelta(content='æ²»ç–—', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,870 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f0477840-037f-4b57-a702-2ebec2232c61', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,871 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f0477840-037f-4b57-a702-2ebec2232c61', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,872 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ²»ç–—'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='W5eZ5yuN' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-748d6c83-c6a4-41de-afbe-0d1f12dca46d', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,873 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-748d6c83-c6a4-41de-afbe-0d1f12dca46d', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,874 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-748d6c83-c6a4-41de-afbe-0d1f12dca46d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,874 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-748d6c83-c6a4-41de-afbe-0d1f12dca46d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,875 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='fn34WJvK' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5d8cbd27-4edd-498d-8a4c-3ef460723e61', choices=[Choice(delta=ChoiceDelta(content='ç²¾å‡†', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,916 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5d8cbd27-4edd-498d-8a4c-3ef460723e61', choices=[Choice(delta=ChoiceDelta(content='ç²¾å‡†', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç²¾å‡†', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,917 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç²¾å‡†', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5d8cbd27-4edd-498d-8a4c-3ef460723e61', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç²¾å‡†', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,917 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5d8cbd27-4edd-498d-8a4c-3ef460723e61', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç²¾å‡†', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,918 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç²¾å‡†'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='VZMcITWu' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6a191b1d-4496-46e2-8481-dda2992f1906', choices=[Choice(delta=ChoiceDelta(content='åŒ»å­¦', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,918 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6a191b1d-4496-46e2-8481-dda2992f1906', choices=[Choice(delta=ChoiceDelta(content='åŒ»å­¦', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åŒ»å­¦', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,920 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åŒ»å­¦', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6a191b1d-4496-46e2-8481-dda2992f1906', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åŒ»å­¦', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,920 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6a191b1d-4496-46e2-8481-dda2992f1906', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åŒ»å­¦', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,921 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='åŒ»å­¦'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='dLk7IA7Q' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f622301b-50cb-4585-b28c-5e4238acd707', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,964 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f622301b-50cb-4585-b28c-5e4238acd707', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,965 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f622301b-50cb-4585-b28c-5e4238acd707', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,966 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f622301b-50cb-4585-b28c-5e4238acd707', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,966 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='DoA8Jg8X' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3b21c934-0872-403e-95b2-bd7d21f90c39', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,967 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3b21c934-0872-403e-95b2-bd7d21f90c39', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,968 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3b21c934-0872-403e-95b2-bd7d21f90c39', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,968 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3b21c934-0872-403e-95b2-bd7d21f90c39', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,969 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='66CCdk2j' timestamp=1763450949.457893
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-109fab83-d66d-4d88-88f7-6a1bb9144c7f', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:20,970 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-109fab83-d66d-4d88-88f7-6a1bb9144c7f', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:20,971 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:20 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-109fab83-d66d-4d88-88f7-6a1bb9144c7f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,971 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-109fab83-d66d-4d88-88f7-6a1bb9144c7f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:20,973 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='0FXrgqt3' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-045e9971-780a-4189-b2fa-44bb411fa72c', choices=[Choice(delta=ChoiceDelta(content='8', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,008 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-045e9971-780a-4189-b2fa-44bb411fa72c', choices=[Choice(delta=ChoiceDelta(content='8', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='8', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,009 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='8', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-045e9971-780a-4189-b2fa-44bb411fa72c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='8', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,009 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-045e9971-780a-4189-b2fa-44bb411fa72c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='8', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,011 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='8'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='BgztOQ0s' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d7953b70-4d56-4117-81e5-e48d1755ccc2', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,011 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d7953b70-4d56-4117-81e5-e48d1755ccc2', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,012 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d7953b70-4d56-4117-81e5-e48d1755ccc2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,012 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d7953b70-4d56-4117-81e5-e48d1755ccc2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,013 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='iuYd8rM5' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-65aa341c-9c69-4abb-86f3-d85445bec2da', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,054 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-65aa341c-9c69-4abb-86f3-d85445bec2da', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,056 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-65aa341c-9c69-4abb-86f3-d85445bec2da', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,056 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-65aa341c-9c69-4abb-86f3-d85445bec2da', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,057 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='3'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='Ay5OIUaB' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c2f511b2-f80c-4f16-838d-923b3808bc9e', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,058 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c2f511b2-f80c-4f16-838d-923b3808bc9e', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,059 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c2f511b2-f80c-4f16-838d-923b3808bc9e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,059 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c2f511b2-f80c-4f16-838d-923b3808bc9e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,060 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='uq7sIruA' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a815f970-c82d-4e3c-9bba-d53076e18439', choices=[Choice(delta=ChoiceDelta(content='ä¸å…¶ä»–', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,106 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a815f970-c82d-4e3c-9bba-d53076e18439', choices=[Choice(delta=ChoiceDelta(content='ä¸å…¶ä»–', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸å…¶ä»–', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,108 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸å…¶ä»–', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a815f970-c82d-4e3c-9bba-d53076e18439', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸å…¶ä»–', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,108 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a815f970-c82d-4e3c-9bba-d53076e18439', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸å…¶ä»–', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,109 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸å…¶ä»–'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='dHYzTaNa' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-07f03c2f-8e90-439a-9cc5-25a0bcb0be34', choices=[Choice(delta=ChoiceDelta(content='æ²»ç–—', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,109 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-07f03c2f-8e90-439a-9cc5-25a0bcb0be34', choices=[Choice(delta=ChoiceDelta(content='æ²»ç–—', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,111 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-07f03c2f-8e90-439a-9cc5-25a0bcb0be34', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,111 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-07f03c2f-8e90-439a-9cc5-25a0bcb0be34', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,112 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ²»ç–—'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='YI5t2CFG' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0523b6a0-d9a0-4480-bd11-f0eb7d79331e', choices=[Choice(delta=ChoiceDelta(content='æŠ€æœ¯', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,152 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0523b6a0-d9a0-4480-bd11-f0eb7d79331e', choices=[Choice(delta=ChoiceDelta(content='æŠ€æœ¯', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æŠ€æœ¯', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,153 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æŠ€æœ¯', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0523b6a0-d9a0-4480-bd11-f0eb7d79331e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æŠ€æœ¯', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,153 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0523b6a0-d9a0-4480-bd11-f0eb7d79331e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æŠ€æœ¯', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,154 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æŠ€æœ¯'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='KlVnZiJ2' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-55eacac3-1869-4feb-bb1e-ce52fba582ac', choices=[Choice(delta=ChoiceDelta(content='çš„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,157 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-55eacac3-1869-4feb-bb1e-ce52fba582ac', choices=[Choice(delta=ChoiceDelta(content='çš„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,159 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-55eacac3-1869-4feb-bb1e-ce52fba582ac', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,159 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-55eacac3-1869-4feb-bb1e-ce52fba582ac', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,161 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='çš„'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='f3QBGtmj' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9145fc12-ce67-4c8c-a246-7ae49a535e70', choices=[Choice(delta=ChoiceDelta(content='æ•´åˆ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,161 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9145fc12-ce67-4c8c-a246-7ae49a535e70', choices=[Choice(delta=ChoiceDelta(content='æ•´åˆ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ•´åˆ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,163 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ•´åˆ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9145fc12-ce67-4c8c-a246-7ae49a535e70', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ•´åˆ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,163 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9145fc12-ce67-4c8c-a246-7ae49a535e70', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ•´åˆ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,165 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ•´åˆ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='AUWR32XX' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f86a4fc1-30c6-4048-8051-3ef1d7b11069', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,241 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f86a4fc1-30c6-4048-8051-3ef1d7b11069', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,243 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f86a4fc1-30c6-4048-8051-3ef1d7b11069', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,243 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f86a4fc1-30c6-4048-8051-3ef1d7b11069', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,244 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""

"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='2mVvYoJ0' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1b9a6fc2-d941-48c8-b5b6-e4a995a29d19', choices=[Choice(delta=ChoiceDelta(content='##', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,244 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1b9a6fc2-d941-48c8-b5b6-e4a995a29d19', choices=[Choice(delta=ChoiceDelta(content='##', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,246 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1b9a6fc2-d941-48c8-b5b6-e4a995a29d19', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,246 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1b9a6fc2-d941-48c8-b5b6-e4a995a29d19', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,247 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='##'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='LQOPVP96' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-57ef337a-2e07-4d50-8db9-5f8f7896806d', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,286 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-57ef337a-2e07-4d50-8db9-5f8f7896806d', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,287 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-57ef337a-2e07-4d50-8db9-5f8f7896806d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,287 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-57ef337a-2e07-4d50-8db9-5f8f7896806d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,289 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='Hg8GGZWU' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9d8e375c-71b2-4c72-a39b-426cd2bdf959', choices=[Choice(delta=ChoiceDelta(content='9', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,290 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9d8e375c-71b2-4c72-a39b-426cd2bdf959', choices=[Choice(delta=ChoiceDelta(content='9', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='9', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,290 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='9', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9d8e375c-71b2-4c72-a39b-426cd2bdf959', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='9', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,290 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9d8e375c-71b2-4c72-a39b-426cd2bdf959', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='9', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,292 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='9'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='kF3VPmkb' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ea989204-c6b3-43d2-ac72-850185457370', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,293 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ea989204-c6b3-43d2-ac72-850185457370', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,294 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ea989204-c6b3-43d2-ac72-850185457370', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,294 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ea989204-c6b3-43d2-ac72-850185457370', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,295 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='YZRQpPVO' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c31f4a56-6189-41a7-82b1-d625e86f326d', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,295 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c31f4a56-6189-41a7-82b1-d625e86f326d', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,297 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c31f4a56-6189-41a7-82b1-d625e86f326d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,297 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c31f4a56-6189-41a7-82b1-d625e86f326d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0ba9117f-7833-4ae6-8fb0-b7bfbb6ea6d7', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,336 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-0ba9117f-7833-4ae6-8fb0-b7bfbb6ea6d7', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,337 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0ba9117f-7833-4ae6-8fb0-b7bfbb6ea6d7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,337 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-0ba9117f-7833-4ae6-8fb0-b7bfbb6ea6d7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4f596d28-11bf-44dd-8319-12c0efcfd1d2', choices=[Choice(delta=ChoiceDelta(content=' æ¯”', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,338 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4f596d28-11bf-44dd-8319-12c0efcfd1d2', choices=[Choice(delta=ChoiceDelta(content=' æ¯”', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' æ¯”', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,339 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' æ¯”', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4f596d28-11bf-44dd-8319-12c0efcfd1d2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' æ¯”', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,340 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4f596d28-11bf-44dd-8319-12c0efcfd1d2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' æ¯”', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,341 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' æ¯”'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='9ox8gP48' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e29b22d1-ccad-46e9-ba7c-4e839c964de2', choices=[Choice(delta=ChoiceDelta(content='è¾ƒ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,380 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e29b22d1-ccad-46e9-ba7c-4e839c964de2', choices=[Choice(delta=ChoiceDelta(content='è¾ƒ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¾ƒ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,381 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¾ƒ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e29b22d1-ccad-46e9-ba7c-4e839c964de2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¾ƒ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,381 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e29b22d1-ccad-46e9-ba7c-4e839c964de2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¾ƒ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,382 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¾ƒ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='s4GNe5zh' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d8aa6be5-fd9f-4d6b-ae87-e3d718e0c36f', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,384 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d8aa6be5-fd9f-4d6b-ae87-e3d718e0c36f', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,385 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d8aa6be5-fd9f-4d6b-ae87-e3d718e0c36f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,385 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d8aa6be5-fd9f-4d6b-ae87-e3d718e0c36f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,386 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='xZMf8kuc' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-19a81a94-2990-4a21-851a-6fd4f15b8578', choices=[Choice(delta=ChoiceDelta(content='äº‰è®®', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,427 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-19a81a94-2990-4a21-851a-6fd4f15b8578', choices=[Choice(delta=ChoiceDelta(content='äº‰è®®', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='äº‰è®®', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,428 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='äº‰è®®', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-19a81a94-2990-4a21-851a-6fd4f15b8578', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='äº‰è®®', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,428 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-19a81a94-2990-4a21-851a-6fd4f15b8578', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='äº‰è®®', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,429 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='äº‰è®®'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='QieejQc6' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-290a783f-4f9e-43cd-9f91-e4faf89ffcb5', choices=[Choice(delta=ChoiceDelta(content='ç‚¹', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,430 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-290a783f-4f9e-43cd-9f91-e4faf89ffcb5', choices=[Choice(delta=ChoiceDelta(content='ç‚¹', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç‚¹', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,432 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç‚¹', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-290a783f-4f9e-43cd-9f91-e4faf89ffcb5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç‚¹', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,432 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-290a783f-4f9e-43cd-9f91-e4faf89ffcb5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç‚¹', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,433 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç‚¹'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='q1m5JxFG' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b1523e65-1c6c-40e3-b425-73cd8401a87e', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,434 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b1523e65-1c6c-40e3-b425-73cd8401a87e', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,435 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b1523e65-1c6c-40e3-b425-73cd8401a87e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,436 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b1523e65-1c6c-40e3-b425-73cd8401a87e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,437 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='V7zTIn6p' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8758017e-0edf-44f1-be7f-34e49a3eac85', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,472 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8758017e-0edf-44f1-be7f-34e49a3eac85', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,473 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8758017e-0edf-44f1-be7f-34e49a3eac85', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,473 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8758017e-0edf-44f1-be7f-34e49a3eac85', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,474 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='4wR0wFXt' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-79783667-2346-4333-a5f3-8ea30e6b7a49', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,474 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-79783667-2346-4333-a5f3-8ea30e6b7a49', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,476 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-79783667-2346-4333-a5f3-8ea30e6b7a49', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,476 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-79783667-2346-4333-a5f3-8ea30e6b7a49', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,477 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='n4EI5pBd' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-79dab54b-7ac5-41a4-bede-a9b8cdf10e5f', choices=[Choice(delta=ChoiceDelta(content='9', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,518 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-79dab54b-7ac5-41a4-bede-a9b8cdf10e5f', choices=[Choice(delta=ChoiceDelta(content='9', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='9', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,520 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='9', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-79dab54b-7ac5-41a4-bede-a9b8cdf10e5f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='9', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,520 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-79dab54b-7ac5-41a4-bede-a9b8cdf10e5f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='9', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,521 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='9'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='oiBU62qh' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e3ee3a94-1e19-47a6-b51a-a7ad8791ef5c', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,522 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e3ee3a94-1e19-47a6-b51a-a7ad8791ef5c', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,523 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e3ee3a94-1e19-47a6-b51a-a7ad8791ef5c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,523 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e3ee3a94-1e19-47a6-b51a-a7ad8791ef5c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,525 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='oMzHZaMf' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7fea1917-2691-4d58-8cc7-63e00fda491d', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,564 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7fea1917-2691-4d58-8cc7-63e00fda491d', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,566 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7fea1917-2691-4d58-8cc7-63e00fda491d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,566 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7fea1917-2691-4d58-8cc7-63e00fda491d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,567 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='1'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='0jYXm046' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a67d344a-e9bb-4071-918b-2dcbee008997', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,568 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a67d344a-e9bb-4071-918b-2dcbee008997', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,569 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a67d344a-e9bb-4071-918b-2dcbee008997', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,569 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a67d344a-e9bb-4071-918b-2dcbee008997', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7de30de9-cc8b-4cb9-ad07-05ab34b15065', choices=[Choice(delta=ChoiceDelta(content=' è¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,612 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7de30de9-cc8b-4cb9-ad07-05ab34b15065', choices=[Choice(delta=ChoiceDelta(content=' è¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' è¡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,613 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' è¡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7de30de9-cc8b-4cb9-ad07-05ab34b15065', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' è¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,613 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7de30de9-cc8b-4cb9-ad07-05ab34b15065', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' è¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,614 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' è¡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='j7d01o7D' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c453fe0f-b7e7-414b-a5c8-76bb4021b3e1', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,615 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c453fe0f-b7e7-414b-a5c8-76bb4021b3e1', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,617 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c453fe0f-b7e7-414b-a5c8-76bb4021b3e1', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,617 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c453fe0f-b7e7-414b-a5c8-76bb4021b3e1', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,618 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç”Ÿç‰©'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='yjxfDXm7' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-88ce9ee1-189c-4d31-a799-5eb93a646dd7', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,657 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-88ce9ee1-189c-4d31-a799-5eb93a646dd7', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,658 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-88ce9ee1-189c-4d31-a799-5eb93a646dd7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,658 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-88ce9ee1-189c-4d31-a799-5eb93a646dd7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,660 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='RLmWfeUh' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-372dad68-f766-4f2e-8ee6-58335891d305', choices=[Choice(delta=ChoiceDelta(content='ä¼ ç»Ÿ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,660 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-372dad68-f766-4f2e-8ee6-58335891d305', choices=[Choice(delta=ChoiceDelta(content='ä¼ ç»Ÿ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¼ ç»Ÿ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,662 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¼ ç»Ÿ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-372dad68-f766-4f2e-8ee6-58335891d305', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¼ ç»Ÿ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,662 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-372dad68-f766-4f2e-8ee6-58335891d305', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¼ ç»Ÿ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,663 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¼ ç»Ÿ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='s9sHtaS7' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-23af6e80-5243-421b-a7cd-c2732202b3a3', choices=[Choice(delta=ChoiceDelta(content='æ²»ç–—', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,663 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-23af6e80-5243-421b-a7cd-c2732202b3a3', choices=[Choice(delta=ChoiceDelta(content='æ²»ç–—', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,664 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-23af6e80-5243-421b-a7cd-c2732202b3a3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,664 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-23af6e80-5243-421b-a7cd-c2732202b3a3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ²»ç–—', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç ”å‘'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç ”å‘
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¶‹åŠ¿'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¶‹åŠ¿
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='8'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 8
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='2'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 2
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸ªæ€§åŒ–'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸ªæ€§åŒ–
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ²»ç–—'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ²»ç–—
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç²¾å‡†'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç²¾å‡†
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='åŒ»å­¦'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: åŒ»å­¦
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='8'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 8
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='3'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 3
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸å…¶ä»–'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸å…¶ä»–
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ²»ç–—'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ²»ç–—
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æŠ€æœ¯'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æŠ€æœ¯
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='çš„'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: çš„
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ•´åˆ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ•´åˆ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""

"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 


è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='##'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ##
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='9'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 9
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' æ¯”'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  æ¯”
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¾ƒ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¾ƒ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='äº‰è®®'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: äº‰è®®
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç‚¹'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç‚¹
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='9'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 9
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='1'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 1
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' è¡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  è¡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç”Ÿç‰©'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç”Ÿç‰©
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¼ ç»Ÿ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¼ ç»Ÿ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ²»ç–—'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ²»ç–—2025-11-18 15:29:21,664 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ²»ç–—'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='5zSUjeUO' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e9713464-34e4-406b-87e0-27ffd01ff60f', choices=[Choice(delta=ChoiceDelta(content='çš„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,703 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e9713464-34e4-406b-87e0-27ffd01ff60f', choices=[Choice(delta=ChoiceDelta(content='çš„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,704 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e9713464-34e4-406b-87e0-27ffd01ff60f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,704 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e9713464-34e4-406b-87e0-27ffd01ff60f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='çš„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,706 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='çš„'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='yKedFfgj' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e41fda32-6ac5-4823-96c9-9f7d545b3aaa', choices=[Choice(delta=ChoiceDelta(content='å¯¹æ¯”', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,707 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e41fda32-6ac5-4823-96c9-9f7d545b3aaa', choices=[Choice(delta=ChoiceDelta(content='å¯¹æ¯”', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å¯¹æ¯”', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,708 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å¯¹æ¯”', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e41fda32-6ac5-4823-96c9-9f7d545b3aaa', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å¯¹æ¯”', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,708 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e41fda32-6ac5-4823-96c9-9f7d545b3aaa', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å¯¹æ¯”', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,709 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å¯¹æ¯”'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='imIJAklJ' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e7694dc6-c042-428b-adfc-7b36a8decb6c', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,751 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e7694dc6-c042-428b-adfc-7b36a8decb6c', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,752 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e7694dc6-c042-428b-adfc-7b36a8decb6c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,752 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e7694dc6-c042-428b-adfc-7b36a8decb6c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,753 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='bJ8pBwI8' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-44dd72e2-b480-48fc-ae85-248ccba324e8', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,754 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-44dd72e2-b480-48fc-ae85-248ccba324e8', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,755 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-44dd72e2-b480-48fc-ae85-248ccba324e8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,755 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-44dd72e2-b480-48fc-ae85-248ccba324e8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,756 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='NOp0tr2n' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8b8b5408-9025-4feb-af71-27509f87d6fb', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,796 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8b8b5408-9025-4feb-af71-27509f87d6fb', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,798 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8b8b5408-9025-4feb-af71-27509f87d6fb', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,798 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8b8b5408-9025-4feb-af71-27509f87d6fb', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,799 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='MJX0zYgf' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b386b8f7-3976-464a-a9ac-7a86ae5dc25e', choices=[Choice(delta=ChoiceDelta(content='9', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,799 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b386b8f7-3976-464a-a9ac-7a86ae5dc25e', choices=[Choice(delta=ChoiceDelta(content='9', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='9', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,801 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='9', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b386b8f7-3976-464a-a9ac-7a86ae5dc25e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='9', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,801 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b386b8f7-3976-464a-a9ac-7a86ae5dc25e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='9', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,802 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='9'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='HgDJ9imV' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-2b12a945-9b03-4df0-97e2-9c544a87c0f3', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,842 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-2b12a945-9b03-4df0-97e2-9c544a87c0f3', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450956, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,844 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-2b12a945-9b03-4df0-97e2-9c544a87c0f3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,845 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-2b12a945-9b03-4df0-97e2-9c544a87c0f3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,846 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='bQJr7Ux3' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-42e579dd-f574-40d0-8206-b1323de1b428', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,847 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-42e579dd-f574-40d0-8206-b1323de1b428', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,849 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-42e579dd-f574-40d0-8206-b1323de1b428', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,849 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-42e579dd-f574-40d0-8206-b1323de1b428', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,849 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='2'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='qaKY8EXp' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-80897ed8-1cc6-4fc1-8507-fa8e114eac81', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,889 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-80897ed8-1cc6-4fc1-8507-fa8e114eac81', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,890 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-80897ed8-1cc6-4fc1-8507-fa8e114eac81', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,890 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-80897ed8-1cc6-4fc1-8507-fa8e114eac81', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,891 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='jdhsznlX' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-2a87c7ef-f31e-4560-a2b9-571ab8010fc3', choices=[Choice(delta=ChoiceDelta(content='äºš', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,892 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-2a87c7ef-f31e-4560-a2b9-571ab8010fc3', choices=[Choice(delta=ChoiceDelta(content='äºš', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='äºš', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,893 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='äºš', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-2a87c7ef-f31e-4560-a2b9-571ab8010fc3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='äºš', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,893 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-2a87c7ef-f31e-4560-a2b9-571ab8010fc3', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='äºš', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,894 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='äºš'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='XPQHTqGf' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8496a4ca-7af4-406b-bc73-fab324c608a5', choices=[Choice(delta=ChoiceDelta(content='ç»„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,894 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8496a4ca-7af4-406b-bc73-fab324c608a5', choices=[Choice(delta=ChoiceDelta(content='ç»„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç»„', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,896 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç»„', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8496a4ca-7af4-406b-bc73-fab324c608a5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç»„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,896 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8496a4ca-7af4-406b-bc73-fab324c608a5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç»„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,897 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç»„'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='1yAMvh4D' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1f3e76f9-8922-4c67-9504-92f59d0d12d2', choices=[Choice(delta=ChoiceDelta(content='ç ”ç©¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,938 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1f3e76f9-8922-4c67-9504-92f59d0d12d2', choices=[Choice(delta=ChoiceDelta(content='ç ”ç©¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,939 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1f3e76f9-8922-4c67-9504-92f59d0d12d2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,940 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1f3e76f9-8922-4c67-9504-92f59d0d12d2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,941 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç ”ç©¶'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='izTpl8q4' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a9b5d12b-6544-4608-bb43-df635cc025dc', choices=[Choice(delta=ChoiceDelta(content='ä¸­çš„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,942 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a9b5d12b-6544-4608-bb43-df635cc025dc', choices=[Choice(delta=ChoiceDelta(content='ä¸­çš„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸­çš„', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,944 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸­çš„', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a9b5d12b-6544-4608-bb43-df635cc025dc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸­çš„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,944 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a9b5d12b-6544-4608-bb43-df635cc025dc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸­çš„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,945 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸­çš„'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='nzKE5FAX' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-900cda22-3a7a-43e5-beb2-581a10a36b67', choices=[Choice(delta=ChoiceDelta(content='ç–—æ•ˆ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,985 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-900cda22-3a7a-43e5-beb2-581a10a36b67', choices=[Choice(delta=ChoiceDelta(content='ç–—æ•ˆ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç–—æ•ˆ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,986 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç–—æ•ˆ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-900cda22-3a7a-43e5-beb2-581a10a36b67', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç–—æ•ˆ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,986 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-900cda22-3a7a-43e5-beb2-581a10a36b67', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç–—æ•ˆ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,987 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç–—æ•ˆ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='3XUXIQKn' timestamp=1763450949.457893
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6ef6470f-b263-475c-919e-336c587e5407', choices=[Choice(delta=ChoiceDelta(content='å·®å¼‚', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:21,987 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-6ef6470f-b263-475c-919e-336c587e5407', choices=[Choice(delta=ChoiceDelta(content='å·®å¼‚', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å·®å¼‚', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:21,989 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å·®å¼‚', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:21 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6ef6470f-b263-475c-919e-336c587e5407', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å·®å¼‚', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,990 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-6ef6470f-b263-475c-919e-336c587e5407', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å·®å¼‚', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:21,991 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å·®å¼‚'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='GN8lOHeG' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c1e7cb88-a00b-4e98-9e34-3cc9b59fc7d5', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,032 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c1e7cb88-a00b-4e98-9e34-3cc9b59fc7d5', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,033 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c1e7cb88-a00b-4e98-9e34-3cc9b59fc7d5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,033 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c1e7cb88-a00b-4e98-9e34-3cc9b59fc7d5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,034 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='AcHZwmxe' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8aeb8bfb-02da-4a9c-b3ce-0ee128c1eea7', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,034 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8aeb8bfb-02da-4a9c-b3ce-0ee128c1eea7', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,036 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8aeb8bfb-02da-4a9c-b3ce-0ee128c1eea7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,036 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8aeb8bfb-02da-4a9c-b3ce-0ee128c1eea7', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,037 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='oTAVWCZr' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b487f401-60ad-476b-899e-d2856d0ccdda', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,077 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b487f401-60ad-476b-899e-d2856d0ccdda', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,088 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b487f401-60ad-476b-899e-d2856d0ccdda', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,089 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b487f401-60ad-476b-899e-d2856d0ccdda', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,091 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='ApKR2O4t' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f40f4d29-83a3-4cbc-a49a-f982b97d855d', choices=[Choice(delta=ChoiceDelta(content='9', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,093 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f40f4d29-83a3-4cbc-a49a-f982b97d855d', choices=[Choice(delta=ChoiceDelta(content='9', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='9', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,095 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='9', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f40f4d29-83a3-4cbc-a49a-f982b97d855d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='9', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,096 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f40f4d29-83a3-4cbc-a49a-f982b97d855d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='9', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,098 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='9'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='8720CIjh' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b1d9491c-156b-4a0e-87f1-cf37f86e391b', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,098 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b1d9491c-156b-4a0e-87f1-cf37f86e391b', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,099 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b1d9491c-156b-4a0e-87f1-cf37f86e391b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,100 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b1d9491c-156b-4a0e-87f1-cf37f86e391b', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,101 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='XC85Ndja' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b1b12167-54c5-497a-9356-ff5d6a3abb6a', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,127 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b1b12167-54c5-497a-9356-ff5d6a3abb6a', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,129 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b1b12167-54c5-497a-9356-ff5d6a3abb6a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,129 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b1b12167-54c5-497a-9356-ff5d6a3abb6a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,130 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='3'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='JRLjTAZ5' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-987ffd99-814b-43a5-9a9c-f10a920afc04', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,131 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-987ffd99-814b-43a5-9a9c-f10a920afc04', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,132 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-987ffd99-814b-43a5-9a9c-f10a920afc04', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,132 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-987ffd99-814b-43a5-9a9c-f10a920afc04', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,133 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='mFGycpX3' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-83a99087-c908-4819-be89-0ec8486c52d5', choices=[Choice(delta=ChoiceDelta(content='è¯æ®', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,173 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-83a99087-c908-4819-be89-0ec8486c52d5', choices=[Choice(delta=ChoiceDelta(content='è¯æ®', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¯æ®', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,176 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¯æ®', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-83a99087-c908-4819-be89-0ec8486c52d5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¯æ®', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,176 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-83a99087-c908-4819-be89-0ec8486c52d5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¯æ®', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,178 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¯æ®'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='FAKIHfUA' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-93534d21-1f31-48aa-86c8-b26eae58fa27', choices=[Choice(delta=ChoiceDelta(content='è´¨é‡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,178 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-93534d21-1f31-48aa-86c8-b26eae58fa27', choices=[Choice(delta=ChoiceDelta(content='è´¨é‡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è´¨é‡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,179 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è´¨é‡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-93534d21-1f31-48aa-86c8-b26eae58fa27', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è´¨é‡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,180 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-93534d21-1f31-48aa-86c8-b26eae58fa27', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è´¨é‡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,180 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è´¨é‡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='WEpYsUKL' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b8ea1784-5c00-4659-8e64-3ee36e754529', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,221 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b8ea1784-5c00-4659-8e64-3ee36e754529', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,224 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b8ea1784-5c00-4659-8e64-3ee36e754529', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,224 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b8ea1784-5c00-4659-8e64-3ee36e754529', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,225 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='VrDVsOd4' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4e35bdf0-d48e-40b4-af8d-421b916e0d7e', choices=[Choice(delta=ChoiceDelta(content='ç ”ç©¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,226 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4e35bdf0-d48e-40b4-af8d-421b916e0d7e', choices=[Choice(delta=ChoiceDelta(content='ç ”ç©¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,227 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4e35bdf0-d48e-40b4-af8d-421b916e0d7e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,228 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4e35bdf0-d48e-40b4-af8d-421b916e0d7e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,229 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç ”ç©¶'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='aIT8E75G' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4f3da83d-5339-4ac2-a179-80d4372934c8', choices=[Choice(delta=ChoiceDelta(content='å', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,266 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-4f3da83d-5339-4ac2-a179-80d4372934c8', choices=[Choice(delta=ChoiceDelta(content='å', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,268 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4f3da83d-5339-4ac2-a179-80d4372934c8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,268 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-4f3da83d-5339-4ac2-a179-80d4372934c8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,269 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='SPqwvwQl' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-47357130-49c0-48b3-9795-942f6875267a', choices=[Choice(delta=ChoiceDelta(content='å€š', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,270 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-47357130-49c0-48b3-9795-942f6875267a', choices=[Choice(delta=ChoiceDelta(content='å€š', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å€š', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,271 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å€š', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-47357130-49c0-48b3-9795-942f6875267a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å€š', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,271 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-47357130-49c0-48b3-9795-942f6875267a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å€š', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,272 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å€š'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='KQ4czSEA' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e6b5ac35-10a8-42ae-84a1-8158a218d08f', choices=[Choice(delta=ChoiceDelta(content='åˆ†æ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,273 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-e6b5ac35-10a8-42ae-84a1-8158a218d08f', choices=[Choice(delta=ChoiceDelta(content='åˆ†æ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åˆ†æ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,274 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='åˆ†æ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e6b5ac35-10a8-42ae-84a1-8158a218d08f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åˆ†æ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,274 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-e6b5ac35-10a8-42ae-84a1-8158a218d08f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='åˆ†æ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,275 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='åˆ†æ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='JMB1eFY2' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-306456af-8544-440e-a9ee-d0783e13d0df', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,313 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-306456af-8544-440e-a9ee-d0783e13d0df', choices=[Choice(delta=ChoiceDelta(content='\n\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,314 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-306456af-8544-440e-a9ee-d0783e13d0df', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,314 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-306456af-8544-440e-a9ee-d0783e13d0df', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,316 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""

"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='jkhlhqCY' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-41a2ff94-2d9d-458e-b0fd-b8a7bce9c13a', choices=[Choice(delta=ChoiceDelta(content='##', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,317 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-41a2ff94-2d9d-458e-b0fd-b8a7bce9c13a', choices=[Choice(delta=ChoiceDelta(content='##', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,318 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-41a2ff94-2d9d-458e-b0fd-b8a7bce9c13a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,318 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-41a2ff94-2d9d-458e-b0fd-b8a7bce9c13a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='##', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,319 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='##'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='Jnn8jGk0' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ce02dbca-b244-45e6-a6dd-667e128483fc', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,360 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ce02dbca-b244-45e6-a6dd-667e128483fc', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,362 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ce02dbca-b244-45e6-a6dd-667e128483fc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,362 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ce02dbca-b244-45e6-a6dd-667e128483fc', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,363 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='AutJCZ3G' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-29a2bd33-96a6-428f-a883-e55d3d7a0fc8', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,364 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-29a2bd33-96a6-428f-a883-e55d3d7a0fc8', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,365 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-29a2bd33-96a6-428f-a883-e55d3d7a0fc8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,365 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-29a2bd33-96a6-428f-a883-e55d3d7a0fc8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,366 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='1'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='BKnwr8lU' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8a8855e4-ba10-42bd-9330-cbedfaf91191', choices=[Choice(delta=ChoiceDelta(content='0', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,406 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-8a8855e4-ba10-42bd-9330-cbedfaf91191', choices=[Choice(delta=ChoiceDelta(content='0', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='0', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,408 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='0', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8a8855e4-ba10-42bd-9330-cbedfaf91191', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='0', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,408 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-8a8855e4-ba10-42bd-9330-cbedfaf91191', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='0', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,409 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='0'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='GopXP9jQ' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f4f5e25c-9e55-4b6f-8b2e-a847c343ac37', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,410 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-f4f5e25c-9e55-4b6f-8b2e-a847c343ac37', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,411 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f4f5e25c-9e55-4b6f-8b2e-a847c343ac37', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,411 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-f4f5e25c-9e55-4b6f-8b2e-a847c343ac37', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,412 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='TJTNx5Ke' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-298f0b91-c8b2-4691-b93b-57553edbcdc5', choices=[Choice(delta=ChoiceDelta(content=' ç»“', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,453 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-298f0b91-c8b2-4691-b93b-57553edbcdc5', choices=[Choice(delta=ChoiceDelta(content=' ç»“', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ç»“', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,454 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ç»“', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-298f0b91-c8b2-4691-b93b-57553edbcdc5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ç»“', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,454 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-298f0b91-c8b2-4691-b93b-57553edbcdc5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ç»“', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,454 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' ç»“'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='zjDJHiPu' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-93297029-7f30-49fc-87e6-3b6c24b1f360', choices=[Choice(delta=ChoiceDelta(content='è®º', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,456 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-93297029-7f30-49fc-87e6-3b6c24b1f360', choices=[Choice(delta=ChoiceDelta(content='è®º', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è®º', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,457 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è®º', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-93297029-7f30-49fc-87e6-3b6c24b1f360', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è®º', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,457 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-93297029-7f30-49fc-87e6-3b6c24b1f360', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è®º', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,458 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è®º'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='OGz2rA35' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-29da85ce-d578-47f9-8b32-0c34b15fcd0c', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,459 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-29da85ce-d578-47f9-8b32-0c34b15fcd0c', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,460 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-29da85ce-d578-47f9-8b32-0c34b15fcd0c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,460 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-29da85ce-d578-47f9-8b32-0c34b15fcd0c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,461 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='GtSuA6EE' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b6cad500-3e1d-4b5b-b117-55b016a872d4', choices=[Choice(delta=ChoiceDelta(content='å»ºè®®', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,502 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b6cad500-3e1d-4b5b-b117-55b016a872d4', choices=[Choice(delta=ChoiceDelta(content='å»ºè®®', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å»ºè®®', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,503 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å»ºè®®', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b6cad500-3e1d-4b5b-b117-55b016a872d4', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å»ºè®®', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,503 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b6cad500-3e1d-4b5b-b117-55b016a872d4', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å»ºè®®', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,504 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å»ºè®®'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='0VLS4k6i' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a17dd80f-6d81-4c0c-b3c7-b4c559143db0', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,505 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a17dd80f-6d81-4c0c-b3c7-b4c559143db0', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,506 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a17dd80f-6d81-4c0c-b3c7-b4c559143db0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,506 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a17dd80f-6d81-4c0c-b3c7-b4c559143db0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,507 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='sEFtJfzA' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ca0ab7c3-7059-43cc-aca9-cd6fc8f88928', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,547 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ca0ab7c3-7059-43cc-aca9-cd6fc8f88928', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,549 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ca0ab7c3-7059-43cc-aca9-cd6fc8f88928', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,549 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ca0ab7c3-7059-43cc-aca9-cd6fc8f88928', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,550 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='FqfolMey' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a4b154cb-adb3-46fc-97f9-8a9157a0ded5', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,551 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a4b154cb-adb3-46fc-97f9-8a9157a0ded5', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,552 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a4b154cb-adb3-46fc-97f9-8a9157a0ded5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,552 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a4b154cb-adb3-46fc-97f9-8a9157a0ded5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,552 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='cPZHohS9' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-af9c432e-7894-4bf7-9b37-76079702197a', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,594 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-af9c432e-7894-4bf7-9b37-76079702197a', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,596 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-af9c432e-7894-4bf7-9b37-76079702197a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,596 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-af9c432e-7894-4bf7-9b37-76079702197a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,597 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='1'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='W03yFyYh' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b9299a2f-cd8d-4cc7-a04e-d8332483c5a8', choices=[Choice(delta=ChoiceDelta(content='0', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,598 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-b9299a2f-cd8d-4cc7-a04e-d8332483c5a8', choices=[Choice(delta=ChoiceDelta(content='0', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='0', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,599 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='0', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b9299a2f-cd8d-4cc7-a04e-d8332483c5a8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='0', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,599 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-b9299a2f-cd8d-4cc7-a04e-d8332483c5a8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='0', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,599 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='0'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='TnIjOT5x' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5cbcf467-7079-405d-af73-1dd21b2ca5ff', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,639 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5cbcf467-7079-405d-af73-1dd21b2ca5ff', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,641 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5cbcf467-7079-405d-af73-1dd21b2ca5ff', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,642 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5cbcf467-7079-405d-af73-1dd21b2ca5ff', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,644 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='kQPpM7F0' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-afec602a-bacb-4118-9328-30c04d3d66cb', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,645 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-afec602a-bacb-4118-9328-30c04d3d66cb', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,646 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-afec602a-bacb-4118-9328-30c04d3d66cb', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,646 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-afec602a-bacb-4118-9328-30c04d3d66cb', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,647 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='1'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='JhMchamO' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5b0f805e-7f01-46bc-839c-479fb7b6766a', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,648 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-5b0f805e-7f01-46bc-839c-479fb7b6766a', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,649 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5b0f805e-7f01-46bc-839c-479fb7b6766a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,649 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-5b0f805e-7f01-46bc-839c-479fb7b6766a', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-17edbed2-c401-49e3-a2ef-56ed02952e51', choices=[Choice(delta=ChoiceDelta(content=' è¡€', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,686 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-17edbed2-c401-49e3-a2ef-56ed02952e51', choices=[Choice(delta=ChoiceDelta(content=' è¡€', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' è¡€', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,687 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' è¡€', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-17edbed2-c401-49e3-a2ef-56ed02952e51', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' è¡€', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,688 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-17edbed2-c401-49e3-a2ef-56ed02952e51', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' è¡€', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='çš„'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: çš„
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å¯¹æ¯”'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å¯¹æ¯”
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='9'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 9
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='2'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 2
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='äºš'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: äºš
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç»„'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç»„
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç ”ç©¶'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç ”ç©¶
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸­çš„'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸­çš„
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç–—æ•ˆ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç–—æ•ˆ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å·®å¼‚'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å·®å¼‚
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='9'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 9
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='3'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 3
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¯æ®'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¯æ®
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è´¨é‡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è´¨é‡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç ”ç©¶'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç ”ç©¶
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å€š'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å€š
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='åˆ†æ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: åˆ†æ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""

"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 


è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='##'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ##
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='1'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 1
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='0'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 0
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' ç»“'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  ç»“
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è®º'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è®º
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å»ºè®®'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å»ºè®®
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='1'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 1
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='0'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 0
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='1'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 1
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' è¡€'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  è¡€2025-11-18 15:29:22,690 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' è¡€'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='tHfdH17v' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3103b95e-bfe1-40e1-8726-90dc6b28141f', choices=[Choice(delta=ChoiceDelta(content='å°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,690 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3103b95e-bfe1-40e1-8726-90dc6b28141f', choices=[Choice(delta=ChoiceDelta(content='å°', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,692 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3103b95e-bfe1-40e1-8726-90dc6b28141f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,692 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3103b95e-bfe1-40e1-8726-90dc6b28141f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å°', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,693 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å°'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='uT0nJ5Pm' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1b0966c3-3a06-48c5-95bf-597432d47989', choices=[Choice(delta=ChoiceDelta(content='æ¿', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,733 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1b0966c3-3a06-48c5-95bf-597432d47989', choices=[Choice(delta=ChoiceDelta(content='æ¿', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,735 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1b0966c3-3a06-48c5-95bf-597432d47989', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,735 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1b0966c3-3a06-48c5-95bf-597432d47989', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ¿', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,736 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ¿'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='eJLJgKNJ' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9adf2c5b-bc88-4587-a72d-293d19070814', choices=[Choice(delta=ChoiceDelta(content='è¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,736 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9adf2c5b-bc88-4587-a72d-293d19070814', choices=[Choice(delta=ChoiceDelta(content='è¡', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,737 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9adf2c5b-bc88-4587-a72d-293d19070814', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,737 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9adf2c5b-bc88-4587-a72d-293d19070814', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è¡', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,739 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è¡'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='18wulQDq' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-630e9504-39dc-48dc-b777-129fd0bdbc33', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,780 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-630e9504-39dc-48dc-b777-129fd0bdbc33', choices=[Choice(delta=ChoiceDelta(content='ç”Ÿç‰©', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,782 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-630e9504-39dc-48dc-b777-129fd0bdbc33', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,782 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-630e9504-39dc-48dc-b777-129fd0bdbc33', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç”Ÿç‰©', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,783 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç”Ÿç‰©'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='MQCXd6Oc' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ea176580-bc7d-4337-b7fd-cb7a5722b143', choices=[Choice(delta=ChoiceDelta(content='çš„ç ”ç©¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,784 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ea176580-bc7d-4337-b7fd-cb7a5722b143', choices=[Choice(delta=ChoiceDelta(content='çš„ç ”ç©¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='çš„ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,784 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='çš„ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ea176580-bc7d-4337-b7fd-cb7a5722b143', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='çš„ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,784 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ea176580-bc7d-4337-b7fd-cb7a5722b143', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='çš„ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,786 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='çš„ç ”ç©¶'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='PkdItZj7' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c0961ed3-a9e0-4550-bd66-3abe6516c655', choices=[Choice(delta=ChoiceDelta(content='ä»·å€¼', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,827 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c0961ed3-a9e0-4550-bd66-3abe6516c655', choices=[Choice(delta=ChoiceDelta(content='ä»·å€¼', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä»·å€¼', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,829 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä»·å€¼', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c0961ed3-a9e0-4550-bd66-3abe6516c655', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä»·å€¼', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,829 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c0961ed3-a9e0-4550-bd66-3abe6516c655', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä»·å€¼', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,832 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä»·å€¼'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='sOHiz4ch' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3bdadc0d-e4aa-45dd-8a7a-12c38034f485', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,833 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3bdadc0d-e4aa-45dd-8a7a-12c38034f485', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450957, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,836 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3bdadc0d-e4aa-45dd-8a7a-12c38034f485', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,836 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3bdadc0d-e4aa-45dd-8a7a-12c38034f485', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,838 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='fQfyefHH' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-387fffbf-2768-4845-9ec4-ec25f9be90af', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,874 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-387fffbf-2768-4845-9ec4-ec25f9be90af', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,876 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-387fffbf-2768-4845-9ec4-ec25f9be90af', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,876 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-387fffbf-2768-4845-9ec4-ec25f9be90af', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,878 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='W7QuESkx' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-373a1d61-fc92-4ad9-b58a-bbfe05509a27', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,879 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-373a1d61-fc92-4ad9-b58a-bbfe05509a27', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,880 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-373a1d61-fc92-4ad9-b58a-bbfe05509a27', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,880 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-373a1d61-fc92-4ad9-b58a-bbfe05509a27', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,881 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='jyzblQUa' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3649b502-4a0c-41c5-a5e7-edc7f9e81db2', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,881 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3649b502-4a0c-41c5-a5e7-edc7f9e81db2', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,882 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3649b502-4a0c-41c5-a5e7-edc7f9e81db2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,882 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3649b502-4a0c-41c5-a5e7-edc7f9e81db2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,883 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='1'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='z6bH0O5j' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3741b660-7923-47d0-b2a5-1c0ec3a31ff0', choices=[Choice(delta=ChoiceDelta(content='0', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,919 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-3741b660-7923-47d0-b2a5-1c0ec3a31ff0', choices=[Choice(delta=ChoiceDelta(content='0', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='0', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,920 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='0', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3741b660-7923-47d0-b2a5-1c0ec3a31ff0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='0', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,920 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-3741b660-7923-47d0-b2a5-1c0ec3a31ff0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='0', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,921 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='0'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='5fziZ7je' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1587a9e0-678e-4299-bb36-0f7bf738f298', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,922 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1587a9e0-678e-4299-bb36-0f7bf738f298', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,924 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1587a9e0-678e-4299-bb36-0f7bf738f298', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,924 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1587a9e0-678e-4299-bb36-0f7bf738f298', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,925 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='e9qJtZly' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d9eef408-eaeb-4277-9849-99196923e66e', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,965 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d9eef408-eaeb-4277-9849-99196923e66e', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,966 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d9eef408-eaeb-4277-9849-99196923e66e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,966 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d9eef408-eaeb-4277-9849-99196923e66e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='2', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,967 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='2'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='aB2eiOKx' timestamp=1763450949.457893
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-28b61e4e-4d96-4e08-ad22-5573a0331b38', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:22,968 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-28b61e4e-4d96-4e08-ad22-5573a0331b38', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:22,969 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:22 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-28b61e4e-4d96-4e08-ad22-5573a0331b38', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:22,969 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-28b61e4e-4d96-4e08-ad22-5573a0331b38', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9f2b418e-0a15-4fe5-892c-88e90ea2700f', choices=[Choice(delta=ChoiceDelta(content=' è¿›', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:23,012 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9f2b418e-0a15-4fe5-892c-88e90ea2700f', choices=[Choice(delta=ChoiceDelta(content=' è¿›', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' è¿›', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:23,013 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' è¿›', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9f2b418e-0a15-4fe5-892c-88e90ea2700f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' è¿›', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,013 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9f2b418e-0a15-4fe5-892c-88e90ea2700f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' è¿›', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,014 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' è¿›'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='W18GBXP7' timestamp=1763450949.457893
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-03fa4ddb-06e8-4cfe-bb24-e4201aeeefcb', choices=[Choice(delta=ChoiceDelta(content='ä¸€æ­¥', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:23,016 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-03fa4ddb-06e8-4cfe-bb24-e4201aeeefcb', choices=[Choice(delta=ChoiceDelta(content='ä¸€æ­¥', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸€æ­¥', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:23,017 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸€æ­¥', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-03fa4ddb-06e8-4cfe-bb24-e4201aeeefcb', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸€æ­¥', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,017 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-03fa4ddb-06e8-4cfe-bb24-e4201aeeefcb', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸€æ­¥', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,018 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸€æ­¥'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='AsWpWtGk' timestamp=1763450949.457893
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-df04cbfb-ef60-4d75-98b3-b90515a19500', choices=[Choice(delta=ChoiceDelta(content='ç ”ç©¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:23,058 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-df04cbfb-ef60-4d75-98b3-b90515a19500', choices=[Choice(delta=ChoiceDelta(content='ç ”ç©¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:23,059 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-df04cbfb-ef60-4d75-98b3-b90515a19500', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,059 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-df04cbfb-ef60-4d75-98b3-b90515a19500', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,060 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç ”ç©¶'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='1sJ9khso' timestamp=1763450949.457893
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-842f387d-3cd9-4c8c-9b33-22792d8db406', choices=[Choice(delta=ChoiceDelta(content='æ–¹å‘', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:23,061 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-842f387d-3cd9-4c8c-9b33-22792d8db406', choices=[Choice(delta=ChoiceDelta(content='æ–¹å‘', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ–¹å‘', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:23,062 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ–¹å‘', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-842f387d-3cd9-4c8c-9b33-22792d8db406', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ–¹å‘', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,062 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-842f387d-3cd9-4c8c-9b33-22792d8db406', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ–¹å‘', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,063 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ–¹å‘'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='gxrbCty5' timestamp=1763450949.457893
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-988f4c74-e505-4715-9878-b44f4f2e1b49', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:23,104 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-988f4c74-e505-4715-9878-b44f4f2e1b49', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:23,106 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-988f4c74-e505-4715-9878-b44f4f2e1b49', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,107 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-988f4c74-e505-4715-9878-b44f4f2e1b49', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,108 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='bfN9u7sG' timestamp=1763450949.457893
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-10df393b-c5a9-4e1c-ad04-8333a0f923cf', choices=[Choice(delta=ChoiceDelta(content='æ”¿ç­–', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:23,108 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-10df393b-c5a9-4e1c-ad04-8333a0f923cf', choices=[Choice(delta=ChoiceDelta(content='æ”¿ç­–', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ”¿ç­–', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:23,110 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æ”¿ç­–', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-10df393b-c5a9-4e1c-ad04-8333a0f923cf', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ”¿ç­–', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,110 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-10df393b-c5a9-4e1c-ad04-8333a0f923cf', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æ”¿ç­–', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,112 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æ”¿ç­–'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='0T1map8v' timestamp=1763450949.457893
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d3be6e63-6b4e-4b96-8237-4537fee39080', choices=[Choice(delta=ChoiceDelta(content='å»ºè®®', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:23,113 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-d3be6e63-6b4e-4b96-8237-4537fee39080', choices=[Choice(delta=ChoiceDelta(content='å»ºè®®', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å»ºè®®', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:23,114 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='å»ºè®®', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d3be6e63-6b4e-4b96-8237-4537fee39080', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å»ºè®®', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,114 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-d3be6e63-6b4e-4b96-8237-4537fee39080', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='å»ºè®®', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,116 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='å»ºè®®'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='uSBvbaja' timestamp=1763450949.457893
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-52da001f-93a0-48b7-bb30-551af7d9647e', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:23,151 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-52da001f-93a0-48b7-bb30-551af7d9647e', choices=[Choice(delta=ChoiceDelta(content='\n', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:23,152 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-52da001f-93a0-48b7-bb30-551af7d9647e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,152 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-52da001f-93a0-48b7-bb30-551af7d9647e', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='\n', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,153 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text="""
"""
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='zk5BZyjO' timestamp=1763450949.457893
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1e744327-f74c-46d9-86bd-3a0035680f72', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:23,154 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-1e744327-f74c-46d9-86bd-3a0035680f72', choices=[Choice(delta=ChoiceDelta(content='###', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:23,156 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1e744327-f74c-46d9-86bd-3a0035680f72', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,156 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-1e744327-f74c-46d9-86bd-3a0035680f72', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='###', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,157 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='###'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='mhcsQR8L' timestamp=1763450949.457893
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-01ce7d64-a1d4-429c-8fd7-b8c71e3fb5d2', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:23,197 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-01ce7d64-a1d4-429c-8fd7-b8c71e3fb5d2', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:23,199 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-01ce7d64-a1d4-429c-8fd7-b8c71e3fb5d2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,199 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-01ce7d64-a1d4-429c-8fd7-b8c71e3fb5d2', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,200 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='HjvBH2HK' timestamp=1763450949.457893
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ce3414f8-5457-43ba-93bf-3e9ae0af54d5', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:23,201 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-ce3414f8-5457-43ba-93bf-3e9ae0af54d5', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:23,202 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ce3414f8-5457-43ba-93bf-3e9ae0af54d5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,202 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-ce3414f8-5457-43ba-93bf-3e9ae0af54d5', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='1', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,203 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='1'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='aAUWQYfp' timestamp=1763450949.457893
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-002b4adc-9caf-46e3-bc12-2c06eb05779f', choices=[Choice(delta=ChoiceDelta(content='0', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:23,244 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-002b4adc-9caf-46e3-bc12-2c06eb05779f', choices=[Choice(delta=ChoiceDelta(content='0', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='0', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:23,246 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='0', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-002b4adc-9caf-46e3-bc12-2c06eb05779f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='0', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,246 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-002b4adc-9caf-46e3-bc12-2c06eb05779f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='0', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,247 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='0'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='g9lZIUv1' timestamp=1763450949.457893
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-be6fd065-fdf4-4368-b4af-ecb8d6e08269', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:23,249 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-be6fd065-fdf4-4368-b4af-ecb8d6e08269', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:23,250 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-be6fd065-fdf4-4368-b4af-ecb8d6e08269', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,250 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-be6fd065-fdf4-4368-b4af-ecb8d6e08269', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='.', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,251 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='.'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='uuhzEWQS' timestamp=1763450949.457893
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9f8ac21b-ee3e-45c4-9a3c-19aee1ef836f', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:23,290 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9f8ac21b-ee3e-45c4-9a3c-19aee1ef836f', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:23,292 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9f8ac21b-ee3e-45c4-9a3c-19aee1ef836f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,292 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9f8ac21b-ee3e-45c4-9a3c-19aee1ef836f', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='3', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,293 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='3'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='uwUiZIpB' timestamp=1763450949.457893
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a4d02d78-2f9b-45ab-a44b-425b853d39bb', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:23,294 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-a4d02d78-2f9b-45ab-a44b-425b853d39bb', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:23,294 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a4d02d78-2f9b-45ab-a44b-425b853d39bb', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,294 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-a4d02d78-2f9b-45ab-a44b-425b853d39bb', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content=' ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,296 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text=' '
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='zTOozqBn' timestamp=1763450949.457893
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-04a91fc6-7390-4bba-80cb-434f36bfc685', choices=[Choice(delta=ChoiceDelta(content='æœªæ¥', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:23,336 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-04a91fc6-7390-4bba-80cb-434f36bfc685', choices=[Choice(delta=ChoiceDelta(content='æœªæ¥', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æœªæ¥', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:23,337 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='æœªæ¥', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-04a91fc6-7390-4bba-80cb-434f36bfc685', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æœªæ¥', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,338 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-04a91fc6-7390-4bba-80cb-434f36bfc685', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='æœªæ¥', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,339 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='æœªæ¥'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='qv7PRwaX' timestamp=1763450949.457893
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-fdd7200c-6d77-45ce-aa5a-55a9f361ba13', choices=[Choice(delta=ChoiceDelta(content='è½¬åŒ–', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:23,340 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-fdd7200c-6d77-45ce-aa5a-55a9f361ba13', choices=[Choice(delta=ChoiceDelta(content='è½¬åŒ–', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è½¬åŒ–', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:23,341 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è½¬åŒ–', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-fdd7200c-6d77-45ce-aa5a-55a9f361ba13', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è½¬åŒ–', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,341 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-fdd7200c-6d77-45ce-aa5a-55a9f361ba13', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è½¬åŒ–', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,342 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è½¬åŒ–'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='j1EgHDFA' timestamp=1763450949.457893
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9c4a22a6-56e7-41d2-a435-d9eb2dec1cb8', choices=[Choice(delta=ChoiceDelta(content='ç ”ç©¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:23,382 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9c4a22a6-56e7-41d2-a435-d9eb2dec1cb8', choices=[Choice(delta=ChoiceDelta(content='ç ”ç©¶', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:23,383 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9c4a22a6-56e7-41d2-a435-d9eb2dec1cb8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,383 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9c4a22a6-56e7-41d2-a435-d9eb2dec1cb8', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ç ”ç©¶', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,384 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ç ”ç©¶'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='TAbE87rG' timestamp=1763450949.457893
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7f9cf1cd-2f52-4e2e-b0d0-b83f16eb5d8d', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:23,385 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-7f9cf1cd-2f52-4e2e-b0d0-b83f16eb5d8d', choices=[Choice(delta=ChoiceDelta(content='ä¸', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:23,386 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7f9cf1cd-2f52-4e2e-b0d0-b83f16eb5d8d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,386 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-7f9cf1cd-2f52-4e2e-b0d0-b83f16eb5d8d', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,387 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='kZFbGaX1' timestamp=1763450949.457893
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-06ea4050-f0ec-4fa1-8aa5-166438e849f0', choices=[Choice(delta=ChoiceDelta(content='ä¸´åºŠ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:23,388 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-06ea4050-f0ec-4fa1-8aa5-166438e849f0', choices=[Choice(delta=ChoiceDelta(content='ä¸´åºŠ', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:23,389 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-06ea4050-f0ec-4fa1-8aa5-166438e849f0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,390 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-06ea4050-f0ec-4fa1-8aa5-166438e849f0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='ä¸´åºŠ', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,391 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='ä¸´åºŠ'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='GBK1DlHo' timestamp=1763450949.457893
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9c0b785e-d742-46b4-8257-15848c1b80fe', choices=[Choice(delta=ChoiceDelta(content='è½¬åŒ–', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:23,429 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-9c0b785e-d742-46b4-8257-15848c1b80fe', choices=[Choice(delta=ChoiceDelta(content='è½¬åŒ–', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è½¬åŒ–', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:23,430 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è½¬åŒ–', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9c0b785e-d742-46b4-8257-15848c1b80fe', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è½¬åŒ–', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,431 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-9c0b785e-d742-46b4-8257-15848c1b80fe', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è½¬åŒ–', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,432 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è½¬åŒ–'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='AHYAAK22' timestamp=1763450949.457893
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-66d2cc99-9a0e-4ea5-8e53-6f538882034c', choices=[Choice(delta=ChoiceDelta(content='è·¯å¾„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:23,432 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-66d2cc99-9a0e-4ea5-8e53-6f538882034c', choices=[Choice(delta=ChoiceDelta(content='è·¯å¾„', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è·¯å¾„', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:23,434 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='è·¯å¾„', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-66d2cc99-9a0e-4ea5-8e53-6f538882034c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è·¯å¾„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,434 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-66d2cc99-9a0e-4ea5-8e53-6f538882034c', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='è·¯å¾„', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,434 [INFO] å…¶å®ƒçš„äº‹ä»¶,ä¾‹å¦‚æ•°æ®çš„æµäº‹ä»¶ content=Content(
  parts=[
    Part(
      text='è·¯å¾„'
    ),
  ],
  role='model'
) grounding_metadata=None partial=True turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-8533966a-8ab1-45c8-93f3-5773d1192baa' author='outline_agent' actions=EventActions(skip_summarization=None, state_delta={'language': 'chinese'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='KT8dOjnv' timestamp=1763450949.457893
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c276a4ca-a8b9-4fd8-a76d-d3973f85a2a0', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
2025-11-18 15:29:23,477 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-c276a4ca-a8b9-4fd8-a76d-d3973f85a2a0', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason=None, index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:23,478 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c276a4ca-a8b9-4fd8-a76d-d3973f85a2a0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
2025-11-18 15:29:23,479 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-c276a4ca-a8b9-4fd8-a76d-d3973f85a2a0', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, citations=None, service_tier=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1824 - PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-81aad377-a21b-4ee2-bf0b-c4db51b81aef', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason='stop', index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=658, prompt_tokens=1462, total_tokens=2120, completion_tokens_details=None, prompt_tokens_details=None))
2025-11-18 15:29:23,480 [DEBUG] PROCESSED ASYNC CHUNK PRE CHUNK CREATOR: ChatCompletionChunk(id='chatcmpl-81aad377-a21b-4ee2-bf0b-c4db51b81aef', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=[]), finish_reason='stop', index=0, logprobs=None)], created=1763450958, model='qwen3', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=658, prompt_tokens=1462, total_tokens=2120, completion_tokens_details=None, prompt_tokens_details=None))
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:925 - model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
2025-11-18 15:29:23,482 [DEBUG] model_response.choices[0].delta inside is_chunk_non_empty: Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None)
[92m15:29:23 - LiteLLM:DEBUG[0m: streaming_handler.py:1831 - PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-81aad377-a21b-4ee2-bf0b-c4db51b81aef', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=658, prompt_tokens=1462, total_tokens=2120, completion_tokens_details=None, prompt_tokens_details=None), citations=None, service_tier=None)
2025-11-18 15:29:23,482 [DEBUG] PROCESSED ASYNC CHUNK POST CHUNK CREATOR: ModelResponseStream(id='chatcmpl-81aad377-a21b-4ee2-bf0b-c4db51b81aef', created=1763450949, model='qwen3', object='chat.completion.chunk', system_fingerprint=None, choices=[StreamingChoices(finish_reason=None, index=0, delta=Delta(provider_specific_fields=None, refusal=None, content='', role=None, function_call=None, tool_calls=[], audio=None), logprobs=None)], provider_specific_fields=None, usage=Usage(completion_tokens=658, prompt_tokens=1462, total_tokens=2120, completion_tokens_details=None, prompt_tokens_details=None), citations=None, service_tier=None)

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å°'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å°
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ¿'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ¿
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è¡'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è¡
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç”Ÿç‰©'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç”Ÿç‰©
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='çš„ç ”ç©¶'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: çš„ç ”ç©¶
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä»·å€¼'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä»·å€¼
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='1'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 1
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='0'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 0
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='2'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 2
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' è¿›'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  è¿›
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸€æ­¥'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸€æ­¥
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç ”ç©¶'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç ”ç©¶
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ–¹å‘'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ–¹å‘
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æ”¿ç­–'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æ”¿ç­–
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='å»ºè®®'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: å»ºè®®
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""
"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 

è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='###'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ###
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='1'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 1
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='0'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 0
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='.'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: .
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='3'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: 3
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text=' '
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯:  
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='æœªæ¥'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: æœªæ¥
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è½¬åŒ–'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è½¬åŒ–
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ç ”ç©¶'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ç ”ç©¶
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='ä¸´åºŠ'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: ä¸´åºŠ
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è½¬åŒ–'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è½¬åŒ–
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text='è·¯å¾„'
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: è·¯å¾„
è°ƒç”¨äº†outline_agentæ¨¡å‹åçš„callback, è¿™æ¬¡æ¨¡å‹å›å¤[Part(
  text="""<think>

</think>

# è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©åœ¨ç³–å°¿ç—…è¶³æºƒç–¡æ²»ç–—ä¸­çš„ä½œç”¨åŠæœºåˆ¶ç ”ç©¶è¿›å±•

## æ‘˜è¦
- èƒŒæ™¯ï¼šç³–å°¿ç—…è¶³æºƒç–¡é«˜å‘ä¸”éš¾æ²»ï¼Œç°æœ‰ç–—æ³•å±€é™
- ç›®çš„ï¼šç»¼è¿°è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©çš„æ²»ç–—æ½œåŠ›ä¸ä½œç”¨æœºåˆ¶
- æ–¹æ³•ï¼šæ£€ç´¢è¿‘5å¹´æ–‡çŒ®ï¼Œèšç„¦ä½œç”¨æœºåˆ¶ä¸ä¸´åºŠè½¬åŒ–
- ä¸»è¦å‘ç°ï¼šè¡€å°æ¿è¡ç”Ÿç‰©ä¿ƒè¿›æ„ˆåˆã€æŠ—ç‚åŠè¡€ç®¡ç”Ÿæˆ
- ç»“è®ºä¸å±•æœ›ï¼šæ ‡å‡†åŒ–åˆ¶å¤‡ä¸ä¸´åºŠéªŒè¯ä»æ˜¯å…³é”®æŒ‘æˆ˜
- å…³é”®è¯ï¼šè¡€å°æ¿ï¼›è¡ç”Ÿç‰©ï¼›ç³–å°¿ç—…è¶³æºƒç–¡ï¼›ä½œç”¨æœºåˆ¶ï¼›æ²»ç–—

## 1. å¼•è¨€
### 1.1 ç³–å°¿ç—…è¶³æºƒç–¡ç°çŠ¶ä¸æ²»ç–—æŒ‘æˆ˜
### 1.2 è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©ç ”ç©¶èƒŒæ™¯
### 1.3 æœ¬ç»¼è¿°çš„ç ”ç©¶ç›®æ ‡ä¸æ„ä¹‰

## 2. è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©çš„ç”Ÿç‰©å­¦ç‰¹æ€§
### 2.1 è¡€å°æ¿åŠŸèƒ½ä¸åœ¨ä¼¤å£ä¿®å¤ä¸­çš„ä½œç”¨
### 2.2 è¡ç”Ÿç‰©ç±»å‹ä¸åˆ¶å¤‡æ–¹æ³•
### 2.3 ä¸åŒè¡ç”Ÿç‰©çš„ç”Ÿç‰©æ´»æ€§æ¯”è¾ƒ

## 3. ä½œç”¨æœºåˆ¶ç ”ç©¶
### 3.1 ä¿ƒè¿›ç»†èƒå¢æ®–ä¸è¿ç§»
### 3.2 æŠ—ç‚ä¸å…ç–«è°ƒèŠ‚ä½œç”¨
### 3.3 ä¿ƒè¿›è¡€ç®¡ç”Ÿæˆä¸ç»„ç»‡ä¿®å¤

## 4. ä¸´åºŠåº”ç”¨ä¸ç–—æ•ˆè¯„ä¼°
### 4.1 ä¸´åºŠè¯•éªŒç»“æœä¸ç–—æ•ˆæ•°æ®
### 4.2 ä¸åŒäººç¾¤ä¸­çš„æ²»ç–—æ•ˆæœå·®å¼‚
### 4.3 ä¸å…¶ä»–æ²»ç–—æ‰‹æ®µçš„ååŒæ•ˆåº”

## 5. å®‰å…¨æ€§ä¸å‰¯ä½œç”¨
### 5.1 çŸ­æœŸä¸é•¿æœŸå‰¯ä½œç”¨
### 5.2 ç‰¹æ®Šäººç¾¤çš„é£é™©è¯„ä¼°
### 5.3 å®‰å…¨æ€§æ•°æ®ä¸ä¸´åºŠç›‘æµ‹

## 6. åˆ¶å¤‡ä¸æ ‡å‡†åŒ–æŒ‘æˆ˜
### 6.1 åˆ¶å¤‡å·¥è‰ºä¸è´¨é‡æ§åˆ¶
### 6.2 å®‰å…¨æ ‡å‡†ä¸ç›‘ç®¡è¦æ±‚
### 6.3 è¡Œä¸šæ ‡å‡†åŒ–è¿›å±•ä¸éšœç¢

## 7. çœŸå®ä¸–ç•Œè¯æ®ä¸ç°åœºå®è·µ
### 7.1 åŒ»é™¢ä¸ç¤¾åŒºåº”ç”¨æ¡ˆä¾‹
### 7.2 æˆæœ¬æ•ˆç›Šåˆ†æä¸ç»æµå½±å“
### 7.3 ä¸´åºŠå®è·µä¸­çš„åº”ç”¨å±€é™

## 8. æœªæ¥å‘å±•æ–¹å‘
### 8.1 æ–°å‹è¡ç”Ÿç‰©ç ”å‘è¶‹åŠ¿
### 8.2 ä¸ªæ€§åŒ–æ²»ç–—ä¸ç²¾å‡†åŒ»å­¦
### 8.3 ä¸å…¶ä»–æ²»ç–—æŠ€æœ¯çš„æ•´åˆ

## 9. æ¯”è¾ƒä¸äº‰è®®ç‚¹
### 9.1 è¡ç”Ÿç‰©ä¸ä¼ ç»Ÿæ²»ç–—çš„å¯¹æ¯”
### 9.2 äºšç»„ç ”ç©¶ä¸­çš„ç–—æ•ˆå·®å¼‚
### 9.3 è¯æ®è´¨é‡ä¸ç ”ç©¶åå€šåˆ†æ

## 10. ç»“è®ºä¸å»ºè®®
### 10.1 è¡€å°æ¿è¡ç”Ÿç‰©çš„ç ”ç©¶ä»·å€¼
### 10.2 è¿›ä¸€æ­¥ç ”ç©¶æ–¹å‘ä¸æ”¿ç­–å»ºè®®
### 10.3 æœªæ¥è½¬åŒ–ç ”ç©¶ä¸ä¸´åºŠè½¬åŒ–è·¯å¾„"""
)]æ¡ä¿¡æ¯,metadataæ•°æ®ä¸ºï¼š{'language': 'chinese', 'user_id': ''},å›å¤å†…å®¹æ˜¯: <think>

</think>

# è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©åœ¨ç³–å°¿ç—…è¶³æºƒç–¡æ²»ç–—ä¸­çš„ä½œç”¨åŠæœºåˆ¶ç ”ç©¶è¿›å±•

## æ‘˜è¦
- èƒŒæ™¯ï¼šç³–å°¿ç—…è¶³æºƒç–¡é«˜å‘ä¸”éš¾æ²»ï¼Œç°æœ‰ç–—æ³•å±€é™
- ç›®çš„ï¼šç»¼è¿°è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©çš„æ²»ç–—æ½œåŠ›ä¸ä½œç”¨æœºåˆ¶
- æ–¹æ³•ï¼šæ£€ç´¢è¿‘5å¹´æ–‡çŒ®ï¼Œèšç„¦ä½œç”¨æœºåˆ¶ä¸ä¸´åºŠè½¬åŒ–
- ä¸»è¦å‘ç°ï¼šè¡€å°æ¿è¡ç”Ÿç‰©ä¿ƒè¿›æ„ˆåˆã€æŠ—ç‚åŠè¡€ç®¡ç”Ÿæˆ
- ç»“è®ºä¸å±•æœ›ï¼šæ ‡å‡†åŒ–åˆ¶å¤‡ä¸ä¸´åºŠéªŒè¯ä»æ˜¯å…³é”®æŒ‘æˆ˜
- å…³é”®è¯ï¼šè¡€å°æ¿ï¼›è¡ç”Ÿç‰©ï¼›ç³–å°¿ç—…è¶³æºƒç–¡ï¼›ä½œç”¨æœºåˆ¶ï¼›æ²»ç–—

## 1. å¼•è¨€
### 1.1 ç³–å°¿ç—…è¶³æºƒç–¡ç°çŠ¶ä¸æ²»ç–—æŒ‘æˆ˜
### 1.2 è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©ç ”ç©¶èƒŒæ™¯
### 1.3 æœ¬ç»¼è¿°çš„ç ”ç©¶ç›®æ ‡ä¸æ„ä¹‰

## 2. è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©çš„ç”Ÿç‰©å­¦ç‰¹æ€§
### 2.1 è¡€å°æ¿åŠŸèƒ½ä¸åœ¨ä¼¤å£ä¿®å¤ä¸­çš„ä½œç”¨
### 2.2 è¡ç”Ÿç‰©ç±»å‹ä¸åˆ¶å¤‡æ–¹æ³•
### 2.3 ä¸åŒè¡ç”Ÿç‰©çš„ç”Ÿç‰©æ´»æ€§æ¯”è¾ƒ

## 3. ä½œç”¨æœºåˆ¶ç ”ç©¶
### 3.1 ä¿ƒè¿›ç»†èƒå¢æ®–ä¸è¿ç§»
### 3.2 æŠ—ç‚ä¸å…ç–«è°ƒèŠ‚ä½œç”¨
### 3.3 ä¿ƒè¿›è¡€ç®¡ç”Ÿæˆä¸ç»„ç»‡ä¿®å¤

## 4. ä¸´åºŠåº”ç”¨ä¸ç–—æ•ˆè¯„ä¼°
### 4.1 ä¸´åºŠè¯•éªŒç»“æœä¸ç–—æ•ˆæ•°æ®
### 4.2 ä¸åŒäººç¾¤ä¸­çš„æ²»ç–—æ•ˆæœå·®å¼‚
### 4.3 ä¸å…¶ä»–æ²»ç–—æ‰‹æ®µçš„ååŒæ•ˆåº”

## 5. å®‰å…¨æ€§ä¸å‰¯ä½œç”¨
### 5.1 çŸ­æœŸä¸é•¿æœŸå‰¯ä½œç”¨
### 5.2 ç‰¹æ®Šäººç¾¤çš„é£é™©è¯„ä¼°
### 5.3 å®‰å…¨æ€§æ•°æ®ä¸ä¸´åºŠç›‘æµ‹

## 6. åˆ¶å¤‡ä¸æ ‡å‡†åŒ–æŒ‘æˆ˜
### 6.1 åˆ¶å¤‡å·¥è‰ºä¸è´¨é‡æ§åˆ¶
### 6.2 å®‰å…¨æ ‡å‡†ä¸ç›‘ç®¡è¦æ±‚
### 6.3 è¡Œä¸šæ ‡å‡†åŒ–è¿›å±•ä¸éšœç¢

## 7. çœŸå®ä¸–ç•Œè¯æ®ä¸ç°åœºå®è·µ
### 7.1 åŒ»é™¢ä¸ç¤¾åŒºåº”ç”¨æ¡ˆä¾‹
### 7.2 æˆæœ¬æ•ˆç›Šåˆ†æä¸ç»æµå½±å“
### 7.3 ä¸´åºŠå®è·µä¸­çš„åº”ç”¨å±€é™

## 8. æœªæ¥å‘å±•æ–¹å‘
### 8.1 æ–°å‹è¡ç”Ÿç‰©ç ”å‘è¶‹åŠ¿
### 8.2 ä¸ªæ€§åŒ–æ²»ç–—ä¸ç²¾å‡†åŒ»å­¦
### 8.3 ä¸å…¶ä»–æ²»ç–—æŠ€æœ¯çš„æ•´åˆ

## 9. æ¯”è¾ƒä¸äº‰è®®ç‚¹
### 9.1 è¡ç”Ÿç‰©ä¸ä¼ ç»Ÿæ²»ç–—çš„å¯¹æ¯”
### 9.2 äºšç»„ç ”ç©¶ä¸­çš„ç–—æ•ˆå·®å¼‚
### 9.3 è¯æ®è´¨é‡ä¸ç ”ç©¶åå€šåˆ†æ

## 10. ç»“è®ºä¸å»ºè®®
### 10.1 è¡€å°æ¿è¡ç”Ÿç‰©çš„ç ”ç©¶ä»·å€¼
### 10.2 è¿›ä¸€æ­¥ç ”ç©¶æ–¹å‘ä¸æ”¿ç­–å»ºè®®
### 10.3 æœªæ¥è½¬åŒ–ç ”ç©¶ä¸ä¸´åºŠè½¬åŒ–è·¯å¾„[92m15:29:23 - LiteLLM:DEBUG[0m: litellm_logging.py:1660 - Logging Details LiteLLM-Success Call: Cache_hit=False
2025-11-18 15:29:23,519 [DEBUG] Logging Details LiteLLM-Success Call: Cache_hit=False
[92m15:29:23 - LiteLLM:DEBUG[0m: litellm_logging.py:1689 - Logging Details LiteLLM-Success Call streaming complete
2025-11-18 15:29:23,520 [INFO] è¿”å›æœ€ç»ˆçš„ç»“æœ: [TextPart(kind='text', metadata=None, text='<think>\n\n</think>\n\n# è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©åœ¨ç³–å°¿ç—…è¶³æºƒç–¡æ²»ç–—ä¸­çš„ä½œç”¨åŠæœºåˆ¶ç ”ç©¶è¿›å±•\n\n## æ‘˜è¦\n- èƒŒæ™¯ï¼šç³–å°¿ç—…è¶³æºƒç–¡é«˜å‘ä¸”éš¾æ²»ï¼Œç°æœ‰ç–—æ³•å±€é™\n- ç›®çš„ï¼šç»¼è¿°è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©çš„æ²»ç–—æ½œåŠ›ä¸ä½œç”¨æœºåˆ¶\n- æ–¹æ³•ï¼šæ£€ç´¢è¿‘5å¹´æ–‡çŒ®ï¼Œèšç„¦ä½œç”¨æœºåˆ¶ä¸ä¸´åºŠè½¬åŒ–\n- ä¸»è¦å‘ç°ï¼šè¡€å°æ¿è¡ç”Ÿç‰©ä¿ƒè¿›æ„ˆåˆã€æŠ—ç‚åŠè¡€ç®¡ç”Ÿæˆ\n- ç»“è®ºä¸å±•æœ›ï¼šæ ‡å‡†åŒ–åˆ¶å¤‡ä¸ä¸´åºŠéªŒè¯ä»æ˜¯å…³é”®æŒ‘æˆ˜\n- å…³é”®è¯ï¼šè¡€å°æ¿ï¼›è¡ç”Ÿç‰©ï¼›ç³–å°¿ç—…è¶³æºƒç–¡ï¼›ä½œç”¨æœºåˆ¶ï¼›æ²»ç–—\n\n## 1. å¼•è¨€\n### 1.1 ç³–å°¿ç—…è¶³æºƒç–¡ç°çŠ¶ä¸æ²»ç–—æŒ‘æˆ˜\n### 1.2 è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©ç ”ç©¶èƒŒæ™¯\n### 1.3 æœ¬ç»¼è¿°çš„ç ”ç©¶ç›®æ ‡ä¸æ„ä¹‰\n\n## 2. è¡€å°æ¿åŠå…¶è¡ç”Ÿç‰©çš„ç”Ÿç‰©å­¦ç‰¹æ€§\n### 2.1 è¡€å°æ¿åŠŸèƒ½ä¸åœ¨ä¼¤å£ä¿®å¤ä¸­çš„ä½œç”¨\n### 2.2 è¡ç”Ÿç‰©ç±»å‹ä¸åˆ¶å¤‡æ–¹æ³•\n### 2.3 ä¸åŒè¡ç”Ÿç‰©çš„ç”Ÿç‰©æ´»æ€§æ¯”è¾ƒ\n\n## 3. ä½œç”¨æœºåˆ¶ç ”ç©¶\n### 3.1 ä¿ƒè¿›ç»†èƒå¢æ®–ä¸è¿ç§»\n### 3.2 æŠ—ç‚ä¸å…ç–«è°ƒèŠ‚ä½œç”¨\n### 3.3 ä¿ƒè¿›è¡€ç®¡ç”Ÿæˆä¸ç»„ç»‡ä¿®å¤\n\n## 4. ä¸´åºŠåº”ç”¨ä¸ç–—æ•ˆè¯„ä¼°\n### 4.1 ä¸´åºŠè¯•éªŒç»“æœä¸ç–—æ•ˆæ•°æ®\n### 4.2 ä¸åŒäººç¾¤ä¸­çš„æ²»ç–—æ•ˆæœå·®å¼‚\n### 4.3 ä¸å…¶ä»–æ²»ç–—æ‰‹æ®µçš„ååŒæ•ˆåº”\n\n## 5. å®‰å…¨æ€§ä¸å‰¯ä½œç”¨\n### 5.1 çŸ­æœŸä¸é•¿æœŸå‰¯ä½œç”¨\n### 5.2 ç‰¹æ®Šäººç¾¤çš„é£é™©è¯„ä¼°\n### 5.3 å®‰å…¨æ€§æ•°æ®ä¸ä¸´åºŠç›‘æµ‹\n\n## 6. åˆ¶å¤‡ä¸æ ‡å‡†åŒ–æŒ‘æˆ˜\n### 6.1 åˆ¶å¤‡å·¥è‰ºä¸è´¨é‡æ§åˆ¶\n### 6.2 å®‰å…¨æ ‡å‡†ä¸ç›‘ç®¡è¦æ±‚\n### 6.3 è¡Œä¸šæ ‡å‡†åŒ–è¿›å±•ä¸éšœç¢\n\n## 7. çœŸå®ä¸–ç•Œè¯æ®ä¸ç°åœºå®è·µ\n### 7.1 åŒ»é™¢ä¸ç¤¾åŒºåº”ç”¨æ¡ˆä¾‹\n### 7.2 æˆæœ¬æ•ˆç›Šåˆ†æä¸ç»æµå½±å“\n### 7.3 ä¸´åºŠå®è·µä¸­çš„åº”ç”¨å±€é™\n\n## 8. æœªæ¥å‘å±•æ–¹å‘\n### 8.1 æ–°å‹è¡ç”Ÿç‰©ç ”å‘è¶‹åŠ¿\n### 8.2 ä¸ªæ€§åŒ–æ²»ç–—ä¸ç²¾å‡†åŒ»å­¦\n### 8.3 ä¸å…¶ä»–æ²»ç–—æŠ€æœ¯çš„æ•´åˆ\n\n## 9. æ¯”è¾ƒä¸äº‰è®®ç‚¹\n### 9.1 è¡ç”Ÿç‰©ä¸ä¼ ç»Ÿæ²»ç–—çš„å¯¹æ¯”\n### 9.2 äºšç»„ç ”ç©¶ä¸­çš„ç–—æ•ˆå·®å¼‚\n### 9.3 è¯æ®è´¨é‡ä¸ç ”ç©¶åå€šåˆ†æ\n\n## 10. ç»“è®ºä¸å»ºè®®\n### 10.1 è¡€å°æ¿è¡ç”Ÿç‰©çš„ç ”ç©¶ä»·å€¼\n### 10.2 è¿›ä¸€æ­¥ç ”ç©¶æ–¹å‘ä¸æ”¿ç­–å»ºè®®\n### 10.3 æœªæ¥è½¬åŒ–ç ”ç©¶ä¸ä¸´åºŠè½¬åŒ–è·¯å¾„')]
2025-11-18 15:29:23,520 [DEBUG] Logging Details LiteLLM-Success Call streaming complete
[92m15:29:23 - LiteLLM:DEBUG[0m: cost_calculator.py:833 - selected model name for cost calculation: openai/qwen3
2025-11-18 15:29:23,521 [INFO] [adk executor] Agentæ‰§è¡Œå®Œæˆé€€å‡º
[92m15:29:23 - LiteLLM:DEBUG[0m: utils.py:376 - Logging Details LiteLLM-Async Success Call, cache_hit=False
2025-11-18 15:29:23,521 [DEBUG] selected model name for cost calculation: openai/qwen3
[92m15:29:23 - LiteLLM:DEBUG[0m: utils.py:4823 - checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
2025-11-18 15:29:23,523 [DEBUG] Logging Details LiteLLM-Async Success Call, cache_hit=False
[92m15:29:23 - LiteLLM:DEBUG[0m: utils.py:376 - Async success callbacks: Got a complete streaming response
2025-11-18 15:29:23,524 [DEBUG] checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
[92m15:29:23 - LiteLLM:DEBUG[0m: utils.py:5073 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-11-18 15:29:23,524 [DEBUG] Async success callbacks: Got a complete streaming response
[92m15:29:23 - LiteLLM:DEBUG[0m: cost_calculator.py:833 - selected model name for cost calculation: openai/qwen3
2025-11-18 15:29:23,524 [DEBUG] Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
[92m15:29:23 - LiteLLM:DEBUG[0m: cost_calculator.py:1149 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=openai/qwen3 - This model isn't mapped yet. model=openai/qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
2025-11-18 15:29:23,524 [DEBUG] selected model name for cost calculation: openai/qwen3
[92m15:29:23 - LiteLLM:DEBUG[0m: utils.py:4823 - checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
2025-11-18 15:29:23,524 [DEBUG] litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=openai/qwen3 - This model isn't mapped yet. model=openai/qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
[92m15:29:23 - LiteLLM:DEBUG[0m: cost_calculator.py:833 - selected model name for cost calculation: qwen3
2025-11-18 15:29:23,525 [DEBUG] checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
[92m15:29:23 - LiteLLM:DEBUG[0m: utils.py:5073 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-11-18 15:29:23,525 [DEBUG] selected model name for cost calculation: qwen3
[92m15:29:23 - LiteLLM:DEBUG[0m: utils.py:4823 - checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
2025-11-18 15:29:23,525 [DEBUG] Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
[92m15:29:23 - LiteLLM:DEBUG[0m: cost_calculator.py:1149 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=openai/qwen3 - This model isn't mapped yet. model=openai/qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
2025-11-18 15:29:23,525 [DEBUG] checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
[92m15:29:23 - LiteLLM:DEBUG[0m: utils.py:5073 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-11-18 15:29:23,526 [DEBUG] litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=openai/qwen3 - This model isn't mapped yet. model=openai/qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
[92m15:29:23 - LiteLLM:DEBUG[0m: cost_calculator.py:833 - selected model name for cost calculation: qwen3
2025-11-18 15:29:23,526 [DEBUG] Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
[92m15:29:23 - LiteLLM:DEBUG[0m: cost_calculator.py:1149 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=qwen3 - This model isn't mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
2025-11-18 15:29:23,526 [DEBUG] selected model name for cost calculation: qwen3
[92m15:29:23 - LiteLLM:DEBUG[0m: utils.py:4823 - checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
2025-11-18 15:29:23,526 [DEBUG] litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=qwen3 - This model isn't mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
[92m15:29:23 - LiteLLM:DEBUG[0m: litellm_logging.py:1331 - response_cost_failure_debug_information: {'error_str': "This model isn't mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.", 'traceback_str': 'Traceback (most recent call last):\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 4912, in _get_model_info_helper\n    raise ValueError(\nValueError: This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\litellm_logging.py", line 1312, in _response_cost_calculator\n    response_cost = litellm.response_cost_calculator(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1270, in response_cost_calculator\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1253, in response_cost_calculator\n    response_cost = completion_cost(\n                    ^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1162, in completion_cost\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1155, in completion_cost\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1094, in completion_cost\n    ) = cost_per_token(\n        ^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 379, in cost_per_token\n    return openai_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\llms\\openai\\cost_calculation.py", line 35, in cost_per_token\n    return generic_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\llm_cost_calc\\utils.py", line 515, in generic_cost_per_token\n    model_info = get_model_info(model=model, custom_llm_provider=custom_llm_provider)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 5158, in get_model_info\n    _model_info = _get_model_info_helper(\n                  ^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 5076, in _get_model_info_helper\n    raise Exception(\nException: This model isn\'t mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n', 'model': 'qwen3', 'cache_hit': False, 'custom_llm_provider': 'openai', 'base_model': None, 'call_type': 'acompletion', 'custom_pricing': False}
2025-11-18 15:29:23,526 [DEBUG] checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
[92m15:29:23 - LiteLLM:DEBUG[0m: utils.py:5073 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-11-18 15:29:23,527 [DEBUG] response_cost_failure_debug_information: {'error_str': "This model isn't mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.", 'traceback_str': 'Traceback (most recent call last):\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 4912, in _get_model_info_helper\n    raise ValueError(\nValueError: This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\litellm_logging.py", line 1312, in _response_cost_calculator\n    response_cost = litellm.response_cost_calculator(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1270, in response_cost_calculator\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1253, in response_cost_calculator\n    response_cost = completion_cost(\n                    ^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1162, in completion_cost\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1155, in completion_cost\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1094, in completion_cost\n    ) = cost_per_token(\n        ^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 379, in cost_per_token\n    return openai_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\llms\\openai\\cost_calculation.py", line 35, in cost_per_token\n    return generic_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\llm_cost_calc\\utils.py", line 515, in generic_cost_per_token\n    model_info = get_model_info(model=model, custom_llm_provider=custom_llm_provider)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 5158, in get_model_info\n    _model_info = _get_model_info_helper(\n                  ^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 5076, in _get_model_info_helper\n    raise Exception(\nException: This model isn\'t mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n', 'model': 'qwen3', 'cache_hit': False, 'custom_llm_provider': 'openai', 'base_model': None, 'call_type': 'acompletion', 'custom_pricing': False}
[92m15:29:23 - LiteLLM:DEBUG[0m: utils.py:4823 - checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
2025-11-18 15:29:23,527 [DEBUG] Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
[92m15:29:23 - LiteLLM:DEBUG[0m: cost_calculator.py:1149 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=qwen3 - This model isn't mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
2025-11-18 15:29:23,528 [DEBUG] checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
[92m15:29:23 - LiteLLM:DEBUG[0m: utils.py:5073 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-11-18 15:29:23,528 [DEBUG] litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=qwen3 - This model isn't mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.
[92m15:29:23 - LiteLLM:DEBUG[0m: litellm_logging.py:1331 - response_cost_failure_debug_information: {'error_str': "This model isn't mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.", 'traceback_str': 'Traceback (most recent call last):\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 4912, in _get_model_info_helper\n    raise ValueError(\nValueError: This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\litellm_logging.py", line 1312, in _response_cost_calculator\n    response_cost = litellm.response_cost_calculator(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1270, in response_cost_calculator\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1253, in response_cost_calculator\n    response_cost = completion_cost(\n                    ^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1162, in completion_cost\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1155, in completion_cost\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1094, in completion_cost\n    ) = cost_per_token(\n        ^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 379, in cost_per_token\n    return openai_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\llms\\openai\\cost_calculation.py", line 35, in cost_per_token\n    return generic_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\llm_cost_calc\\utils.py", line 515, in generic_cost_per_token\n    model_info = get_model_info(model=model, custom_llm_provider=custom_llm_provider)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 5158, in get_model_info\n    _model_info = _get_model_info_helper(\n                  ^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 5076, in _get_model_info_helper\n    raise Exception(\nException: This model isn\'t mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n', 'model': 'qwen3', 'cache_hit': False, 'custom_llm_provider': 'openai', 'base_model': None, 'call_type': 'acompletion', 'custom_pricing': False}
2025-11-18 15:29:23,528 [DEBUG] Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
[92m15:29:23 - LiteLLM:DEBUG[0m: litellm_logging.py:4204 - Model=qwen3 is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload
2025-11-18 15:29:23,528 [DEBUG] response_cost_failure_debug_information: {'error_str': "This model isn't mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.", 'traceback_str': 'Traceback (most recent call last):\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 4912, in _get_model_info_helper\n    raise ValueError(\nValueError: This model isn\'t mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\litellm_logging.py", line 1312, in _response_cost_calculator\n    response_cost = litellm.response_cost_calculator(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1270, in response_cost_calculator\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1253, in response_cost_calculator\n    response_cost = completion_cost(\n                    ^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1162, in completion_cost\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1155, in completion_cost\n    raise e\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 1094, in completion_cost\n    ) = cost_per_token(\n        ^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\cost_calculator.py", line 379, in cost_per_token\n    return openai_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\llms\\openai\\cost_calculation.py", line 35, in cost_per_token\n    return generic_cost_per_token(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\llm_cost_calc\\utils.py", line 515, in generic_cost_per_token\n    model_info = get_model_info(model=model, custom_llm_provider=custom_llm_provider)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 5158, in get_model_info\n    _model_info = _get_model_info_helper(\n                  ^^^^^^^^^^^^^^^^^^^^^^^\n  File "D:\\man\\myvenv\\Lib\\site-packages\\litellm\\utils.py", line 5076, in _get_model_info_helper\n    raise Exception(\nException: This model isn\'t mapped yet. model=qwen3, custom_llm_provider=openai. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json.\n', 'model': 'qwen3', 'cache_hit': False, 'custom_llm_provider': 'openai', 'base_model': None, 'call_type': 'acompletion', 'custom_pricing': False}
[92m15:29:23 - LiteLLM:DEBUG[0m: litellm_logging.py:2243 - Model=qwen3; cost=None
2025-11-18 15:29:23,528 [DEBUG] Model=qwen3 is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload
2025-11-18 15:29:23,529 [DEBUG] Model=qwen3; cost=None
[92m15:29:23 - LiteLLM:DEBUG[0m: utils.py:4823 - checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
2025-11-18 15:29:23,529 [DEBUG] checking potential_model_names in litellm.model_cost: {'split_model': 'qwen3', 'combined_model_name': 'openai/qwen3', 'stripped_model_name': 'qwen3', 'combined_stripped_model_name': 'openai/qwen3', 'custom_llm_provider': 'openai'}
[92m15:29:23 - LiteLLM:DEBUG[0m: utils.py:5073 - Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
2025-11-18 15:29:23,529 [DEBUG] Error getting model info: This model isn't mapped yet. Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json
[92m15:29:23 - LiteLLM:DEBUG[0m: litellm_logging.py:4204 - Model=qwen3 is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload
2025-11-18 15:29:23,530 [DEBUG] Model=qwen3 is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload
2025-11-18 15:29:23,531 [WARNING] Queue is closed. Event will not be dequeued.
